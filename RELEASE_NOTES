###############################################################################
#                                                                             #
# Trilinos Release 12.12 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.12 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Tempus*,
Teuchos, ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios,
Triutils, Xpetra, Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Domi 

  - Enhancements
    - Added more sophisticated processor decomposition algorithm. If the
      decomposition of the processors along each axis is specified
      incompletely for two or more axes, Domi now returns a much more
      logical decomposition

  - Bug fixes
    - Fixed memory management error related to Tuple and ArrayView
    - Update ParameterList documentation so that they display properly
      in HTML documentation
    - Fixed bug in MDMap::getAugmentedMDMap() method

Ifpack2

  - Multithreaded Gauss-Seidel now builds by default (#288)

    Ifpack2's support for multithreaded Gauss-Seidel uses a new
    thread-parallel graph coloring algorithm implemented in KokkosKernels.
    (KokkosKernels currently lives in tpetra/kernels.)  Ifpack2 makes this
    algorithm available in Ifpack2::Relaxation.  In the 12.10 release,
    users had to set CMake configuration options to nondefault values in
    order to enable this code.  Now, this code builds and is available by
    default.  (This fixes GitHub Issue #288.)  It is still possible to
    disable building this code, by setting the following CMake option to
    OFF:

      - Ifpack2_ENABLE_Experimental_KokkosKernels_Features

Isorropia

 - Removed experimental Tpetra interface.  The macro that would have
   enabled it was commented out, so it could never have built.  See
   discussion in #1406: https://github.com/trilinos/Trilinos/issues/1406

PyTrilinos

  - General
    - PyTrilinos now works with both Python versions 2 and 3
    - Internally, PyTrilinos now uses relative imports
    - Protect against Doxygen version 1.8.13

  - Teuchos
    - Fix ParameterList __cmp__() operator
    - Improved memory management for wrapped version of sublists
    - Fixed a memory leak in the definitions for certain directorin
      typemaps

  - Epetra
    - Add AsMap() method to Epetra.BlockMap class

  - ML
    - Fixed a dangling reference error in an ML example script.

  - LOCA
    - Fixed a memory leak in LOCA example script
    - Fixed a memory leak in the wrappers for the
      LOCA::Abstract::Iterator::StepStatus enumeration

  - Anasazi
    - Fixed a memory leak that PyTrilinos introduced with the
      Eigensolution<...>::evecs() and espace() methods

Tempus

  Tempus provides a general infrastructure for the time evolution
  of solutions to ODEs, PDEs, and DAEs, through a variety of general
  integration schemes, and can be used from small systems of
  equations (e.g., single ODEs for the time evolution of plasticity
  models) to large-scale transient simulations requiring exascale
  computing (e.g., flow fields around reentry vehicles and
  magneto-hydrodynamics).

  - Examples of time-integration methods available are:
    - Tempus::StepperForwardEuler "Forward Euler"
    - Tempus::StepperBackwardEuler "Backward Euler"
    - Tempus::StepperExplicitRK "Explicit Runge-Kutta"
    - Tempus::StepperDIRK "Diagonally Implicit Runge-Kutta methods"
    - Newmark-&beta;
      - Tempus::StepperNewmarkExplicitAForm "Explicit A-form"
      - Tempus::StepperNewmarkImplicitAForm "Implicit A-form"
      - Tempus::StepperNewmarkImplicitDForm "Implicit D-form"
    - Tempus::StepperHHTAlpha "Hilber-Hughes-Taylor (HHT-&alpha;)"
    - Tempus::StepperIMEX_RK "Implicit/Explicit Runge-Kutta (IMEX-RK) methods"
    - Tempus::StepperIMEX_RK_Partition "Partitioned IMEX-RK methods"


###############################################################################
#                                                                             #
# Trilinos Release 12.10 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.10 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos,
ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra,
Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Ifpack2

  - Experimental multithreaded Gauss-Seidel

    This uses a new thread-parallel graph coloring algorithm implemented
    in KokkosKernels.  Ifpack2's support for this lives in
    Ifpack2::Relaxation.  Currently, building it is disabled by default
    (see #288).  Enabling it requires enabling the following CMake options
    that are currently OFF by default:

      - TpetraKernels_ENABLE_Experimental
      - Ifpack2_ENABLE_Experimental
      - Ifpack2_ENABLE_Experimental_KokkosKernels_Features

  - Ifpack2::Krylov is really SUPER deprecated now

    It's been deprecated for a LONG time, complete with deprecated
    warnings.  This didn't suffice for warning some users, so I moved the
    class to the new Ifpack2::DeprecatedAndMayDisappearAtAnyTime
    namespace.

  - Encapsulate local sparse triangular solves in a new class,
    LocalSparseTriangularSolver

  - Fix various issues

    Issues fix include (but are not limited to) #672, #570, #567, #558,
    #551, #544, #409, #234, and #64.

Tpetra

  - Build time and size improvements (fix #700)

    KokkosKernels now only pre-builds the sparse matrix-vector multiply
    kernels that Tpetra needs.  Also, for integer Scalar types,
    KokkosKernels no longer optimizes sparse matrix-vector multiply for
    multiple right-hand sides.  It does so only for non-integer (e.g.,
    floating-point) Scalar types.  This reduces build time and size.  (See
    Github Issue #700.)  Furthermore, KokkosKernels now only pre-builds
    sparse matrix-vector multiply for the default offset type.

  - Removed "using Teuchos::*" declarations from Tpetra_ConfigDefs.hpp

    Tpetra no longer imports Teuchos classes like Comm and RCP (among
    others) into the Tpetra namespace.  This will help us eventually
    remove all the Teuchos_*.hpp header file includes from
    Tpetra_ConfigDefs.hpp, thus improving build time.

  - MultiVector: Add new two-argument randomize(min,max)

  - MultiVector: Get rid of old-interface DistObject methods

    Tpetra::MultiVector implements the new DistObject interface.  Thus, it
    no longer needs to provide implementations for the following three
    old-interface DistObject methods:

      - createViews
      - createViewsNonConst
      - releaseViews

  - Optimize Map::replaceCommWithSubset for MPI_COMM_SELF (#673)

  - Fixed many other issues

    Issues fixed include (but are not limited to) #699, #680, #638, #617,
    #607, #603, #601, #597, #561, and #46.


###############################################################################
#                                                                             #
# Trilinos Release 12.8 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.8 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos,
ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra,
Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Domi

  - Added replicated boundaries
    - A replicated boundary exists only on a periodic domain, and is
      simply a convention that the end points are the same points. For
      example, a left end coordinate that represents 0 degrees and a
      right end coordinate that represents 360 degrees. Domi now
      supports either convention, and it affects communication.
    - Added additional tests for periodic domains

  - Enhancements
    - New MDVector constructor that takes a parent MDVector and an array
      of Slices
    - MDMap support for axis maps
    - MDMap getMDComm() method

PyTrilinos

  - General
    - Improved formatting in example scripts

  - Domi
    - Update MDMap constructor for replicated boundaries
    - Fixed ETI bugs

  - NOX/LOCA
    - Fixed memory leak by updating NOX typemaps

  - Tpetra
    - Fix difficult-to-wrap Map class by using %inline

Tpetra

  - Stop creating Node instances explicitly!

    Hi users!  Please don't create Node instances explicitly any more.
    Tpetra::Map creates one for you, if you really need one.  You really
    don't need Node instances: Map's constructors and nonmember
    "constructors" don't need them any more, nor do Tpetra's Matrix Market
    readers.

    Creating Node instances explicitly causes issues with Kokkos
    initialization.  Node will go away eventually, in favor of Kokkos
    execution spaces and memory spaces.

  - Lots of bug fixes, especially for CUDA

  - Computing offsets in CrsGraph and CrsMatrix is now thread parallel

    CrsGraph's and CrsMatrix's fillComplete method computes row offsets,
    if they have not yet been computed.  This is now thread parallel.  It
    uses Kokkos::parallel_scan.

  - More BlockCrsMatrix kernels are thread parallel

  - Interface changes to KokkosSparse::CrsMatrix (the "local" matrix)

    - The replaceValues and sumIntoValues methods now take "is_sorted" and
      "force_atomic" arguments.  These methods now use binary search
      (falling back to linear search for short rows) for the sorted case.

    - Row views in KokkosSparse::CrsMatrix are no longer templated.  They
      now use the ordinal type, rather than the offset type, for indexing.
      This suffices as long as there are not enough duplicate entries in a
      row to exceed ordinal_type.  This has the beneficial side effect of
      reducing the number of local sparse matrix-vector multiply kernel
      instantiations.

  - Got rid of LittleBlock and LittleVector (for Block* classes)

    Instead, use the little_block_type, const_little_block_type,
    little_vec_type, and const_little_vec_type typedefs in BlockCrsMatrix
    and other related classes.  Underlying data layout has NOT changed
    (yet), but constructors HAVE changed.  This is technically a
    non-backwards-compatible interface change, but all these classes are
    in an Experimental namespace anyway.

  - Got rid of KokkosClassic::DefaultArithmetic

    Stokhos was using this, so we had left it in place in previous
    releases for backwards compatibility.  Now that no other packages
    depend on it, we have gotten rid of it for good.  Its functionality
    has been replaced by various functions in TpetraKernels.

    The original idea behind DefaultArithmetic, as suggested in the name,
    was that users could swap out this "default" implementation of
    multivector operations with their own implementations.  This is
    generally less useful than swapping out the implementation of sparse
    matrix kernels (like sparse matrix-vector multiply or sparse
    triangular solve).  As a result, Tpetra never had an implementation
    (since at least January 2010) of multivector operations other than
    DefaultArithmetic.

ROL

  - NEW FEATURES
    - Methods   
      - New phi-divergence capabilities for distributionally-robust
        optimization.
      - NonlinearLeastSquaresObjective functionality enables the solution of
        nonlinear equations through the EqualityConstraint object.

    - Infrastructure
      - Composite bound constraint (ROL_BoundConstraint_Partitioned).
      - Composite equality constraint (ROL_EqualityConstraint_Partitioned)
      - Merit function for interior point methods.
      - Adapter for Teuchos::SerialDenseVector.
      - L1, Lp, Linf norms for interior point methods.
      - Allow user-defined bracketing objects.
      - Line searches can take user-defined scalar minimizers.
      - Ability to supply ScalarMinimizationLineSearch with custom
        ScalarFunction.
      - New application development and interface tools for PDE-constrained
        optimization in PDE-OPT.
      - New PDE-OPT examples: stochastic Stefan-Boltzmann, stochastic
        advection-diffusion, etc.
      - Adaptive sparse grid capabilities with TriKota.

Zoltan

  - Improved robustness of RCB partitioner for problems where many objects have
    weight = 0 (e.g., PIC codes).  Convergence is faster and the stopping 
    criteria are more robust.

  - Fixed bug that occurred when RETURN_LIST=PARTS and (Num_GID > 1 or
    Num_LID > 1); GIDs and LIDs are now copied correctly into return lists.

  - Fixed a bug related to struct padding in the siMPI serial MPI interface.


Zoltan2 

  - Graph/Matrix ordering
    - Scotch now can be used for graph/matrix ordering.
    - The ordering interface Zoltan2::OrderingSolution has been updated
      to allow users to access separator info, if it is available.
    - Zoltan2::OrderingSolution method getPermutation() is now 
      getPermutationView().

  - Partitioning Metrics
    - Partitioning metrics have been moved out of the PartitioningProblem.
      They are now accessed through a separate class:  
      Zoltan2::EvaluatePartition.  
    - EvaluatePartition accepts as input a
      Zoltan2::Adapter and, optionally, a Zoltan2::PartitioningSolution.
      Thus, it can be used before or after partitioning, and before or
      after migration.
    - Imbalance and graph metrics are available.

  - Task placement
    - A new PartitionMapping class maps parts to processors.  
    - The MachineRepresentation has been updated, and specializations using
      Cray RCA and IBM TopoMgr are provided.
    - Geometric task placement using Multijagged partitioning better handles
      cases where the machine's network dimension is greater than the 
      dimension of the coordinates.

  - Multijagged partitioning
    - Zoltan2's Multijagged partitioner can now partition wrt the longest
      coordinate dimension, or in specified x-y-z order.

  - TPLs
    - Conversions between the index types in TPLs (ParMETIS, Scotch, Zoltan)
      are handled more robustly through the TPL_Traits class.
    - Interfaces to ParMETIS' AdaptiveRepart and RefineKway algorithms were
      added.
    - Bugs in the Zoltan interface are fixed.


###############################################################################
#                                                                             #
# Trilinos Release 12.6 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.6 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos,
ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra,
Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Ifpack2

  - Fixed Ifpack2's part of Bug 6358

    Ifpack2, as well as its tests and examples, no longer require
    GlobalOrdinal = int to be enabled in Tpetra.

  - Fixed Bug 6443

    One unit test for RILUK had an excessively tight tolerance for Scalar
    = float.  This commit relaxes the tolerance in a principled way.  As a
    result, the test now passes.


ROL

  - Enhancements:

    -  Default template parameters for ROL::TpetraMultiVector.
    -  StdVector, TpetraMultiVector, and PartitionedVector now do
       dimensional compatibility checks.
    -  More unary and binary elementwise functions added.


  - New Features:

    - Methods:
      -  InteriorPointStep class, and classes it uses (e.g. PenalizedObjective,
         InequalityConstraint, and CompositeConstraint) to solve Interior Point
         problems with the CompositeStep SQP solver with successive penalty
         reduction.
      -  Standalone GMRES solver in the Krylov directory.
      -  Mixed quantile risk measure.
      -  New risk measure corresponding to Kullback-Liebler based
         distributionally robust optimization.
      -  SROM SampleGenerator:  The associated samples are determined
         by solving an optimization problem.  Current objective functions
         correspond to moment matching and the squared L2 error between
         distribution functions.
      -  The PDE-OPT Application Development Kit (ADK) enables the rapid
         prototyping of large-scale risk-averse optimization problems with
         PDE constraints. The PDE-OPT ADK comprises three key modules:
           -- degree-of-freedom manager, which enables the use of an arbitrary
              number of simulation, control, and design fields based on finite
              element discretizations, on 1D, 2D and 3D meshes;
           -- finite element assembly loops and data structures that enable the
              development of a variety of multiphysics components, built on
              Intrepid for local finite element computations and Tpetra for
              parallel linear algebra data structures;
           -- interface between the physics module and the SimOpt programming
              interface.

    - Infrastructure:
      -  OptimizationProblem class unifies Algorithm::run interface.
      -  StochasticProblem allows for the construction of a general
         stochastic objective function based on input parameters.
      -  Generalized CVaRVector to RiskVector.  This allows for a very general
         treatment of risk-averse optimization problems.
      -  Risk measure factory.
      -  Default solve implementation for EqualityConstraint_SimOpt.
      -  BoundConstraint capability for Interior Point problems with and
         without Equality Constraints.

Tpetra

  - Better CUDA testing

    We added more nightly test builds with CUDA enabled (for running on
    NVIDIA GPUs).  The builds test various combinations of CUDA with
    different compiler versions and host thread parallelism options
    (OpenMP, Pthreads, serial).  CUDA + GCC 4.7.2 is currently the
    best-tested option, but we're using these tests to improve support for
    other options.

  - CrsMatrix, MultiVector, Vector: Added 'atomic' option to sumInto

    The sumIntoLocalValues method in Tpetra::CrsMatrix, and the
    sumIntoLocalValue and sumIntoGlobalValue methods in
    Tpetra::MultiVector and Tpetra::Vector, now take an optional bool
    'atomic' argument.  If true, the methods use Kokkos::atomic_add
    (atomic +=); if false, they use (non-atomic) += as before.

    This lets different threads call the methods concurrently on the same
    entry/ies of the matrix, multivector, or vector.  To support this, I
    also modified CrsMatrix::sumIntoGlobalValues so that it does not
    change Teuchos::RCP reference counts, thus making it thread safe.

    The default value of 'atomic' depends on the class' execution space.
    If the execution space is Kokkos::Serial (no threads), atomic is false
    by default; else, it is true by default.  This ensures that existing
    MPI-only codes do not need to pay the (small integer factor) overhead
    of atomic updates, while making sumInto always correct by default when
    using thread parallelism.

    If you know that different threads will never access the same entries
    concurrently, you should set atomic=false for best performance.

  - Block(Multi)Vector: Add "offset view" constructors (Bug 6450)

    Tpetra::Experimental::{BlockMultiVector, BlockVector} now have two
    "offset view" constructors.  They behave analogously to the offsetView
    and offsetViewNonConst methods of Tpetra::MultiVector.

    The constructors view an existing BlockMultiVector with a different
    mesh Map, and an optional local row offset from which to start the
    view on each process.  The offset is a mesh offset (it gets multiplied
    by the block size internally in order to find the point offset).  The
    two constructors differ only in that one lets you supply the new point
    Map, while the other computes it for you.

    This fixes Bug 6450 (which was a feature request).

Zoltan

  - Minor code cleanup and bug fixes.

  - New Zoltan_Get_Fn interface returning pointers to callback functions.
    See zoltan/src/include/zoltan.h for details.

  - Closest stand-alone Zoltan release is v3.83.  
    http://www.cs.sandia.gov/Zoltan

Zoltan2

  -  New interface to graph partitioning third-party library PuLP (Partitioning
     using Label Propagation).  PuLP is currently single-node, multi-threaded
     with OpenMP.  Work for the next release will include extension to 
     MPI+OpenMP.

  -  Improved handling of TPL data types, especially in the Zoltan interface.

  -  Interface from MatrixAdapter to Zoltan hypergraph algorithms implemented.

  -  Consistent handling of Tpetra explicitly instantiated types; in particular,
     enabled builds without GlobalOrdinal=int and without Epetra.

  -  PartitioningSolutionQuality class is being refactored and renamed 
     EvaluatePartition; work will continue to next release.


###############################################################################
#                                                                             #
# Trilinos Release 12.4 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.4 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos,
ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra,
Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Amesos2

  - Added MUMPS 5.0 support

  - KLU2 is enabled by default

  - Bug fixes

  - Superlu_dist multiple version support (up to 4.0)

Domi

  - Various bug fixes:
    - Fixed a bug where a periodic axis under a serial build would not
      update communication padding.  The parallel version uses MPI
      capabilities to do this, so a serial-only capability had to be
      added for this corner case.

    - Fixed a test that was doing a dynamic type comparison to be more
      robust.

    - Fixed some minor bugs in the MDVector getTpetraMultiVector()
      method.

    - The MDArrayView size() method was made const, as it should be

  - Created serial tests
    - Domi does not provide much in the way of unique capabilities if it
      is compiled in serial.  Nevertheless, all tests that run on 1
      processor were updated to run under a serial build of Trilinos as
      well.

Ifpack2

  - Deprecated Ifpack2::Krylov
    If you want a Krylov solver, just use Belos.  Ifpack2::Factory now
    throws with an informative exception message if you ask for "KRYLOV".

Muelu

  - MueLu requires certain C++11 features.  Minimum compiler versions are
    gcc 4.7.2 or icc 13. (See https://trilinos.org/about/cxx11.)

  - Kokkos is a required dependency.

  - New MatrixAnalysis Factory.

  - Deprecated Create[TE]petraPreconditioner interfaces taking
    Tpetra::CrsMatrix types as input argument in favor of interfaces
    accepting Tpetra::Operator types.

  - Numerous improvements to MueMex (MueLu's interface to Matlab).

  - Mumps can now be used as a coarse grid solver through Amesos2.

  - Unification of MueLu Epetra and Tpetra interfaces through Stratimikos.

PyTrilinos

  - General
    - Fixed several memory management bugs
    - Fixed a pervasive bug where C++ exceptions were caught in the
      wrong order. This fix results in Python errors that have much
      better messages, making it easier to debug problems that employ
      cross-language polymorphism.

  - Epetra
    - Added new Python-to-C++ converters that convert a wider variety of
      Python objects to distributed Epetra vectors (Epetra_MultiVector,
      Epetra_Vector, Epetra_IntVector).  This includes any Python object
      that exports the Distributed Array Protocol, such as Enthought's
      DistArray.  It also includes NumPy arrays when running in a serial
      environment.
    - Added __distarray__() method to Epetra vector classes, so that
      they now export the Distributed Array Protocol.
    - Memory management issues associated with the Epetra.LinearProblem
      class and the new Epetra vector converters were fixed.

  - Tpetra
    - Fixed wrappers for Tpetra MultiVector and Vector classes.
    - Added __distarray__() method to Tpetra vector classes, so that
      they now export the Distributed Array Protocol.
    - Bug fixes related to latest Tpetra upgrade

  - LOCA
    - Introduced a new LOCA test in which the Chan problem is solved
      using a preconditioner.

ROL

  - Enhancements

    -  Hierarchical XML parameter lists.  This makes ROL easier to use and
       control.  Demonstrated in all examples and test.  Also created
       the tierParameterList function to generate a hierarchical list
       from a flat list, in rol/src/zoo/ROL_ParameterListConverters.hpp,
       demonstrated in rol/test/parameters.

    -  Algorithm constructor now takes reference-counted pointers to
       Step and StatusTest.  There is another constructor that takes a step 
       name (string) and a parameter list.  This makes it easier to initialize
       a ROL algorithm, based on default choices of steps and status tests.

    -  New elementwise functions in ROL::Vector allow application of general
       nonlinear unary and binary functions as well as reduce operations.

    -  Modified ROL::BoundConstraint to work with any vector type for which
       Vector::applyUnary, Vector::applyBinary, and Vector::reduce are
       implemented.

    -  Modified default behavior of line search so that when the maximum
       number of function evaluations is reached and sufficient decrease has
       not been attained, optimization terminates.  The previous behavior can
       be recovered by setting the parameter "Accept Last Alpha" to true in
       the Step->Line Search sublist.

    -  Added line search parameter "Accept Linesearch Minimizer" to the
       Step->Line Search sublist. If this parameter is selected to be true,
       the argmin step length will be used if the maximum number of function
       evaluations is reached without attaining sufficient decrease.

    -  Renamed CompositeStepSQP to CompositeStep.


  - New Features

    - Methods
      -  Bundle Step, for solving nonsmooth problems; see example/minimax/*.

      -  Moreau-Yosida Penalty, for solving general NLPs; see
         example/burgers-control/example_04.

      -  Augmented Lagrangian, for solving general NLPs; see
         example/burgers-control/example_04.

      -  Higher Moment Coherent Risk Measure.  This method is a new risk measure
         for stochastic problems, see example/burgers-control/example_06.

      -  Buffered Probability of Exceedance.  This method is a new capability to
         minimize the probability of a stochastic cost function.  It is
         demonstrated in example/burgers-control/example_06.

    - Infrastructure

      -  In ROL_ScaledStdVector.hpp, added a variant of ROL::StdVector that
         supports constant (positive) diagonal scalings in the dot product. 
         This variant comprises the pair of classes ROL::PrimalScaledStdVector
         and ROL::DualScaledStdVector; changed the examples in
         example/diode-circuit to use variable scalings through these new
         classes.

      -  Distribution Factory, to enable general sampling for stochastic
         problems; demonstrated in example/burgers-control/example_05 through
         _07.

      -  SROMSampler.  This method permits the use of optimization-based
         sampling for stochastic problem.  It is demonstrated in
         test/sol/test_04.

      -  ROL::PartitionedVector, for handling vectors of vectors, e.g., when
         using slack variables, see /rol/test/vector/test_04.cpp.


  - Bug Fixes

    -  Removed reset of counters for objective function and gradient evaluations
       contained in the AlgorithmState in rol/src/step/ROL_TrustRegionStep.hpp.

    -  Corrected reading of the constraint tolerance parameter in
       ROL::AugmentedLagrangianStep.

Tpetra

  - Changed CMake option for setting default Node type

    To set the default Node type, use the Tpetra_DefaultNode CMake option.
    We support the old KokkosClassic_DefaultNode CMake option for
    backwards compatibility.

    Tpetra will eventually change from using Node types to using
    Kokkos::Device types directly.  For now, though, if you wish to set
    the default Node type explicitly, you must use one of the following:

      - Kokkos::Compat::KokkosCudaWrapperNode    (CUDA)
      - Kokkos::Compat::KokkosOpenMPWrapperNode  (OpenMP)
      - Kokkos::Compat::KokkosSerialWrapperNode  (Serial (no threads))
      - Kokkos::Compat::KokkosThreadsWrapperNode (Pthreads)

    Tpetra normally only enables one Node type, so you only need to set
    the default Node type if you have enabled more than one Node type.

  - Rules for which Node type gets enabled by default

    Tpetra only enables one Node type by default, whether or not ETI
    (explicit template instantiation) is enabled.  Here are the rules for
    which Node type gets enabled by default:

      1. If you're building with CUDA, Tpetra uses CUDA by default.
      2. Otherwise, if you're building with OpenMP, Tpetra uses OpenMP by
         default.
      3. Otherwise, if Kokkos enables the Serial execution space (if
         Kokkos_ENABLE_Serial is ON), Tpetra uses Serial by default.
      4. Otherwise, if Kokkos enables the Threads execution space (if
         Kokkos_ENABLE_Pthread is ON), Tpetra uses Threads by default.

    If you wish to enable other Node types, you may set the following
    CMake options.  You do NOT need to set any of these options explicitly
    if the Node type would be enabled by default anyway.

      - Tpetra_INST_CUDA (Kokkos_ENABLE_Cuda must be ON, and Trilinos must
        be built with CUDA; ON by default if building with CUDA)
      - Tpetra_INST_OPENMP (Kokkos_ENABLE_OpenMP must be ON, and Trilinos
        must be built with OpenMP support)
      - Tpetra_INST_PTHREAD (Kokkos_ENABLE_Pthread must be ON)
      - Tpetra_INST_SERIAL (Kokkos_ENABLE_Serial must be ON)

    While it is legal to enable both the OpenMP and Pthreads back-ends in
    the same executable, it is a bad idea.  Both back-ends spawn their own
    worker threads, and those threads will fight over cores.

  - Completely removed the "classic" version of Tpetra

    You might recall that a while back, we split Tpetra into "classic"
    (old) and "Kokkos refactor" (new) versions.  As of Trilinos 12.0, the
    classic version was no longer supported, but we kept it in place for a
    few users.  As of this release, we have removed the classic version
    completely.

    You no longer need to set Tpetra_ENABLE_Kokkos_Refactor to get the new
    verson of Tpetra.  It is ON (TRUE).  If you attempt to set it to OFF
    (FALSE), Tpetra's CMake raises an error at configure time.  Just
    enable Tpetra -- that's all you need to do!

    This change affects both the Classic and Core subpackages of Tpetra.
    All the "classic" Node types are gone now, along with their associated
    computational kernels.  Use the Kernels subpackage of Tpetra for local
    kernels.  (We left KokkosClassic::DefaultArithmetic in place for
    Stokhos, but ONLY for Stokhos.)  The "classic" versions of Tpetra
    classes are also now gone.  We have replaced them completely with
    their "Kokkos refactor" versions.

    You might have noticed that Doxygen had a hard time generating
    documentation for the classes which had "classic" and "refactor"
    versions.  These changes should fix that.  Furthermore, it's easier to
    find header files for classes.  In particular, most of the header
    files in the tpetra/core/src/kokkos_refactor directory now just have
    trivial definitions and only remain for backwards compatibility.

  - Improved build times and fewer .cpp files in source directory

    Tpetra does a better job now of splitting up explicit instantiations
    into separate .cpp files.  In some cases, it uses CMake to generate
    those .cpp files automatically.  This means fewer .cpp files in
    tpetra/core/src, so it's easier to find what you want.

  - 128-bit floating-point arithmetic through Scalar = __float128

    __float128 is a GCC language extension to C(++) that implements
    "double-double" 128-bit floating-point arithmetic.  It requires
    linking with libquadmath, which comes with GCC.

    You must use GCC in order to try this feature.  Also, set the
    following CMake variables:

    Tpetra_INST_FLOAT128:BOOL=ON
    CMAKE_CXX_FLAGS:STRING="-std=gnu++11 -fext-numeric-literals"
    TPL_ENABLE_quadmath:BOOL=ON

    You may also have to tell CMake where to find the libquadmath library
    and quadmath.h header file:

    quadmath_LIBRARY_DIRS:FILEPATH="${QUADMATH_LIB_DIR}"
    quadmath_INCLUDE_DIRS:FILEPATH="${QUADMATH_INC_DIR}"

    Here, ${QUADMATH_LIB_DIR} points to the directory containing the
    libquadmath library (usually your GCC library directory), and
    ${QUADMATH_INC_DIR} points to the directory containing its header file
    (quadmath.h).  For example, if you use a GCC installed in
    $HOME/pkg/gcc-5.2.0, you might need to set those variables as follows:

    QUADMATH_LIB_DIR=$HOME/pkg/gcc-5.2.0/lib
    QUADMATH_INC_DIR=\
      $HOME/pkg/gcc-5.2.0/lib/gcc/x86_64-unknown-linux-gnu/5.2.0/include

    Trilinos likes to set the "-pedantic" flag, which causes warnings for
    __float128 literals.  The build works regardless, but it would be more
    pleasing to your eyes if you could figure out how to shut off the
    warnings.

    I implemented this because the Kokkos refactor of Tpetra broke QD
    support (dd_real and qd_real -- "double-double" and "quad-double,"
    128- resp. 256-bit floating-point arithmetic).  Applications were
    asking for a work-around solution.

Zoltan2

  -  Template argument for arbitrary global identifiers (zgid_t) has been
     removed for greater efficiency in the code as well as greater conformity
     with Trilinos.  
     -  BasicUserTypes now has only three template parameters;
        the zgid_t template argument has been removed.
     -  OrderingSolution now has two different template parameters:
        <lno_t, gno_t> for <local ordinal type, global ordinal type>

  -  A new test driver capability has been added to Zoltan2 for more robust
     testing and experimentation.

  -  An interface to the Zoltan partitioners has been added to Zoltan2.
     Parameter "algorithm" == "zoltan" invokes Zoltan partitioners; parameters
     needed by Zoltan are provided through a parameter sublist called
     "zoltan_parameters".  Zoltan's geometric and hypergraph methods are
     available.

  -  A new interface to third-party library ParMA (from Rensselaer Polytechnic
     Institute) is available.  ParMA provides mesh partition improvement to
     balance both primary and secondary entities.
     It assumes the number of processors is equal to the number of requested
     parts, and that the input mesh distribution corresponds to the input part 
     assignments.  RPI's SCOREC repository is needed to use ParMA.  

  -  A new hypergraph mesh partitioning model is available in Zoltan2
     through the MeshAdapter.

  -  Parameters to third-party libraries Scotch and ParMETIS are provided 
     through parameter sublists "scotch_parameters" and 
     "parmetis_parameters", respectively.


###############################################################################
#                                                                             #
# Trilinos Release 12.2 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.2 general release contains 58 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, ROL*, RTOp, Rythmos, Sacado,
SEACAS, Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos,
ThreadPool, Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra,
Zoltan, Zoltan2.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Domi

  - Input arguments that come in the form of const Domi::MDArrayView<
    int > have been changed to be const-correct, i.e., they are now
    const Domi::MDArrayView< const int >.  This allowed for more logical
    wrappers in PyTrilinos.

  - A new Domi::DefaultNode class has been added.  If Tpetra is enabled,
    it uses the Tpetra default node.  If Tpetra is not enabled, it uses
    the serial wrapper node from Teuchos.

  - Domi's required dependencies have been simplified, to Teuchos,
    Kokkos, and TeuchosKokkosCompat.  Optional dependencies are Epetra,
    TpetraClassic, and TpetraCore.

MueLu

  - Allow to dynamically switch transfer operators between different multigrid
    levels. Can be used in context of semi-coarsening.

  - Enabled semi-coarsening (using Ray's line detection algorithm).

  - Add support for line smoothing (Ifpack/Ifpack2) [EXPERIMENTAL]

  - New AMGX Adapter [EXPERIMENTAL]

    New experimental adapter which allows a user with AMGX installed to utilize
    this software for the preconditioning and solution of linear systems. If a
    user provides AMGX configuration options instead of a MueLu input deck, the
    adapter will be called. Currently supported with Tpetra objects.

  - Matlab interface for MueLu [EXPERIMENTAL]

    Setup and solve hierarchies from Matlab and use Matlab functions as MueLu
    factories.

PyTrilinos

  - General
    - Updated the Developers Guide

  - Teuchos
    - Made Teuchos a required dependency for PyTrilinos.

  - Domi
    - Domi wrappers now use new Domi::DefaultNode class
    - Added HAVE_DOMI as a macro in PyTrilinos_config.h
    - Fixed docstrings for Domi package
    - Added a simple Domi example
    - Fixed Domi.MDVector extensions

  - Tpetra
    - Enabled Tpetra wrappers in the release branch
    - Fixed a dynamic typing problem
    - Bug fixes in Tpetra.Map
    - Added HAVE_TPETRA as a macro in PyTrilinos_config.h
    - Fixed docstrings for Tpetra package
    - Got wrappers for all requiredTpetra constructors to work
    - Expanded Tpetra.Vector unit tests
    - Added unit tests for Tpetra.MultiVector

ROL 

  Rapid Optimization Library (ROL) is a C++ package for large-scale
  optimization. It is used for the solution of optimal design, optimal control
  and inverse problems in large-scale engineering applications. Other uses
  include mesh optimization and image processing.

  ROL aims to combine flexibility, efficiency and robustness.  Key features:

  - Matrix-free application programming interfaces (APIs) --enable direct use
    of application data structures and memory spaces, linear solvers,
    nonlinear solvers and preconditioners.

  - State-of-the-art algorithms for unconstrained optimization, constrained
    optimization and optimization under uncertainty --enable inexact and
    adaptive function evaluations and iterative linear system solves.

  - Special APIs for simulation-based optimization --enable a streamlined
    embedding into engineering applications, rigorous implementation
    verification and efficient use.

  - Modular interfaces throughout the optimization process --enable custom
    and user-defined algorithms, stopping criteria, hierarchies of algorithms,
    and selective use of a variety of tools and components.

  For a detailed description of user interfaces and algorithms included in this
  release, see the presentation ROL-Trilinos-12.2.pptx (or .pdf) in the
  doc/presentations directory.

Tpetra

  - Improvements to the "local" part of Tpetra::Map

    Tpetra::Details::FixedHashTable implements the "local" part of
    Tpetra::Map, where the "local part" is that which does not use MPI
    communication.  For example, FixedHashTable knows how to convert from
    global indices to local indices, for all the global indices known by
    the calling process.

    FixedHashTable now uses Kokkos for its data structures.  Its
    initialization is completely Kokkos parallel, and its conversions
    between global and local indices are Kokkos device functions.  This
    achieves an important goal of making the local part of Tpetra::Map
    functionality available for Kokkos parallel operations.

  - Many Tpetra classes now split instantiations into multiple files

    This matters only when explicit template instantiation (ETI) is ON.
    (This _should_ be ON by default, but is not ON by default yet.)

    The largest Tpetra classes (e.g., CrsGraph, CrsMatrix, and
    MultiVector) now split their explicit instantiations into multiple
    .cpp files.  This helps reduce build times and memory usage when ETI
    is ON, and makes setting ETI ON an even more attractive option for
    applications.

  - Fixed Bugs 6335, 6336, 6377, and others

  - Improved tests to catch errors on processes other than Process 0

  - Improved CMake output and internal ETI-related documentation


###############################################################################
#                                                                             #
# Trilinos Release 12.0 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 12.0 general release contains 57 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Domi, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Pike, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS,
Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool,
Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan,
Zoltan2.

Domi

  Domi provides distributed data structures for multi-dimensional data.
  The inspirational use case is parallel domain decomposition for finite
  difference applications.  To that end, Domi provides the following
  classes:

  - MDArray, MDArrayView, MDArrayRCP
      These classes define multi-dimensional arrays, with arbitrary
      runtime-defined dimensions, built on top of the Teuchos Array,
      ArrayView, and ArrayRCP classes, respectively.  These are serial
      in nature and provide the mechanism for data manipulation on each
      processor of distributed MDVectors.

  - Slice
      The Slice class is inspired by the Python slice object, which
      stores a start, stop, and step index, and can be constructed to
      utilize a variety of logical default values.  Slices can be used
      on all multi-dimensional objects to return views into subsets of
      those objects.

  - MDComm
      Multi-dimensional communicator.  This communicator provides a map
      between a multi-dimensional array of processors and their ranks,
      and can be queried for neighbor ranks.  MDComms can be sliced,
      which returns a sub-sommunicator.

  - MDMap
      An MDMap describes the decomposition of an MDVector on an MDComm.
      It stores the start and stop indexes along each dimension,
      including boundary padding for algorithms that require extra
      indexes along boundaries, and communication padding used to
      update values from neighboring processors.  MDMaps can be sliced,
      and the resulting MDMap may reside on a sub-communicator.  An
      MDMap can be converted to an equivalent Epetra or Tpetra Map.

  - MDVector
      An MDVector is a multi-dimensional array, distrubuted in a
      structured manner across multiple processors.  This distribution
      is described by an MDVector's MDMap.  The MDVector's data is
      stored locally on each processor with an MDArrayRCP.  An MDVector
      can update its communication padding from neighboring processors
      automatically.  An MDVector can be sliced, and the resulting
      MDVector may reside on a sub-communicator.  An MDVector can be
      converted to equivalent Epetra or Tpetra Vectors or MultiVectors.
      If there are no stride gaps in the data due to slicing, these
      converted Epetra and Tpetra objects may be views of the original
      data.

MueLU

  - Hierarchy::Iterate now understands tolerance

      When MueLu::Hierarchy is being used as a standalone solver, and not as a
      preconditioner, a user may now create a stopping criteria based on a
      provided tolerance for the relative residual in addition to the maximum
      number of iterations

  - New reuse options option: "tP"

      This reuse option allows reuse of only tentative prolongators, while
      rebuilding smoothed prolongator and coarse level operators.

  - Selected bugfixes:
      6301:  Operator complexity was computed incorrectly for large size
      problems

Pike

  PIKE: Physics Integration KErnels

  Pike is a blackbox multiphysics coupling tool.  It provides basic
  interfaces and implementations for building high level multiphysics
  coupling strategies.  In particular, PIKE provides utilities for
  Picard-style couplings.  For Newton-based couplings, use the NOX and
  Thyra packages to build the block phsyics systems.  In the future,
  interoperability tools between NOX, PIKE and PIRO will be added.

  - Initial release!

  - Supports block Jacobi and block Gauss-Seidel coupling.

  - Supports global and local convergence criteria.

  - Supports hierarchical solves.

  - Supports subcycled transient solves and steady-state.

  - Support both Parameter and Response interfaces.

  - Contains a multiphysics distributor to support parallel
    distribution of applications.

  - Provides abstract factories for solvers and global status tests

  - Supports observers for user injection of code.  Special observers
    for logging and debugging are implemeted.

  - Pure virtual interfaces for applications and data transfers.

  - Adapter for nesting a solver as a model evaluator for hierarchical
    solves.

  ****************************************


PyTrilinos

  - General
      - Changed to BSD license
      - Mpi4Py support has been made optional.  Previously, if Mpi4Py was
        found, it was automatically enabled within PyTrilinos.  Now that
        behavior can be turned off.

  - LOCA
      - The LOCA module has been refactored and now has been demonstrated
        to work for the Chan problem.  We have two example problems
        working, one without preconditioning, and one with.

  - Tpetra
      - Package is still experimental.  The recent refactor has broken
        MultiVectors and Vectors.
      - Map support has been improved

  - Anasazi
      - Fixed a bug where return eigenvalues are converted to a NumPy
        array, but the dimension used the wrong type.

  - Kokkos
      - Fixed a macro issue

  - NOX
      - Started PETSc compatibility.  This is still experimental, and
        includes compatibility with petsc4py.

  - STK
      - Removed PyPercept, as it is currently not a part of the new STK.

  - Domi
      - Added package


Tpetra

  - Tpetra now requires C++11

      This requirement comes in part from Tpetra itself, and in part from
      the Kokkos package, on which Tpetra depends.

  - "Kokkos refactor" (new) version of Tpetra is the only version

      We no longer enable or support the old ("classic") version of Tpetra.
      The new ("Kokkos refactor") implementation of Tpetra is now the only
      supported version.

      Do not use any of the Node types in the KokkosClassic namespace.  We
      do not support any of those Node types anymore.  Instead, use any of
      the following Node types:

        - Kokkos::Compat::KokkosOpenMPWrapperNode (OpenMP)
        - Kokkos::Compat::KokkosCudaWrapperNode (NVIDIA CUDA)
        - Kokkos::Compat::KokkosSerialWrapperNode (no threads)
        - Kokkos::Compat::KokkosThreadsWrapperNode (Pthreads)

      Each of these is a typedef for
      Kokkos::Compat::KokkosDeviceWrapperNode<ExecSpace>, for the
      corresponding Kokkos execution space.

  - Set / rely on the default Node type as much as possible

      Tpetra classes have a template parameter, "Node", which determines
      what thread-level parallel programming model Tpetra will use.  This
      corresponds directly to the "execution space" concept in Kokkos.

      Tpetra classes have a default Node type.  Users do NOT need to specify
      this explicitly.  I cannot emphasize this enough:

      IF YOU ONLY EVER USE THE DEFAULT VALUES OF TEMPLATE PARAMETERS, DO NOT
      SPECIFY THEM EXPLICITLY.

      If you need to refer to the default values of template parameters, ask
      Tpetra classes.  For example, 'Tpetra::Map<>::node_type' is the
      default Node type.

      Tpetra pays attention to Kokkos' build configuration when determining
      the default Node type.  For example, it will not use a disabled
      execution space.  If you do not like the default Node type, but you
      only ever use one Node type in your application, you should change the
      default Node type at Trilinos configure time.  You may do this by
      setting the 'KokkosClassic_DefaultNode' CMake option.  Here is a list
      of reasonable values:

        "Kokkos::Compat::KokkosSerialWrapperNode": use Kokkos::Serial
        execution space (execute in a single thread on the CPU)

        "Kokkos::Compat::KokkosOpenMPWrapperNode": use Kokkos::OpenMP
        execution space (use OpenMP for thread-level parallelism on the CPU)

        "Kokkos::Compat::KokkosThreadsWrapperNode": use Kokkos::Threads
        execution space (use Pthreads (the POSIX Threads library) for
        thread-level parallelism on the CPU)

        "Kokkos::Compat::KokkosCudaWrapperNode": use Kokkos::Cuda execution
        space (use NVIDIA's CUDA programming model for thread-level
        parallelism on the CPU)

      You must use the above strings with the 'KokkosClassic_DefaultNode'
      CMake option.  If you choose (unwisely, in many cases) to specify the
      Node template parameter directly in your code, you may use those
      names.  Alternately, you may let the Kokkos execution space determine
      the Node type, by using the templated class
      Kokkos::Compat::KokkosDeviceWrapperNode.  This class is templated on
      the Kokkos execution space.  The above four types are typedefs to
      their corresponding specializations of KokkosDeviceWrapperNode.  For
      example, KokkosSerialWrapperNode is a typedef of
      KokkosDeviceWrapperNode<Kokkos::Serial>.  This may be useful if your
      code already makes use of Kokkos execution spaces.

  - Removed (deprecated classes) Tpetra::VbrMatrix, Tpetra::BlockMap,
    Tpetra::BlockCrsGraph, and Tpetra::BlockMultiVector.

      All these classes relate to VBR (variable-block-size block sparse
      matrix) functionality.  We may reimplement that at some point, but for
      now it's going away.

  - Removed (deprecated class) Tpetra::HybridPlatform

Teuchos

  - Fixed Teuchos::Ptr::operator=() to catch dangling references (6 April 2015)



###############################################################################
#                                                                             #
# Trilinos Release 11.14 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.14 general release contains 55 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS,
Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool,
Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan,
Zoltan2.


Muelu

  - Support for Amesos2 native serial direct solver "Basker".

  - ML parameters can be used through MueLu::CreateEpetraPreconditioner and
    MueLu::CreateTpetraPreconditioner interfaces


  - Several bug fixes:
      6256:  ML parameter "coarse: type" does not work in
             MueLu::MLParameterListInterpreter
      6255:  Multiple issues in MueLu::MLParameterListInterpreter

  - Explicit template instantiation (ETI) changes

    The new version of MueLu uses Tpetra macros for specifying the desired
    template instantiations values (scalars, local ordinals, global ordinals and
    note types). As such, Tpetra instantiation configure options provide the
    necessary MueLu instantiations. For instance, instead of the previous option
        -D MueLu_INST_DOUBLE_INT_LONGLONGINT=ON
    a user should write
        -D Tpetra_INST_INT_LONG_LONG
    See Tpetra documentation for a full set of options.

  - New reuse feature [EXPERIMENTAL]

     MueLu introduced a new experimental reuse feature. A user may specify
     partial preservation of a multigrid hierarchy through the "reuse: type"
     option. Few variants have been implemented:

      - "none"
        No reuse, the preconditioner is constructed from scratch

      - "emin"
        Reuse old prolongator as an initial guess to energy minimization, and
        reuse the prolongator pattern.

      - "RP"
        Reuse smoothed prolongator and restrictor. Smoothers and coarse grid
        operators are recomputed.

      - "RAP"
        Recompute only the finest level smoother.

      - "full"
        Reuse full hierarchy, no changes.

    The current user interface is as follows:

      // User constructs a hierarchy for the first time
      Teuchos::RCP<MueLu::TpetraOperator<SC,LO,GO,NO> > H =
        MueLu::CreateTpetraPreconditioner<SC,LO,GO,NO>(A0, xmlFileName);
      ...
      // User reuses existing hierarchy for consequent steps
      MueLu::ReuseTpetraPreconditioner(A1, *H);

  - Support for user-provided data [EXPERIMENTAL]

      New release of MueLu allows user to provide the data for the first few
      levels of the multigrid Hierarchy, while allowing MueLu to construct
      remaining levels. At the minimum, user needs to provide the data for
      fine-level operator A, prolongation operator (P), restriction operator (R)
      and coarse-level operator (Ac). These operator are required to derive from
      Xpetra::Operator class. This scenario is driven through a ParameterList
      interface (see muelu/example/advanced/levelwrap for some use cases).

Tpetra

  - Public release of "Kokkos refactor" version of Tpetra

    The "Kokkos refactor" version of Tpetra is a new implementation of
    Tpetra.  It is based on the new Kokkos programming model in the
    KokkosCore subpackage.  It coexists with the "classic" version of
    Tpetra, which has been DEPRECATED and will be removed entirely in the
    12.0 major release of Trilinos.  Thus, the Kokkos refactor version
    will become the /only/ version of Tpetra at that time.

    The Kokkos refactor version of Tpetra maintains mostly backwards
    compatibility [SEE NOTE BELOW] with the classic version's interface.
    Its interface will continue to evolve.  For this first public release,
    we have prioritized backwards compatibility over interface innovation.

    The implementation of the Kokkos refactor version of Tpetra currently
    lives in tpetra/core/src/kokkos_refactor.  It works by partial
    specialization on the 'Node' template parameter, and by a final 'bool'
    template parameter (which users must NEVER SPECIFY EXPLICITLY).  The
    "classic" version of Tpetra uses the old ("classic") Node types that
    live in the KokkosClassic namespace.  All of the classic Node types
    have been DEPRECATED, which is how users can see that classic Tpetra
    has been deprecated.

    If you wish to disable the Kokkos refactor version of Tpetra, set the
    Tpetra_ENABLE_Kokkos_Refactor CMake option to OFF.  Please note that
    this will result in a large number of warnings about deprecated
    classes.  This CMake option will go away in the 12.0 release.

  - Note on backwards compatibility of Tpetra interface

    In the new version of Tpetra, MultiVector and Vector implement /view
    semantics/.  That is, the one-argument copy constructor and the
    assignment operator (operator=) perform shallow copies.  (By default,
    in the classic version of Tpetra, they did deep copies.)  For deep
    copies, use one of the following:

      - Two-argument "copy constructor" with Teuchos::Copy as the second
        argument (to create a new MultiVector or Vector which is a deep
        copy of an existing one)
      - Tpetra::deep_copy (works like Kokkos::deep_copy)

  - What if I have trouble building with Scalar=std::complex<T>?

    The new version of Tpetra should be able to build with Scalar =
    std::complex<float> or std::complex<double>.  If you have trouble
    building, you may disable explicit template instantiation (ETI) and
    tests for those Scalar types, using the following CMake options:

      Tpetra_INST_COMPLEX_FLOAT:BOOL=OFF
      Tpetra_INST_COMPLEX_DOUBLE:BOOL=OFF

  - Accessing and changing the default Node type

    Tpetra classes have a template parameter, "Node", which determines
    what thread-level parallel programming model Tpetra will use.  This
    corresponds directly to the "execution space" concept in Kokkos.

    Tpetra classes have a default Node type.  Users do NOT need to specify
    this explicitly.  I cannot emphasize this enough:

    IF YOU ONLY EVER USE THE DEFAULT VALUES OF TEMPLATE PARAMETERS, DO NOT
    SPECIFY THEM EXPLICITLY.

    If you need to refer to the default values of template parameters, ask
    Tpetra classes.  For example, 'Tpetra::Map<>::node_type' is the
    default Node type.

    Tpetra pays attention to Kokkos' build configuration when determining
    the default Node type.  For example, it will not use a disabled
    execution space.  If you do not like the default Node type, but you
    only ever use one Node type in your application, you should change the
    default Node type at Trilinos configure time.  You may do this by
    setting the 'KokkosClassic_DefaultNode' CMake option.  Here is a list
    of reasonable values:

      "Kokkos::Compat::KokkosSerialWrapperNode": use Kokkos::Serial
      execution space (execute in a single thread on the CPU)

      "Kokkos::Compat::KokkosOpenMPWrapperNode": use Kokkos::OpenMP
      execution space (use OpenMP for thread-level parallelism on the CPU)

      "Kokkos::Compat::KokkosThreadsWrapperNode": use Kokkos::Threads
      execution space (use Pthreads (the POSIX Threads library) for
      thread-level parallelism on the CPU)

      "Kokkos::Compat::KokkosCudaWrapperNode": use Kokkos::Cuda execution
      space (use NVIDIA's CUDA programming model for thread-level
      parallelism on the CPU)

    You must use the above strings with the 'KokkosClassic_DefaultNode'
    CMake option.  If you choose (unwisely, in many cases) to specify the
    Node template parameter directly in your code, you may use those
    names.  Alternately, you may let the Kokkos execution space determine
    the Node type, by using the templated class
    Kokkos::Compat::KokkosDeviceWrapperNode.  This class is templated on
    the Kokkos execution space.  The above four types are typedefs to
    their corresponding specializations of KokkosDeviceWrapperNode.  For
    example, KokkosSerialWrapperNode is a typedef of
    KokkosDeviceWrapperNode<Kokkos::Serial>.  This may be useful if your
    code already makes use of Kokkos execution spaces.

  - Changes to subpackages

    Tpetra is now divided into subpackages.  What was formerly just
    "Tpetra" is now "TpetraCore".  Other subpackages of Kokkos have moved,
    some into Teuchos and some into Tpetra.  Those subpackages have
    changed from Experimental (EX) to Primary Tested (PT), so that they
    build by default if Tpetra is enabled.

    The most important change is that Tpetra now has a required dependency
    on the Kokkos programming model.  See below.

    If your application links against Trilinos using either the
    Makefile.export.* system or the CMake FIND_PACKAGE(Trilinos ...)
    system, you do not need to worry about this.  Just enable Tpetra and
    let Trilinos' build system handle the rest.

  - New required dependency on Kokkos

    Tpetra now has a required dependency on the Kokkos programming model.
    In particular, TpetraCore (see above) has required dependencies on the
    KokkosCore, KokkosContainers, and KokkosAlgorithms subpackages of
    Kokkos.

    This means that Tpetra is now subject to Kokkos' build requirements.
    C++11 support is still optional in this release, but future releases
    will require C++11 support.  Please refer to Kokkos' documentation for
    more details.

  - Deprecated variable-block-size classes (like VbrMatrix).

    We have deprecated the following classes in the Tpetra namespace:

      - BlockCrsGraph
      - BlockMap  
      - BlockMultiVector (NOT Tpetra::Experimental::BlockMultiVector)
      - VbrMatrix

    These classes relate to "variable-block-size" vectors and matrices.
    Tpetra::BlockMultiVector (NOT the same as
    Tpetra::Experimental::BlockMultiVector) implements a
    variable-block-size block analogue of MultiVector.  Each row of a
    MultiVector corresponds to a single degree of freedom; each block row
    of a BlockMultiVector corresponds to any number of degrees of freedom.
    "Variable block size" means that different block rows may have
    different numbers of degrees of freedom.  An instance of
    Tpetra::BlockMap represents the block (row) Map of a BlockMultiVector.
    Tpetra::VbrMatrix implements a variable-block-size block sparse matrix
    that corresponds to BlockMultiVector.  Each (block) entry of a
    VbrMatrix is it own dense matrix.  These dense matrices are not
    distributed; they are locally stored and generally "small" (think
    "fits in cache").  An instance of Tpetra::BlockCrsGraph represents the
    block graph of a VbrMatrix.

    Here are the reasons why we are deprecating these classes:

      - Their interfaces as well as their implementations need a
        significant redesign for MPI+X, e.g., for efficient use of
        multiple levels of parallelism.
      - They are poorly exercised, even in comparison to their Epetra
        equivalents.
      - They have poor test coverage, and have outstanding known bugs: see
        e.g., Bug 6039.
      - Most users don't need a fully general VBR [1].
      - We would prefer to name the VBR classes consistently, both to
        emphasize the V (variable) part and to distinguish them from the
        new constant-block-size classes.

    [1] Many users' block matrices have blocks which are all the same
        size.  They would get best performance by using the new
        constant-block-size classes that currently live in the
        Tpetra::Experimental namespace.  Others usually only have a small
        number of different block sizes per matrix (e.g., 3 degrees of
        freedom per interior mesh point; 2 for boundary mesh points).  The
        latter users could get much better performance by a data structure
        that represents the sparse matrix as a sum of constant-block-size
        matrices.

Zoltan2

  - The PartitioningSolution class's interface has changed.
    -  methods getPartList and getProcList have been renamed to 
       getPartListView and getProcListView to emphasize that a view, not a copy,
       is being returned.
    -  method getPartListView now returns the part identifiers in the same order
       that the local data was provided.  The user's localData[i] is assigned 
       to getPartListView()[i].  Conversions from global identifiers
       from PartitioningSolution::getIdList() to local identifiers are no longer
       needed.  
    -  methods getIdList and getLocalNumberOfIds have been removed.
    -  method convertSolutionToImportList has been removed and replaced 
       by the helper function getImportList in Zoltan2_PartitioningHelpers.hpp.
    -  pointAssign and boxAssign methods have been added for some geometric 
       partitioners.  Support is provided through MultiJagged (MJ) partitioning.
       pointAssign returns a part number that contains a given geometric point.
       boxAssign returns all parts that overlap a given geometric box.

  - New graph coloring options:
    - The parameter color_choice can be used to obtain a more balanced coloring.
      Valid values are FirstFit, Random, RandomFast, and LeastUsed.

  - New partitioning options:
    -  Scotch interface updated to Scotch v6 or later (Tested against v6.0.3.)
    -  Interface to ParMETIS v4 or later added.  (Tested against v4.0.3.)

  - Miscellaneous:
    -  Parameter "rectilinear_blocks" has been renamed "rectilinear".


###############################################################################
#                                                                             #
# Trilinos Release 11.12 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.12 general release contains 55 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, MueLu, NOX, Optika, OptiPack,
Pamgen, Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS,
Shards, ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool,
Thyra, Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan,
Zoltan2.


Framework Release Notes:

  - Changed minimum version of CMake from 2.7 to 2.8.11.

MueLu 

  Trilinos 11.12 is the initial release of MueLu.

  MueLu is an extensible multigrid library that is part of the Trilinos project.
  MueLu works with Epetra (32- and 64-bit versions) and Tpetra matrix types. The
  library is written in C++ and allows for different ordinal (index) and scalar
  types. MueLu is designed to be efficient on many different computer
  architectures, from workstations to supercomputers. While it is MPI based,
  MueLu is relies on the "MPI+X" principle, where "X" can be threading or CUDA.

  MueLu's software design allows for the rapid introduction of new multigrid
  algorithms.

  MueLu provides a number of different multigrid algorithms:
   - smoothed aggregation algebraic multigrid (AMG), appropriate for
     Poisson-like
     and elasticity problems
   - Petrov-Galerkin aggregation AMG for convection-diffusion problems
   - aggregation-based AMG for problems arising from the eddy current
     formulation of Maxwell's equations

  A PDF user's guide is located in muelu/doc/UsersGuide.  To compile it, simply
  run "make".


PyTrilinos

  - General

    * Got rid of NestedEpetra paradigm and now use relative imports to
      address the problem that NestedEpetra wass supposed to solve.
    * Changed build system for docstrings.  The docstrings are no longer
      stored in the repository.  If the user wants docstrings, then
      doxygen needs to be installed.  Docstrings are built during the
      configuration phase.
    * Fixed warnings due to Epetra 32/64 bit handling
    * Added mpi4py support.  Specifically, the Eptra_MpiComm
      constructors and Teuchos::MpiComm<> constructors can now take MPI
      sub-communicators, provided by mpi4py.MPI.Comm class.  Ignored if
      mpi4py is not found.
    * Updated Developers Guide

  - Teuchos module

    * Support for the Teuchos::DataAccess enumeration.  This enables
      certain Tpetra and Domi constructors
    * Add Teuchos::Arrays of int, long, float and double, as valid types
      for PyTrilinos ParameterLists

  - DistArray Protocol

    * Added support for the DistArray Protocol.  This is preliminary and
      unfortunatley, does not provide any functionality with this
      release.

  - LOCA module

    * Re-instated the LOCA wrappers.  These are still experimentaland
      require SWIG 3.0.0 and Python 2.5.
    * Re-introduction of the LOCA interface required the introduction of
      relative imports, which require Python 2.5 or higher.

  - Isorropia module

    * Refactor of Isorropia directory structure.  This should not affect
      users.


Tpetra

  - Kokkos refactor version of Tpetra

    The "Kokkos refactor" version of Tpetra is the new version of Tpetra,
    based on the new Kokkos programming model in the KokkosCore
    subpackage.  It coexists with the "classic" version of Tpetra, which
    is currently the default version.  We plan to deprecate the "classic"
    version of Tpetra in the 11.14 minor release in January, and to remove
    it entirely in the 12.0 major release.  Thus, the "Kokkos refactor"
    version of Tpetra will become the /only/ version of Tpetra at that
    time.

    The implementation of the Kokkos refactor version of Tpetra currently
    lives in src/kokkos_refactor.  It works by partial specialization on
    the Node template parameter.  If you would like to enable this version
    of Tpetra, here is a suggested set of CMake options:

    # Enable OpenMP, and enable Kokkos' OpenMP backend
    -D Trilinos_ENABLE_OpenMP:BOOL=ON

    # Set Tpetra's default Node type to use new Kokkos with OpenMP.
    # You could also use KokkosThreadsWrapperNode or even 
    # KokkosSerialWrapperNode here.  
    -D KokkosClassic_DefaultNode:STRING="Kokkos::Compat::KokkosOpenMPWrapperNode"

    # Enable the Kokkos refactor version of Tpetra.
    -D Tpetra_ENABLE_Kokkos_Refactor:BOOL=ON

    In a debug build, you might like to enable Kokkos' run-time bounds
    checking.  Here's how you do that.  These are _optional_ parameters
    and their default values are both OFF (not enabled).

    -D Kokkos_ENABLE_BOUNDS_CHECK:BOOL=ON
    -D Kokkos_ENABLE_DEBUG:BOOL=ON

    The following options may reduce build times if ETI is enabled:

    # Disable KokkosClassic::OpenMPNode
    -D KokkosClassic_ENABLE_OpenMP:BOOL=OFF
    # Disable KokkosClassic::TPINode
    -D KokkosClassic_ENABLE_ThreadPool:BOOL=OFF
    # Shut off Kokkos' Pthreads back-end in favor of OpenMP
    -D Kokkos_ENABLE_Pthread:BOOL=OFF

    You must also enable the following subpackages explicitly, since they
    are not Primary Tested at the moment:

      - KokkosCore
      - KokkosCompat
      - KokkosContainers
      - KokkosLinAlg
      - KokkosAlgorithms
      - KokkosMpiComm

    If Tpetra_ENABLE_Kokkos_Refactor is ON but any of those subpackages
    are not enabled, CMake will stop with an error message that tells you
    what subpackages to enable.

    If you would like to build with the above subpackages enabled, but
    would /not/ like to build Tpetra with any of the new Kokkos Nodes, you
    may try setting the CMake KokkosClassic_ENABLE_KokkosCompat to OFF.
    This works for me as of 07 Oct 2014, but I do not recommend it, and it
    is not supported.

    Fun fact: there are three relevant combinations of (new Kokkos
    enabled?, Kokkos refactor enabled?), and we test them all!  You can
    use the new Kokkos Node types with "classic" Tpetra, or you can use
    them with "Kokkos refactor" Tpetra.

    Most Tpetra tests exercise all enabled Node types, or just use the
    default Node type.  Ifpack2 tests only use the default Node type
    currently.  That's why the above build configuration changes the
    default Node type.  That way, all packages that depend on Tpetra will
    use the Kokkos refactor version of Tpetra in /their/ tests by default.


  - Full set of default values of template parameters

    Usability improvement!  Most Tpetra classes now come with a full set
    of default values of template parameters.  In many cases, you need no
    longer specify _any_ template parameters' values, if you only intend
    to use their defaults.  For example, you may now write the following:

      // All default template parameters!
      Tpetra::Map<> map (...);

      // No "typename" because Map<> is a concrete type.
      typedef Tpetra::Map<>::local_ordinal_type LO;
      typedef Tpetra::Map<>::global_ordinal_type GO;

      for (LO i_lcl = map.getMinLocalIndex (); 
           i_lcl <= map.getMaxLocalIndex (); ++i_lcl) {
        const GO i_gbl = map.getGlobalElement (i_lcl);
        // ...
      }

      // All default template parameters!
      // Scalar defaults to double.
      // LocalOrdinal, GlobalOrdinal, and Node default
      // to the same values as those of Map<> above.
      Tpetra::MultiVector<> X (...);

    Also, if you need to specify (say) GlobalOrdinal explicitly, you don't
    have to specify Node explicitly.  For example:

      // Don't need to specify Node; it takes its default value.
      Tpetra::Map<int, long long> map (...);
      Tpetra::MultiVector<double, int, long long> X (...);

    You may specify the default value of Node at Trilinos configure time
    (that is, when running CMake).  The current default is
    KokkosClassic::SerialNode (no threads; MPI only).  This will change,
    but it will always have a reasonable value for conventional multicore
    processors.

    Please, _please_ prefer default values of template parameters!  This
    will make your code shorter, allow more flexibility at configure time,
    and might even make builds a bit faster.  All Tpetra classes come with
    public typedefs, so you can pick up scalar_type (if applicable),
    local_ordinal_type, global_ordinal_type, and node_type from Tpetra
    directly, rather than specifying them explicitly.

  - Removed the LocalMatOps template parameter

    CrsGraph, CrsMatrix, VbrMatrix, and other classes used to have a
    LocalMatOps template parameter.  This was the fourth template
    parameter of CrsGraph and the fifth template parameter of CrsMatrix.
    It was always optional.  Chris Baker intended it as an extension point
    for users or third-party vendors to insert their own sparse
    matrix-vector multiply or triangular solve routines.  However, no one
    ever used it for this purpose as far as we know.  When it started to
    hinder the Kokkos refactor effort (see release notes for Trilinos
    11.10 below), we removed it.  This should speed up compilation times.

    Lesson: It's always easier to _add_ a template parameter (at the end,
    if it's optional) than it is to remove one.

    Getting rid of LocalMatOps does amount to a backwards incompatible
    interface change.  However, we deemed it a harmless change, for the
    following reasons:

      1. LocalMatOps has a reasonable default value.
      2. As far as I know, no one other than Chris Baker and myself ever
         wrote or used alternate implementations of LocalMatOps.
      3. Trilinos packages or applications which bothered to specify
         LocalMatOps never used anything other than the default value.

    Thus, it never even crossed my mind that applications would bother to
    specify this thing.  Unfortunately, some applications may still
    LocalMatOps explicitly.  This typedef is unnecessary.  You do not need
    to specify this template parameter.  The default value was always
    perfectly fine and has been for years.



###############################################################################
#                                                                             #
# Trilinos Release 11.10 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.10 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan, Zoltan2.

Anasazi

  - Improved examples and added more explanatory comments.
    Thanks to Alicia Klinvex (Purdue) for review and suggestions.

Ifpack2

  - Fixed bug in ReorderFilter (related to Bug 6117).
    ReorderFilter was computing the number of entries for the wrong row,
    which caused temporaries (either in Ifpack2::ReorderFilter or in
    MueLu) to be allocated with the wrong size.  This may be related to
    Bug 6117.

  - LocalFilter::apply now checks whether X aliases Y.

  - Performance improvements to apply() of BlockRelaxation, LocalFilter,
    and Relaxation (10-11 Apr 2014).


STK

  - New STK introduced.

    A new version of STK has been introduced including a number of performance
    improvements. The API of STK has changed from the previous version such that
    it is unlikely that codes that used STK will work without modification. The
    old STK is still available for use, but will be removed in a future release.
    The old STK is now in a new namespace "stk_classic" which will also require
    some changes to continue to use. There is a script that can be used to help.
    The script can be found in
    packages/stk/stk_classic/conversion_scripts/stk_to_stk_classic. Use of the
    script is discussed below.

    STK and STKClassic share many header names so it is not advisable to enable
    both in a single build of Trilinos. Linking to both STK and STKClassic
    at the same time is not supported.

  - The new STK uses subpackages to better support inter-STK dependencies.
  
  - New TPL dependencies. The new STK now depends on Boost 1.54.0 and has been
    tested with boost 1.55.0. A subset of Boost libraries are required by STK
    instead of just Boost headers. This requires using the Trilinos TPL named
    BoostLib, rather than the Boost TPL.

    In addition the subpackage STKSearchUtil has a required dependency on GLM.
    Currently only GLM version 0.9.4.3 has been tested.

  - the old STK is now a subpackage of STK called STKClassic.

    This version is largely the same as the old STK, however, there are a few
    important differences.

      * The namespace has been changed from stk to stk_classic.
      * The package name STK is no longer used to enable this version. Instead
        STKClassic should be used.

    If you only want to use the old STK it is advisable to enable only
    STKClassic with the varibale Trilinos_ENABLE_STKClassic and not any part of
    the new STK when configuring Trilinos. This will ensure that there is no
    opportunity to inadvertantly link against any part of the new STK.

  - Old STK moved to new namespace stk_classic.
    
    The new STK retains the use of the namespace STK. To avoid potential
    conflicts STKClassic has been moved to the namespace stk_classic. There is a
    script provided to convert stk namespace to stk_classic. To use the script
    just cd into a directory containing files you'd like to update and run
    packages/stk/stk_classic/conversion_script/stk_to_stk_classic (do not copy
    the script to the directory you want to modify). The script will update any
    files in the current directory and any subdirectories of the directory you
    are modifying.

     * You should not copy the script to the directory you are modifying.
     * There is a possibility that some instances of the old namespace will be
       not be fixed correctly and may need some manual attention. However, the
       script should catch most uses of the stk namespace.
     * If you had any namespaces like <project name>stk they will be updated
       as well, however it is more likely that not all instances of such
       namespaces will not be updated properly.

  - STK Percept and Rebalance have been removed.
   
    The Percept and Rebalance capabilities have been moved out of STK. The old 
    versions are still available in STKClassic, but the new version will no
    longer support those capabilities. There will be a new Trilinos package that
    will contain the features from Percept and Rebalance in a future Trilinos
    release.

Tpetra

  - Continued work on the Kokkos refactor version of Tpetra

    We plan to replace the current "classic" version of Tpetra with a
    "Kokkos refactor" version, that uses new Kokkos for thread-parallel
    computational kernels and data structures.  The classic version
    continues to be the default, but the Kokkos refactor version is
    available via partial specialization on the Node type.  

    You may try out the Kokkos refactor version of Tpetra by doing the
    following:

      1. Enable the KokkosCore, KokkosCompat, KokkosContainers,
         KokkosLinAlg, and KokkosMpiComm (which does not require MPI)
         subpackages.

      2. Set the CMake option Tpetra_ENABLE_Kokkos_Refactor to ON.

      3. Include either Kokkos_DefaultNode.hpp or
         KokkosCompat_ClassicNodeAPI_Wrapper.hpp, if they are not already
         included by the relevant Tpetra header files.

      4. Use the appropriate Node type in the Kokkos::Compat namespace:
         KokkosCudaWrapperNode with the Kokkos::Cuda device,
         KokkosOpenMPWrapperNode with the Kokkos::OpenMP device,
         KokkosThreadsWrapperNode with the Kokkos::Threads device, or
         KokkosSerialWrapperNode with the Kokkos::SerialNode.

    We plan to deprecate the KokkosClassic namespace and its contents in
    the next minor release (scheduled for October), with the goal of
    removing it entirely by the next major release.

  - CrsMatrix: replaceGlobalValues, sumIntoGlobalValues,
    replaceLocalValues, and sumIntoLocalValues now return error codes,
    instead of throwing on invalid row or column indices

    This will facilitate thread parallelism, and porting Tpetra to use new
    Kokkos.  It also partially addresses Bug 4918 (of which Bug 5806 is a
    duplicate).  The error code tells users both whether the row index was
    valid, and the number of valid column indices.  If the return value
    equals the number of input column indices, the method succeeded.

  - CrsGraph, CrsMatrix: getLocalRowCopy now does not throw if the input
    row index is invalid; instead, it sets numEntries=0 and returns.

    This will facilitate thread parallelism, and porting Tpetra to use new
    Kokkos.  It is also semantically consistent: if the calling process
    doesn't own that row, then the calling process owns zero entries in
    that row, so it's correct to set numEntries=0 and return without
    throwing.

  - New function: Tpetra::Details::makeOptimizedColMap

  - MultiVector and Map now have full default template parameters

    Now, if you write Tpetra::MultiVector<> (empty angle brackets
    required), that sets Scalar=double.  If you write Tpetra::Map<>
    (again, empty angle brackets required), that sets LocalOrdinal=int.
    Tpetra includes a unit test for this feature.

  - New classes in Tpetra::Experimental namespace: BlockCrsMatrix,
    BlockMultiVector, and BlockVector (constant-size small blocks, with
    block size determined at run time)

  - Fixes for Bug 6139 and 6127

  - Tpetra::MatrixMarket::{writeMap, writeMapFile} can now handle an
    overlapping Map.

  - Import and Export now inherit from a common base class
    (useful for implementing communication methods)

  - Refactored and improved examples

  - CrsMatrix: fillComplete with a const graph now uses the graph's
    domain and range Maps (thus fixing an unnumbered bug, in which
    CrsMatrix was instead using the row Map for both)

  - Map now implements view semantics

    "View semantics" means that Map's copy constructor and assignment
    operator (operator=) do a shallow copy, and that empty construction is
    possible.  The new test for isOneToOne (see below) is the first Tpetra
    test that assumes view semantics of Map.

  - Map now has an isOneToOne predicate.

    isOneToOne is a collective which tests whether the Map is one to one
    (that is, whether every global index is owned by at most one process
    in the Map's communicator).

###############################################################################
#                                                                             #
# Trilinos Release 11.8 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.8 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan, Zoltan2.

Amesos2

  - Amesos2's adapter for Tpetra now caches Import and Export objects, so that it
    doesn't have to recreate them on every solve.  This fixes Bug 6011 and should
    improve performance of solves.

Belos

  - More Belos solvers now work with complex Scalar type; more now compile for
    complex Scalar type. This includes GCRODR, LSQR, RCG, and BlockGCRODR.  Not
    all of these solvers are enabled by default; some are still marked
    "experimental."

Galeri

  - Removed some instances of "using namespace std;" User code that
    inadvertantly depended on symbols in std being in the global namespace may 
    now have errors.

Ifpack

  - Removed some instances of "using namespace std;" User code that
    inadvertantly depended on symbols in std being in the global namespace may 
    now have errors.

Ifpack2

  - RILUK and Krylov may now be used as subdomain solvers in
    AdditiveSchwarz.

  - We made many improvements to RILUK and LocalFilter.  This will move
  towards fixes for a number of Ifpack2 bugs, such as 5992 and 5987.

Teuchos

  - New mode for TimeMonitor::summarize (27 Mar 2014)

    We added a new mode of calculating global statistics to
    TimeMonitor::summarize.  The new mode ignores contributions from processes
    that either do not have a particular timer, or have a hard zero for a timer. 
    This mode is off by default, meaning that the default summarize behavior is
    unchanged.

    This new mode is useful in cases where not all processes have the same timers
    and/or some timers are zero.  This can arise when multiple MPI communicators
    are in play.  A single call to summarize using a global communicator yields
    reasonable statistics for all timers.  The cost is an additional
    MPI_Allreduce.

    Consider this example:

      - proc 0 has timers T1=1.0, T2=0.5
      - proc 1 has timers         T2=1.0, T3=1.0
      - proc 2 has timers         T2=2.0, T3=0.5

    where MCW is a communicator containing 0,1,2, and MC12 is a communicator
    containing 1,2.

    Calling
    TimeMonitor::summarize(MCW, std::cout, false, true, false, Teuchos::Union)
    yields

      - min(T1)=0.0, avg(T1)=0.33, max(T1)=1.0
      - min(T2)=0.5, avg(T2)=1.17, max(T2)=2.0
      - min(T3)=0.0, avg(T3)=0.5,  max(T3)=1.0

    Calling
    TimeMonitor::summarize(MC12, std::cout, false, true, false, Teuchos::Union) 
    yields

      - min(T1)=0.0, avg(T1)=0.0,  max(T1)=0.0
      - min(T2)=1.0, avg(T2)=1.5,  max(T2)=2.0
      - min(T3)=0.5, avg(T3)=0.75, max(T3)=1.0

    While each is technically correct for the communicators given, neither by
    itself gives information that one might want, namely, averages over just the
    processes that have a timer and mins over the nonzero times.

    With the new mode, calling 
    TimeMonitor::summarize(MCW, std::cout, false, true, false, Teuchos::Union, "",
    true)  yields

      - min(T1)=1.0, avg(T1)=1.0,  max(T1)=1.0
      - min(T2)=0.5, avg(T2)=1.17, max(T2)=2.0
      - min(T3)=0.5, avg(T3)=0.75, max(T3)=1.0

  - Ptr: Added is_null() method to match RCP (23 Mar 2014)

  - MpiComm: Improved duplicate(), split(), and createSubcommunicator()
    (27 Feb 2014).

    These methods now do MPI_Comm_dup, MPI_Comm_split, resp. MPI_Comm_create, as
    one would expect.  They also do one less MPI_Bcast than before.  This is
    because messages in the new MPI_Comm (which MPI_Comm_dup, MPI_Comm_split, and
    MPI_Comm_create all create) cannot collide with messages in the old MPI_Comm,
    so there is no need for a broadcast to agree on a common tag.

Tpetra

  - BACKWARDS IMCOMPATIBLE CHANGE: MultiVector and Vector now implement
    view semantics.

    This means that the copy constructor and assignment operator (operator=) of
    both classes now do shallow copies.  This change will support gradual porting
    to the new ("Kokkos Refactor") version of Tpetra.

    We have propagated this change to other Trilinos packages that use Tpetra. 
    Please use the new createCopy nonmember function to get a new instance of
    (Multi)Vector that is a deep copy of an existing (Multi)Vector.  Also, please
    use the new nonmember function deep_copy to do a deep copy between two
    existing compatible (Multi)Vector instances.

  - Kokkos Refactor updates.

    Development continues on the Kokkos Refactor version of Tpetra.  This is a
    partial specialization of some Tpetra classes that uses the new Kokkos
    programming model.  We plan eventually to switch to this version of Tpetra and
    deprecate the old version.

    This release adds a Kokkos Refactor version of Map.  Its GID->LID and LID->GID
    conversion methods are now thread-safe and thread-scalable on the host.  It
    also has a "device object" that you can use on CUDA devices.

    The Kokkos Refactor version of MultiVector now implements "dual view"
    semantics.  This means that the Tpetra interface lets users mark either host
    or device as modified, and synchronize between host and device on demand, if
    necessary.

  - Sparse matrix-matrix multiply performance improvements.

    This release includes many performance improvements to Tpetra's sparse
    matrix-matrix multiply routine, and other supporting routines, such as
    explicit transpose, and {im,ex}portAndFillComplete.  Tpetra now has a sparse
    matrix-matrix multiply variant for implementing Jacobi smoothing of matrices. 
    This is useful for algebraic multigrid.

  - CrsMatrix: "Preserve Local Graph" defaults true (17 Mar 2014)

    In CrsMatrix, the undocumented parameter "Preserve Local Graph" now defaults
    to true.  This makes the following scenario work by default:

      1. Create a CrsMatrix A that creates and owns its graph (i.e., don't
          use the constructor that takes an RCP<const Tpetra::CrsGraph> or
          a local graph)
      2. Set an entry in the matrix A, and call fillComplete on it
      3. Create a CrsMatrix B using A's graph (obtained via
          A.getCrsGraph()), so that B has a const (a.k.a. "static") graph
      4. Change a value in B (you can't change its structure), and call
          fillComplete on B

    Before this commit, the above scenario didn't work by default.  This is
    because A's first fillComplete call would call fillLocalGraphAndMatrix, which
    by default sets the local graph to null.  As a result, from that point,
    A.getCrsGraph()->getLocalGraph() returns null, which makes B's fillComplete
    throw an exception.  The only way to make this scenario work was to set A's
    "Preserve Local Graph" parameter to true.  (It defaulted to false.)

    The idea behind this nonintuitive behavior was for the local sparse ops object
    to own all the data.  This might make sense if it is a third-party library
    that takes CSR's three arrays and copies them into its own storage format.  In
    that case, it might be a good idea to free the original three CSR arrays, in
    order to avoid duplicate storage. However, resumeFill never had a way to get
    that data back out of the local sparse ops object.  Rather than try to
    implement that, it's easier just to make "Preserve Local Graph" default to
    true.

    The possible data duplication mentioned in the previous paragraph can never
    happen with the Kokkos Refactor version of CrsMatrix, since it insists on
    controlling the matrix representation itself.  This makes the code shorter and
    easier to read, and also ensures efficient fill. That will in turn make the
    option unnecessary.

  - Many bug fixes.

  - The most important bug fixed is Bug 6069, an error in Distributor, which would
    only manifest on MPICH.  This bug fix alone is enough reason to upgrade to
    Trilinos 11.8.

PyTrilinos

  - Various changes to improve the stability and robustness of the build system. 
    Addresses some instability in PyTrilinos introduced with new 64 bit
    capabilities in Epetra.  Some compilation warnings eliminated.  SWIG version
    checks added.


Zoltan

  - Revised Scotch TPL specification in Trilinos' CMake environment to link with
    all libraries needed by Scotch v6.

  - Fixed bug in interface to ParMETIS v4 when multiple vertex weights are used.

  - Fixed bug in interface to Scotch when some processor has no vertices.

Zoltan2

  - Removed some instances of "using namespace std;" User code that
    inadvertantly depended on symbols in std being in the global namespace may 
    now have errors.

  - Simplified input Adapter classes for easier implementation by applications.
    (This change may break backward compatibility for some users.)

  - Some parameter names have changed or have been deleted:
          pqParts --> mj_parts
          parallel_part_calculation_count --> mj_concurrent_part_count
          migration_check_option --> mj_migration_option
          migration_imbalance_cut_off --> mj_minimum_migration_imbalance
          keep_part_boxes --> mj_keep_part_boxes
          recursion_depth --> mj_recursion_depth
          migration_processor_assignment_type deleted.
          migration_all_to_all_type deleted.
          migration_doMigration_type deleted.

  - Added ability to associate coordinates with matrix rows and graph vertices
    through the MatrixAdapter and GraphAdapter.

  - Improved the performance and readability of Multijagged Partitioning.

  - Added weights to graph partitioning via Scotch.

  - Changed weight specifications in input Adapters; users can no longer provide
    NULL weight arrays for uniform weights.

  - Added more robuts testing.

  - Fixed several bugs.


###############################################################################
#                                                                             #
# Trilinos Release 11.6 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.6 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan, Zoltan2.

Framework Release Notes:

  - Changed behavior of Trilinos_ENABLE_<PACKAGE>=ON to enable all
    subpackages for that package including in propogating forward dependencies.
    See updated <Project>BuildQuickRef.* document.


Amesos2

  - Added experimental support for Cholmod, a sparse Cholesky solver.

Epetra

  - Removed a few "using std::" statements from Epetra headers. These were for
    std::{string, istream, ostream, cerr, cout, endl, flush}. User code that
    inadvertently relied on such names being available in global namespace could
    see errors.  They should explicitly use std::name or place the appropriate
    "using std::name;" statement in their code.

Ifpack2

  - AdditiveSchwarz interface changes

    AdditiveSchwarz implements additive Schwarz domain decomposition.
    The class also manages and invokes the solver for each subdomain.
    That solver must implement Ifpack2::Preconditioner.

    We made two changes to AdditiveSchwarz:

      1. Subdomain solver type is now determined entirely at run time
      2. Second template parameter (LocalInverseType) is deprecated

    These changes are related to each other.  It used to be that users
    would specify the type of the subdomain solver as the second
    template parameter of AdditiveSchwarz, LocalInverseType.  The
    value of LocalInverseType had to be a concrete subclass of
    Preconditioner.  This is no longer the case.  Users now may and
    should omit AdditiveSchwarz's second template parameter.  More
    importantly, they may now specify the subdomain solver's type at
    run time.  They may do so either as a run-time parameter in the
    input ParameterList of AdditiveSchwarz, or by calling
    AdditiveSchwarz's setInnerPreconditioner() method.  See
    AdditiveSchwarz's public class documentation for details.

    AdditiveSchwarz's second template parameter has a default value of
    Ifpack2::Preconditioner.  For backwards compatibility, if users
    specify a known concrete subclass of Ifpack2::Preconditioner for
    LocalInverseType, AdditiveSchwarz will implement the previous
    behavior of creating a subdomain solver of that specific type.  In
    the next major Trilinos release, we plan to remove
    AdditiveSchwarz's second template parameter entirely.

Kokkos

  - Non-backwards compatible change: In the "Kokkos Classic" subpackage
    (everything in kokkos/classic), the "Kokkos" namespace has been
    changed to "KokkosClassic".  

    This will facilitate coexistence of Kokkos Classic with both the
    new Kokkos programming model and the new Kokkos subpackages that
    depend on it.  Coexistence will be necessary for our planned port
    of Tpetra to use new Kokkos instead of Kokkos Classic.  Kokkos
    Classic will eventually be deprecated, and Tpetra (and downstream
    packages) will use new Kokkos instead.

NOX

  - Added a Fixed-point Anderson Acceleration solver.  Unit tests exist for
    Epetra and Thyra adapters.

RTOp

  - Added better runtime support (not dependent on debug-mode builds) for
    printing the application of RTOps in parallel with the
    RTOpPack::SPMD_apply_op() functions.  This makes parallel debugging much
    easier (for example, involving Thyra).

Thyra

  - Refactored Thyra support software and Thyra/Epetra adapters to support
    zero-element processes for vector spaces and maps.  Now
    Thyra::SpmdVectorSpaceBase subclass object can have zero elements on a
    process and have everything work as it should.  The Thyra/Epetra and
    Thyra/Tpetra adapters should also be able to take Eptra and Tpetra Map
    objects that have zero elements on a process as well.  For most clients and
    subclasses, these refactorings should maintain 100% perfect backward
    compatibility except now more use cases are supported than before.  See the
    unit tests and updated class documentation for details.

Tpetra

  - Gradual port to use (new) Kokkos

    Tpetra will migrate to use the new Kokkos programming model.  The
    tpetra/src/kokkos_refactor directory contains a preview of this
    migration under development.  This will include
    backwards-incompatible changes.  For example, MultiVector and
    Vector will have view semantics, instead of their current
    container semantics.  This means that their copy constructor and
    assignment operator (operator=) will make shallow copies, instead
    of deep copies.  This will make Tpetra's semantics more consistent
    with those of Kokkos.  In order to provide deep copies, all Tpetra
    objects will get the following:

      - createCopy() method: returns a deep copy of its *this argument
      - deep_copy() nonmember function: copies the contents of one
        MultiVector into the contents of another existing MultiVector.
        This works like deep_copy() for Kokkos::View objects.

    MultiVector already has both of these functions.  Thus, in order
    to prepare for the backwards incompatible changes to Tpetra, users
    must find all uses of the copy constructor and assignment
    operator, and replace them with createCopy() resp. deep_copy().
    This will affect at least the following packages which have
    generic adapters for Tpetra::MultiVector:

      - Amesos2 (MultiVecAdapter)
      - Anasazi (MultiVecTraits)
      - Belos (MultiVecTraits)
      - Xpetra (Xpetra::TpetraMultiVector)

  - Accepted non-backwards compatible change to KokkosClassic, in which
    that subpackage changed its namespace from Kokkos to KokkosClassic.


###############################################################################
#                                                                             #
# Trilinos Release 11.4 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.4 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan, Zoltan2.

Framework Release Notes:

  - The following packages have been switched to BSD-compatible licenses:
    Didasko, Ifpack, Ifpack2, Moertel, Stokhos, Stratimikos

ForTrilinos

 - This release includes 11 modules or classes of the Epetra package.

 - This package is still in its experimental stage and is only supported on AIX.

 - Sample configure script are provided in
   Trilinos/sampleScripts/aix-fortrilinos-serial and
   Trilinos/sampleScripts/aix-fortrilinos-mpif90 for serial and mpi builds
   respectively.

 - Because of the object-oriented features used, it requires a XL Fortran
   compiler v13.1. The source code can be compiled using the xlf compiler
   option.

 - Required compiler flags for Fortran include:

     -qfixed=72 -qxlines:   deals with older Fortran source code in other
                            Trilinos packages. These flags are used for mpi
                            builds and must be specified in  the configure
                            script.

     -qxlf2003=polymorphic: allows for the use of polymorphism in the source
                            code.

     -qxlf2003=autorealloc: allows the compiler to automatically reallocate the
                            left hand side with the shape of the right hand side
                            when using allocatable variables in an assignment.

     -qfree=f90:            informs the compiler that the source code is free
                            form and  conforms to Fortran 90.

     These flags(-qfree=f90 -qxlf2003=polymorphic -qxlf2003=autorealloc) are
     hardcoded in Trilinos/packages/ForTrilinos/CMakeLists.txt

 - Required compiler flag for xlc++ include:

     -qrtti=all:            this flag should be included in the configure
                            script.

 - The project is primarily user-driven; so new interfaces are developed at the
   request of Trilinos users.


Ifpack2

  - Relaxation: Use precomputed offsets to extract diagonal

    As of this release, Tpetra::CrsMatrix has the ability to to precompute
    offsets of diagonal entries, and use them to accelerate extracting a
    copy of the diagonal. Relaxation now exploits this feature to speed up
    compute() (which extracts a copy of the diagonal of the input matrix).
    The optimization only occurs if the input matrix is a CrsMatrix (not
    just a RowMatrix) and if it has a const ("static") graph. The latter
    is necessary so that we know that the structure can't change between
    calls to compute(). (Otherwise we would have to recompute the offsets
    each time, which would be no more efficient than what it was doing
    before.)

Kokkos

  - Non-backwards compatible change: Default Kokkos/Tpetra Node type is now
    Kokkos::SerialNode 

    User expectation seems to be that the default behavior of Tpetra
    is MPI-only. These users are therefore experiencing unexpected
    performance when the default node is threaded, as is currently the
    case if any of the threading libraries (pthreads, TBB, OpenMP) are
    enabled.  Therefore, after some discussion among Kokkos/Tpetra
    developers, it was decided to change the default Kokkos node (and
    therefore, the default node used by Tpetra objects) to
    Kokkos::SerialNode. This can be overridden at configure time by
    specifying the following option to CMake when configuring
    Trilinos:

      -D KokkosClassic_DefaultNode:STRING="node_type"

    where node_type is one of the official Kokkos nodes:

      Kokkos::SerialNode    (current default)
      Kokkos::TBBNode
      Kokkos::TPINode  
      Kokkos::OpenMPNode

Mesquite

  - Added polygon support to allow reading and writing of vtk files containing
    polygons and smoothing of meshes containing polygons using the Laplacian 
    smoother.

  - Rewrote ShapeImprover wrapper determine if mesh to be optimized is
    tangled or not. If tangled, wrapper now uses a non-barrier metric and
    if not tangled, a barrier metric is used. 

  - Created a new directory structure underneath meshFiles/3D/vtk and 
    meshFiles/2D/vtk that arranges the mesh files into subdirectories 
    based on element type and whether they are tangled or untangled. 

  - Created new class MeshDomainAssoc to formally associate a Mesh instance
    with a Domain instance to verify that the mesh and domain are compatible.

  - Productionized the NonGradient solver.

  - Added new classes TMetricBarrier and TMetricNonBarrier to TMetric class to
    provide a clear division between the barrier and non-barrier target metric
    classes.  

  - Added new classes AWMetricBarrier and AWMetricNonBarrier to AWMetric class
    for same reason as the TMetric classes. 

  - Added a new error code "BARRIER_VIOLATED" to the MsgError class that is 
    issued when a barrier violation is encountered when using a barrier target
    metric class.

  - Added warning when MaxTemplate is used with any solver other than
    NonGradient.

  - Made a number of changes to the Quality Summary output to improve 
    readability and provide additional information.

PyTrilinos

  - Updated the NumPy interface to properly deal with deprecated
    code.  If PyTrilinos if compiled an older NumPy, it still works,
    but if compiled against newer versions of NumPy, the deprecated
    code is avoided, as are the warnings.

Teuchos

  - Added optional automatic global reductions of pass/fail to Teuchos Unit
    Test Harness: Prior to this feature addition, only the result on the root
    process of a parallel unit test would determine pass/fail, even if tests on
    other proesses failed.  This makes it easier to write parallel unit tests
    and results in more robust test code.  For a discussion, see Trilinos issue
    #5909. An example can be found in
    teuchos/comm/test/UnitTesting/UnitTestHarness_Parallel_UnitTests.cpp (see
    the CMakeLists.txt file for how that test is run).  NOTE: By default, no
    global reductions of pass/fail are done as to maintain perfect backward
    compatibility.

  - Added new feature to TimeMonitor: You may now enable or disable a timer
    (instance of Time) by name.  Disabled timers ignore start() and stop()
    calls; calling these methods on a disabled timer does not change its elapsed
    time or call count.  Thus, TimeMonitor's constructor and destructor have no
    effect on disabled timers. However, the disabled timers still exist, and
    TimeMonitor's summarize() and report() class methods will print statistics
    for disabled timers (using their elapsed times and call counts while
    enabled).  Enabling a timer does not reset its elapsed time or call count. 
    This feature is useful if you want to time only certain invocations of a
    particular function that has an internal timer, without modifying the
    function's source code.  For an example, see
    packages/teuchos/comm/test/Time/TimeMonitor_UnitTests.cpp, line 175
    ("TimeMonitor, enableTimer" unit test).

Thyra

  - Fixed explicit template instantation system in the generation of
    Thyra_XXX.hpp files to *not* include Thyra_XXX_def.hpp when explicit
    instantation is turned on.  The refactoring of Thyra to use subpackages some
    time ago broke the generation of Thyra_XXX.hpp files in that they were
    always including Thyra_XXX_def.hpp files.  That was bad because it increased
    compile time for client code and allowed other includes to get pulled in
    silently. Now client code that includes Thyra_XXX.hpp when explicit
    instantiation is turned on will will *not* get the include of
    Thyra_XXX_def.hpp.  This might break some downstream client code that was
    not properly including the necessary header files and was accidentally
    getting them from the Thyra_XXX_def.hpp files that were being silently
    included.  However, this technically does not break backward compatibility
    since client code should have been including the right headers all along. 
    For example, when GCC cleaned up their standard C++ header files this
    required existing C++ code to add a bunch of missing includes that should
    have been there the whole time.

Tpetra

  - Performance improvements to fillComplete (CrsGraph and CrsMatrix)

  - Performance improvements to Map's global-to-local index conversions

  - MPI performance optimizations

    Methods that perform communication between (MPI) processes do less
    communication than before.  This should improve performance,
    especially for large process counts, of the following operations:

      - Creating a Map
      - Creating an Import or Export communication plan
      - Executing an Import or Export (e.g., in a distributed sparse
        matrix-vector multiply, or in global finite element assembly)
      - Calling fillComplete() on a CrsGraph or CrsMatrix

  - Restrict a Map's communicator to processes with nonzero elements,
    and apply the result to a distributed object

    Map now has two new methods.  The first, removeEmptyProcesses(),
    returns a new Map with a new communicator, which contains only those
    processes which have a nonzero number of entries in the original Map.
    The second method, replaceCommWithSubset(), returns a new Map whose
    communicator is an arbitrary subset of processes of the original Map's
    communicator.  Distributed objects (subclasses of DistObject) also
    have a new removeEmptyProcessesInPlace() method, for applying in place
    the new Map created by calling removeEmptyProcesses() on the original
    Map over which the object was distributed.

    These methods are especially useful for algebraic multigrid.  At
    coarser levels of the multigrid hierarchy, it is helpful for
    performance to "rebalance" the matrices at those levels, so that a
    subset of processes share the elements.  This leaves the remaining
    processes without any elements.  Excluding them from the communicator
    reduces the cost of all-reduces and other communication operations
    necessary for creating the coarser levels of the hierarchy.

  - CrsMatrix: Native SOR and Gauss-Seidel kernels

    These kernels improve the performance of Ifpack2 and MueLu.
    Gauss-Seidel is a special case of SOR (Symmetric Over-Relaxation).
    See the documentation of Ifpack2::Relaxation for details on the
    algorithm, which is actually a "hybrid" of Jacobi between MPI
    processes, and SOR (or Gauss-Seidel) within an MPI process.  The
    kernels also include the "symmetric" variant (forward and backward
    sweeps) of SOR and Gauss-Seidel.

  - CrsMatrix: Precompute and reuse offsets of diagonal entries

    The (existing) one-argument verison of CrsMatrix's getLocalDiagCopy()
    method requires the following operations per row:

      1. Convert current local row index to global, using the row Map
      2. Convert global index to local column index, using the column Map
      3. Search the row for that local column index

    Precomputing the offsets of diagonal entries and reusing them skips
    all these steps.  CrsMatrix has a new method getLocalDiagOffsets() to
    precompute the offsets, and a two-argument version of
    getLocalDiagCopy() that uses the precomputed offsets.  The precomputed
    offsets are not meant to be used in any way other than to be given to
    the two-argument version of getLocalDiagCopy().  They must be
    recomputed whenever the structure of the sparse matrix changes (by
    calling insertGlobalValues() or insertLocalValues()) or is optimized
    (e.g., by calling fillComplete() for the first time).

  - CrsGraph,CrsMatrix: Added "No Nonlocal Changes" parameter to
    fillComplete()

    The fillComplete() method accepts an optional ParameterList which
    controls the behavior of fillComplete(), as opposed to behavior of the
    object in general.  "No Nonlocal Changes" is a bool parameter which is
    false by default.  Its value must be the same on all processes in the
    graph or matrix's communicator.  If the parameter is true, the caller
    asserts that no entries were inserted in nonowned rows.  This lets
    fillComplete() skip the global communication that checks whether any
    processes inserted any entries in nonowned rows.

  - Default Kokkos/Tpetra Node type is now Kokkos::SerialNode

    NOTE: This change breaks backwards compatibility.

    Users expect that Tpetra by default uses "MPI only" for parallelism,
    rather than "MPI plus threads."  These users were therefore
    experiencing unexpected performance issues when the default Kokkos
    Node type is threaded, as was the case if Trilinos' support for any of
    the threading libraries (Pthreads, TBB, OpenMP) are enabled.  Trilinos
    detects and enables support for Pthreads automatically on many
    platforms.  Therefore, after some discussion among Kokkos and Tpetra
    developers, we decided to change the default Kokkos Node type (and
    therefore, the default Node used by Tpetra objects) to
    Kokkos::SerialNode. This can be overridden at configure time by
    specifying the following option to CMake when configuring Trilinos:

    -D KokkosClassic_DefaultNode:STRING="<node-type>" 

    where <node-type> any of the official Kokkos Node types, such as the
    following:
    - Kokkos::SerialNode (current default) 
    - Kokkos::TBBNode
    - Kokkos::TPINode
    - Kokkos::OpenMPNode


###############################################################################
#                                                                             #
# Trilinos Release 11.2 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.2 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra, Zoltan, Zoltan2.

AztecOO

  - Added support for 64-bit global indices.  They can be used if 64-bit based
    Epetra maps are used.

Epetra

  - IndexBase argument for 64-bit maps is now a "long long". No change to
    32-bit maps, where it remains an "int".

NOX

  - Added example of user defined preconditioner with a JFNK forward operator to
    the thyra support.

  - Removed all usage of EpetraExt::ModelEvaluator in favor of a direct
    inhertance from the Thyra::ModelEvaluator.  The EpetraExt::ModelEvaluator is
    being deprected.

  - Added support for the Thyra Group to accept user defined preconditioners and
    Jacobian operators.

  - Merged the object code for the library noxthyra into the main nox library to
    work around a circular dependency for the pseudo-transient solver.

  - Added a pseudo-transient solver based on Thyra objects.  Still under
    development.

PyTrilinos
  - General
    - Added STK as an optional dependency of PyTrilinos
    - Added Pliris as a supported package
    - Provide better compatibility with external MPI implementations.
      Specifically, if the user were to "import mpi4py" (for example)
      prior to importing Teuchos or Epetra, then the Teuchos or Epetra
      modules will not take responsibility for calling MPI_Finalize().
    - Fixed some build errors

  - Epetra module
    - Priliminary support for Epetra64.  Ultimately, I would like the
      default behavior to be using 64-bit methods without refering to
      64-bit method names.
    - Added PyTrilnos.Epetra.FECrsMatrix InsertGlobalValues method that
      had been hidden by a %extend SWIG directive.

  - EpetraExt module
    - Gave names to EpetraExt template classes.  Using the nameless
      versions had caused problems with newer versions of SWIG.  This
      should get rid of the need for a patch distributed with
      Archlinux.
    - Added the EpetraExt::CrsMatrix_SubCopy class to
      PyTrilinos.EpetraExt.

  - NOX module
    - Improved NOX support, especially NOX.Epetra.  This should be
      largely invisible to the user, but I used to have to always import
      NOX whether the user wanted it or not, due to nested namespace
      issues.  These issues have been resolved now, and you only import
      NOX if you specifically request it.

  - Anasazi module
    - Added EpetraMultiVecAccessor base class.  Anasazi added this base
      class, and now the PyTrilinos version supports it as well.

TriUtils

  - Added support for 64-bit global indices.  They can be used if 64-bit based
    Epetra maps are used or equivalent TriUtils functions with suffix "64" are
    called.

###############################################################################
#                                                                             #
# Trilinos Release 11.0 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 11.0 general release contains 54 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards,
ShyLU*, STK, Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra,
Tpetra, TriKota, TrilinosCouplings, Trios, Triutils, Xpetra*, Zoltan, Zoltan2*.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Framework Release Notes:

  Transitioning due to removal of deprecated code:
  ---------------------------------------------------------------

  With the update from Trilinos 10.12 to 11.0, several deprecated classes,
  function, macros, and files have been removed from the Trilinos 11.0 sources. 
  If a client code was using these deprecated features and upgrades to 11.0, the
  client code will no longer build.  To ease the transition of client code to
  Trilinos 11.0, the following procedure is recommended:

  1) Get the release tarball for Trilinos 10.12.

  2) Do a build from scratch of the client application code against Trilinos
  10.12 (making sure that deprecated warnings are enabled).  Save the full build
  output to a file to be searched for deprecated warnings.

  3) Search the build output of the client code for "deprecated" warnings
  which give file names and line numbers for deprecated features.  For each
  deprecated warning or feature:

  3.a) Look at the Trilinos source code referenced in the "deprecated"
  warning and see why the feature (or file) was deprecated and what instructions
  there are for using an alternant implementation.  In many cases, the
  deprecated function or macro will be calling a non-deprecated variation.

  3.b) Change the client source code in smaller reasonable sized chucks (looping
  back to step #3.a multiple times) to removed deprecated usage and re-build and
  re-test incrementally to ensure the client code continues to build and run
  correctly.

  4) Once all deprecated code has been addressed through various iterations in
  step #3, go back to step #2 to make sure that no deprecated warnings are
  found.

  5) Rebuild the client code against Trilinos 11.0.

  For most deprecated features, the above algorithm will cleanly and safely
  facilitate the upgrade of client code to Trilinos 11.0.  If, however, the
  client code fails to build against Trilinos 11.0 in step #5 after removing all
  deprecated warnings against 10.12, then a more difficult and risky upgrade
  process may be necessary.  First, consult the release notes and tests and
  examples for the Trilinos package causing the failures.  If that is not
  helpful, email trilinos-users@software.sandia.gov for advice.

  To see a discussion of the why and how of the management of deprecated code in
  Trilinos, see Section 6.5 "Regulated Backward Compatibility: Details" in
  the TriBITS Lifecycle Model technical report:

      http://www.ornl.gov/~8vt/TribitsLifecycleModel_v1.0.pdf

  Sorry for any inconvenience this transition to Trilinos 11.0 may cause due to
  the removal of deprecated features and code.

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

Amesos2
  - Added support for Pardiso-MKL (multithreaded solver)

  - Several bug fixes

Epetra
  Added support for 64-bit global indices
  
  Epetra supports 64-bit global indices beginning with Trilinos Release 11.0
  by using the "long long" datatype. Epetra still supports 32-bit global
  indices and the interface for using them remains the same.
  
  - To construct Epetra objects for 64-bit indices, certain input arguments
    must be "long long" instead of "int". For example, compare
    
      32: Epetra_BlockMap(int NumGlobalElements, int NumMyElements,
                          const int *MyGlobalElements, ...)
      64: Epetra_BlockMap(long long NumGlobalElements, int NumMyElements,
                          const long long *MyGlobalElements, ...)

  - New member functions that return a long long value have a suffix "64". For
    example, GID64, NumGlobalNonzeros64, MaxAllGID64, etc. These functions work
    whether the underlying object is 32-bit or 64-bit based. The older
    non-suffixed functions work for 32-bit objects only.

  - New classes added for "long long" data: Epetra_LongLongVector,
    Epetra_LongLongSerialDenseVector, Epetra_LongLongSerialDenseMatrix.

  - To build Epetra and dependent packages without any 64-bit support turn on
    the CMake flag Trilinos_NO_64BIT_GLOBAL_INDICES. Default is off.

  - To enforce that a code is truly compatible with 64-bit Epetra
    turn on the CMake flag Trilinos_NO_32BIT_GLOBAL_INDICES, and fix any
    compile-time or run-time errors. Default is off.

  Epetra 64-bit support FAQ (compile problem)

  Epetra-dependent code may not compile if it relied on automatic type
  conversion to "int" from non-int types when constructing Epetra objects or
  calling certain member functions. This is because now there can be ambiguity
  due to overloading. Use explicit conversion to either "int" or "long long".

Kokkos
  - Non-backwards compatible change: row pointers for CRS objects are not longer
    size_t; instead, they are the same Ordinal type as the columns indices

  - Non-backwards compatible change: construction of Kokkos local graph objects
    requires specifying number of columns

  - KokkosArray

    - Initial release of experimental package for manycore performance-portable
      kernels using multidimensional array API to transparently swap between
      "array of structures" and "structure of arrays" as per the manycore device
      needs.

    - Proxy-application examples include hybrid parallel (MPI + KokkosArray)
      nonlinear thermal conduction finite elements and explicit dynamics finite
      elements.  These have been tested with pthreads and Cuda on the Cray XK6.

RTOp
  - Dropped deprecated code in Trilinos 10.12 (see general release notes on
    dropping deprecated code).

ShyLU
  - Initial public release for ShyLU. ShyLU is a hybrid direct-iterative
    preconditioner (solver) for general sparse linear systems, based on Schur
    complement approximation.  It uses a hybrid MPI+threads parallel execution
    model.

  - Should be used as Ifpack preconditioner (for now).

  - ShyLU should be considered *EXPERIMENTAL* code.

Teuchos
  - Dropped deprecated code in Trilinos 10.12 (see general release notes on
    dropping deprecated code).

  - Teuchos reference BLAS implementations have been corrected to mimic the
    behavior of their machine-specific counterparts.  See bugs 4262 and 5683.
    This includes fixing the interface to _GER so that the complex instantiation
    of that routine uses _GERU.  Also, _ASUM and _IAMAX were corrected to
    perform the correct calculations for complex-valued data types.

  - Fixed SerialDenseSolver class to correctly handle complex-valued data
    types.  See bug 5308.  

  - CommandLineProcessor now properly throws exceptions.  See bug 4668 and
    5387.  By default this tool throws exceptions and must recognize all the
    options it encounters on the command line.  This is enforced through the
    implementation now.  If exception throwing is disabled, then proper error
    codes will be returned to the user.

  - Filtering timer labels for global statistics and output

    The computeGlobalTimerStatistics(), report(), and summarize() class
    methods of TimeMonitor now support "filtering" timer labels.  See Bug
    5301:

    https://software.sandia.gov/bugzilla/show_bug.cgi?id=5301

    Both methods take an optional "filter" string.  If nonempty, the
    methods only print timers whose labels begin with that string.  

    This feature could be used to implement "namespaces" for timers.
    Trilinos packages may take advantage of this feature by prefixing the
    timer name with the package name.  For example: "Teuchos: Timer 1".
    Users may exploit this feature to reduce the volume of output.  The
    implementation does not compute global statistics for timers that are
    filtered out, so filtering could also reduce computation and
    communication.

  - YAML output option for timing results

    The report() class method of TimeMonitor now has a YAML output option.
    See Bug 5302:

    https://software.sandia.gov/bugzilla/show_bug.cgi?id=5302

    YAML (see yaml.org) is a recursive acronym for "YAML Ain't Markup
    Language."  It "is a human-friendly data serialization standard for
    all programming languages."  I've added YAML output on request of
    Daniel Barnette (SNL), so that timing results can serve as input data
    for his PylotDB (https://github.com/dwbarne/PYLOTDB) framework for
    database creation, management, and analysis.  

    YAML is not the default output format of report().  To specify YAML
    output, give report() a ParameterList with the "Report format"
    parameter set to "YAML".  I have provided two different variants of
    YAML output: "compact" and "spacious".  The default is "spacious".
    You may set this via the "YAML format" parameter.

Thyra
  - Dropped deprecated code in Trilinos 10.12 (see general release notes on
    dropping deprecated code).

Tpetra
  - Significant performance improvements to local sparse matrix-vector multiply
    on CPU nodes. 

  - Removed all deprecated methods.

Xpetra
  - Initial public release of Xpetra. Xpetra is a lightweight wrapper package
    that provides algorithm developers with a unified interface to the
    underlying sparse linear algebra library.

  - Epetra and Tpetra are currently supported.

  - Xpetra is used by the packages Zoltan2 and MueLu.

  - Xpetra should be considered *EXPERIMENTAL* code.

Zoltan
  Highlights are listed below; for more details, see 
  Trilinos/packages/zoltan/doc/Zoltan_html/ug_html/ug_release.html .

  -  Zoltan is now released under Trilinos' BSD license.

  -  The following Zoltan features are no longer supported in Trilinos v11:
     +  Zoltan v1 interface (as described in Zoltan include file lbi_const.h)
     +  Partitioning method OCTPART: use partitioning method HSFC instead.


  -  Hierarchical partitioning received several performance, interface and 
     testing improvements.  An easier-to-use interface has been 
     added using simple parameters (HIER_ASSIST, PLATFORM_NAME, TOPOLOGY)
     instead of callback functions; the callback function interface is still
     supported. 

  -  Memory usage in Zoltan Distributed Data Directories is improved, leading to
     faster execution times for data directories and hierarchical partitioning.

  -  Compilation with gcc 4.7 is now supported.

  -  Zoltan supports PT-Scotch v5.1.12 and ParMETIS v4, as well as some older
     versions of these TPLs. 

Zoltan2
  - Initial public release of Zoltan2.  Zoltan2 is a redesign of the
    Zoltan combinatorial scientific computing toolkit that uses templating and
    Trilinos classes for tighter integration with Trilinos.  Zoltan2 supports
    Epetra and Tpetra data structures through the Xpetra interface.


###############################################################################
#                                                                             #
# Trilinos Release 10.12 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 10.12 general release contains 51 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards, STK,
Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra, Tpetra,
TriKota, TrilinosCouplings, Trios*, Triutils, Zoltan.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

ForTrilinos

  - This package builds with three compilers: the IBM XL Fortran (xlf) compiler
    versions 13.1 and higher, the Numerical Algorithms Group Fortran (nagfor)
    compiler version 5.3 and higher, and the GNU Fortran (gfortran) compiler
    version 4.7.0 and higher.

  - The ForTrilinos interfaces have been simplified relative to their C++
    counterparts: whereas the lack of array programming support in C++
    necessitates passing array size as a separate argument, Fortran arrays carry
    such information in internal descriptors so there is no need to pass array
    sizes.

  - Sample scripts for building ForTrilinos are provided in
    Trilinos/sampleScripts.

  - Building with gfortran versions before 4.8 requires setting flags that work
    around two missing compiler features: support for final subroutines and
    support for deferred-length character components. A sample script that sets
    the aforementioned flags is in :
    Trilinos/sampleScripts/mac-fortrilinos-gcc47-openmpi-debug and
    Trilinos/sampleScripts/mac-fortrilinos-gcc47-serial for mpi and serial
    builds respectively.  Users who build with gfortran should adopt two
    practices to prevent memory leaks:
      1. Construct ForTrilinos objects using the ForTrilinos constructor
         subroutines (do not use ForTrilinos constructor functions).
      2. Manually destroy all constructed ForTrilinos objects using by
         invoking the object's "force_finalize" type-bound procedure.

  - The project is primarily user-driven; new interfaces are developed at the
    request of Trilinos users.

Kokkos

  - Major (backwards-compatible, internal) refactor of local sparse operators,
    esp. DefaultSparseOps

  - Using generic sparse kernels only on host node; CUDA nodes use CUSPARSE.
    Adaptors for Cusp are work-in-progress.

  - Added first-touch-allocation support for sparse matrices; should improve
    performance on NUMA nodes.

  - Still lots of work in progress on sparse matrix support, expected for
    Trilinos 11.0

Mesquite

  - Removed Distance From Target (DFT) based metrics and added 
    Target-Matrix Optimization Paradigm (TMOP) based metrics.

  - Fix broken patch culling functionality

  - Update for ITAPS 1.3 release candidate APIs

  - Added XYPlanarDomain type

  - Updated Histogram to a more intuitive format.

  - Added Scaled Histograms feature to QualityAssessor Summary code.

  - Significant updates to Users Guide.

  - Fixed QualityMetricTester utility class problem reported by Jason

  - fixed typo in header include guards reported by Jason Kraftcheck.

  - Fixed compiler errors using gcc/g++ 4.6 on Linux, Bug #5294

  - Fixed the errors in the MPI_DEBUG version of the check-in script on Linux.

  - Updated constructors in MsqIMeshP.*pp to match those of parent class
    MsqIMdesh.

  - Added parallel error handling to parallel Mesquite/VertexMover.

  - Fixed std::vector not being resized after the number of elements in
    it was reduced.

  - Added Windows code to replace tmp_File() function that does not work in
    Windows 7.

  - Fixed non-unique cmake global name issue.

  - Added code for Windows using srand().  Fix for bug #5351.

Teuchos

  - The current behavior of the Teuchos::XMLParameterListReader has been
    modified  to throw an exception (Teuchos::DuplicateParameterSublist) the
    event that a sublist is duplicated in an XML stream. This change is disabled
    by default in the  XMLParameterListReader class, and is enabled by calling:
    XMLParameterListReader::setAllowsDuplicateSublists( false )  This is
    configured, and thereby constitutes a non-backwards compatible change, 
    in the following encapsulating helper methods: 
        Teuchos::updateParametersFromXmlFile(...)
        Teuchos::updateParametersFromXmlFileAndBroadcast(...)
        Teuchos::getParametersFromXmlFile(...)
        Teuchos::updateParametersFromXmlString(...)
        Teuchos::getParametersFromXmlString(...)
    This change was requested by Panzer/Drekar developers, to aid in debugging
    the input of large XML programs specifying a physics application.

Tpetra

  - Major (backwards-compatible, internal) refactor to interaction between
    Tpetra::CrsGraph/CrsMatrix and their interaction  with their LocalSparseOps
    template parameter. 

  - Removed generic kernels for GPU nodes; GPU sparse kernel support now
    provided by CUSPARSE library; requires CUDA 4.1

  - Additional methods in Reduction/Transformation Interface (RTI) interface,
    examples in tpetra/examples/MultiPrec

  - Fixed major bugs in Tpetra Import/Export

  - Minor bug fixes and documenting tests

  - Numerous improvements to documentation

  - Better MatrixMarket support in tpetra/util

  - Added the ability to construct a Tpetra::Vector/MultiVector using user data
    (host-based nodes only)

  - Deprecated: fillComplete(OptimizeStorageOption) on Tpetra::CrsGraph and
    Tpetra::CrsMatrix, in favor of a ParameterList.

Trios

  - Significant changes to thread support for nessie.  
    - Implemented thread-safe version of nessie client/server... not fully
      tested.
    - Removed thread pool and threaded support from server. Assume service
      developer has their own thread pool.

  - Valgrind-detected bug fixes for IB port of NNTI. 

  - Modified xfer-service (example) to use multiple servers. 
    - Implemented two different client/partitioning schemes: round robin, block
      partition. 


###############################################################################
#                                                                             #
# Trilinos Release 10.10 Release Notes                                        #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 10.10 general release contains 50 packages: Amesos, Amesos2,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS, Shards, STK,
Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra, Tpetra,
TriKota, TrilinosCouplings, Triutils, Zoltan.

Framework Release Notes:

  - The following packages have been switched to BSD-compatible licenses:
    FEI, Globipack, Isorropia, Kokkos, LOCA, MOOCHO, NOX,
    Optika, Optipack, Piro, Tpetra.
    This brings the total number of packages with BSD-compatible licenses to 30
    (out of 50). Please see http://Trilinos.sandia.gov/license.html for more
    information about the licenses in Trilinos.

  - Force CMake to use only static third-party libraries
    Starting with Trilinos 10.8, the option TPL_FIND_SHARED_LIBS can be
    used to force the TPL system to use only static libraries.  By default,
    shared libraries can be used.  To use only static libraries, set the
    option to "OFF".

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

PyTrilinos

  - Added support for the use case when Trilinos requests a
    Teuchos::ArrayView<>.  In Python, the user can supply a NumPy array or a
    Python sequence (input arguments only) and PyTrilinos will convert it to the
    necessary ArrayView type automatically.  This currently only applies to the
    Teuchos.Comm classes, but the infrastructure is there for future needs.

  - Changed PyTrilinos string checks to accommodate older Pythons in which
    strings can only be regular strings and newer Pythons in which strings
    can be either unicode or regular strings.

  - Added experimental support for STK package Percept mesh module.


Teuchos
   - Deprecated the non-namespaced family of TEST_FOR_EXCEPTION(...) macros
     in the file Teuchos_TestForException.hpp: There are now namespaced
     versions prefixed with TEUCHOS_.


###############################################################################
#                                                                             #
# Trilinos Release 10.8 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 10.8 general release contains 50 packages: Amesos, Amesos2*,
Anasazi, AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI,
ForTrilinos, Galeri, GlobiPack, Ifpack, Ifpack2, Intrepid, Isorropia, Kokkos,
Komplex, LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen,
Phalanx, Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, SEACAS*, Shards, STK,
Stokhos, Stratimikos, Sundance, Teko, Teuchos, ThreadPool, Thyra, Tpetra,
TriKota, TrilinosCouplings, Triutils, Zoltan.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

Framework Release Notes:

  - MPI Fortran compiler wrapper search change
    Starting with Trilinos 10.8, when MPI is enabled and a specific Fortran
    compiler is not specified at configure time, the first wrapper searched for
    will be mpif90 instead of mpif77.  If a mpif90 wrapper is not found, the
    search will continue and attempt to find mpif77.  Depending on the
    underlying compilers used and the mpi configuration, a mpif90 wrapper may 
    exist, but not be functional.  In those cases, a functional Fortran compiler
    wrapper should be specified at configure time.

  - CMake export system changes:
    The CMake export system used for finding Trilinos in other CMake projects
    has had some changes to better support CMake projects. First there are now
    CMake targets for each library that is exported. This will allow easier
    handling of dependencies for libraries as all of that information is now
    stored in the CMake Target. The location of the installed *Config.cmake
    files has changed. They are no longer in the <install prefix>/include
    directory, but are instead in <install prefix>/lib/cmake/<package
    name>/<package name>Config.cmake. These paths are more like what CMake
    expects and should only require minor changes to the search path you give to
    find_package(...). You should only need to point to the install prefix where
    Trilinos was installed when using find_package now. 

More information:

Trilinos website: http://trilinos.sandia.gov

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------
Amesos2
  - Initial Public release of Amesos2. Amesos2 provides a common interface to
    different direct solver libraries from Trilinos. 

  - Supports SuperLU, SuperLU_MT and SuperLU_Dist direct solvers.

  - Supports Epetra and Tpetra matrices and mulitvectors.

  - Supports 64-bit and complex data types.

EpetraExt
  - The EpetraExt interface to Zoltan is deprecated in Trilinos v10.8 and will
    be removed in Trilinos v11.  Users of this interface should switch to the
    Isorropia package or use Zoltan directly.

Isorropia
  - New class Isorropia::Epetra::Matcher solves the
    maximum cardinality matching problem for the bipartite graph.
    This is also known as a maximum transversal, and is
    typically used to permute a sparse matrix to zero-free diagonal form. 
    The current implementation uses OpenMP and shared memory model.
    It does not work on distributed matrices.

  - Isorropia is now supported in PyTrilinos.

Kokkos
  - New multidimensional array sub-package in kokkos/array subdirectory.
    The MDArrayView<Type,Device>, MultiVectorView<Type,Device>,
    and ValueView<Type,Device> template classes manage allocated
    memory on the 'Device' and perform compile-time selection of a
    device-optimal mapping of array's multi-index space to data members.
    Includes unit tests, performance tests, and example mini-applications.

PyTrilinos
  - Improved the MPI initialization logic in Teuchos and Epetra modules.
    Previously, both modules would call MPI_Init() when they were imported
    into the python interpreter and register MPI_Finalize() with the
    atexit module (each module did perform checks before executing the
    calls in case the other module beat it to the punch).  Now, each
    module checks to see if MPI_Init() has already been called, and if so,
    it does not register MPI_Finalize() with atexit.  This way, if the
    user initializes MPI ahead of importing Teuchos or Epetra (such as
    with mpi4py, for example), then the user is responsible for
    finalization, and can assume finer control.

  - Added the Isorropia package, for partitioning Epetra objects.  This
    includes an IsorropiaVisualizer.py script.

  - This release contains a large number of internal changes mostly not
    visible to end users, except for increased stability and bug fixes.
    One big change is that C++ referenced counted pointers (via the
    Teuchos::RCP class) are now properly handled.  Fixed a couple of bugs
    in the Amesos, AztecOO and EpetraExt wrappers.  Changed the Amesos
    example scripts to follow PyTrilinos coding standards.  Put all C++
    code within the PyTrilinos namespace.  Changed C++ file names to have
    PyTrilinos_ prefix.

SEACAS

  - New in Trilinos 10.8 the SEACAS package includes the following libraries
    and applications:

  - Libraries:
     - Exodus:     database used to store and retrieve data for finite element
                   analyses
     - Nemesis:    add-on to exodus providing data for parallel finite element
                   analyses
     - Ioss:       C++ front-end to exodus library; provides a higher-level IO
                   support for finite element applications
     - Aprepro:    Can be used to embed aprepro functionality into an
                   application
     - chaco:      graph partitioning library used by nem_slice application
     - supes:      memory management, parsing, and system routines used by
                   seacas fortran applications
     - suplib:     common fortran routines used by the seacas fortran
                   applications

  - Applications:
     - algebra:    manipulate data in exodus databases using equations and
                   functions.
     - aprepro:    algebraic preprocessor; reads a file containing both
                   general text and algebraic, string, or conditional
                   expressions.  It interprets the expressions and outputs
                   them to the output along with the general text.
     - conjoin:    joins two or more Exodus databases into a single database.
                   The input databases should represent the same model
                   geometry with similar variables.
     - ejoin:      used to join two or more Exodus databases into a single
                   Exodus database. The input databases must have disjoint
                   meta and bulk data.     
     - epu:        Combines multiple Exodus databases produced by a parallel
                   application into a single Exodus database. Replaces
                   nem_join.
     - exo2mat:    translates exodus data into Matlab mat-file format.
                   Requires matlab libraries.
     - exodiff:    compares results data from 2 exodus databases.
     - exomatlab:  translates exodus global data into a matlab-readable file.
     - exotxt:     convert exodus database to text format
     - gjoin:      join 2 or more exodus databases into a single database.
                   Will combine nodes, blocks, nodesets, sidesets
     - explore:    query an exodus database.
     - mapvar:     transfer solution results from one database to another.
     - mapvar-kd:  same as mapvar with a kd-based internal search; minor other
                   differences.
     - mat2exo:    convert a Matlab mat-file into an exodus database. Requires
                   Matlab libraries.
     - nem_slice:  generate a decomposition of a finite element mesh for use
                   in parallel analyses
     - nem_spread: use the nem_slice output to spread a finite element mesh
                   into multiple files; one per processor for use in parallel
                   analyses.
     - txtexo:     convert a exotxt-formatted text file into an exodus
                   database.

   - Scripts:
     - decomp:     drives nem_slice and nem_spread to decompose a mesh for use
                   in parallel analyses.

Teuchos
  - Added automatic stack tracing info for exception messages, segfaults, and
    aborts.  Thanks to the work of Ondrej Certik we now have built-in support
    for generating stack traces when using g++ when uncaught exceptions are
    encountered or when a segfault or about occurs.  See the Doxygen
    documentation for more details for how your project can take advantage of
    this feature.

Zoltan
  - Added new recoloring capability to Zoltan coloring algorithms, providing
    lower numbers of colors at small additional cost.


  - Updated Zoltan to allow use of third-party libraries ParMETIS versions 3.1
    and 4.0 and Scotch versions up to 5.1.12.

  - Updated Zoltan's hierarchical partitioning for greater efficiency.

  - Fixed bug in autotools installation of Zoltan; file Zoltan_config.h is now
    installed in the specified include directory.

  - Fixed Fortran90 interface issues that caused compilation and run-time
    problems with gcc 4.5 and later when compiler optimization was enabled.

  - Added support for 64-bit builds of Zoltan, enabling operation on more
    than 2B objects. See details for building in the Zoltan User's Guide.


###############################################################################
#                                                                             #
# Trilinos Release 10.6 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 10.6 general release contains 48 packages: Amesos, Anasazi,
AztecOO, Belos, CTrilinos, Didasko, Epetra, EpetraExt, FEI, ForTrilinos^,
Galeri, GlobiPack, Ifpack, Ifpack2**, Intrepid, Isorropia, Kokkos, Komplex,
LOCA, Mesquite, ML, Moertel, MOOCHO, NOX, Optika, OptiPack, Pamgen, Phalanx,
Piro, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, Shards, STK, Stokhos,
Stratimikos, Sundance, Teko*, Teuchos, ThreadPool, Thyra, Tpetra, TriKota,
TrilinosCouplings, Triutils, Zoltan.

(* denotes package is being released externally as a part of Trilinos for the
first time.)

(** Ifpack2 was previously released under the name "Tifpack".)

(^ ForTrilinos was added to the external release for Trilinos 10.4.1.)

Framework Release Notes:

  - New to Trilinos 10.6 is a small functional example to be used as a template
    for applications that use CMake and want to build against an installed
    version of Trilinos.  The application automatically pulls required
    information from Trilinos including compilers, include paths, and library
    names (in the correct order).  The example can be found in
    demos/buildAgainstTrilinos.

More information:

Trilinos website: http://trilinos.sandia.gov

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

Anasazi

  - Better support for Tpetra in Anasazi.

-------------------------------------------------------------------------------

Belos

  - Minor changes in Belos/Tpetra adaptors.

-------------------------------------------------------------------------------

ForTrilinos

 - This release includes 11 modules or classes of the Epetra package.

 - This package is still in its experimental stage and is only supported on AIX.

 - Sample configure script are provided in
   Trilinos/sampleScripts/aix-fortrilinos-serial and
   Trilinos/sampleScripts/aix-fortrilinos-mpif90 for serial and mpi builds
   respectively.
 
 - Because of the object-oriented features used, it requires a XL Fortran
   compiler v13.1. The source code can be compiled using the xlf compiler
   option.

 - Required compiler flags for Fortran include:
   -qfixed=72 -qxlines:   deals with older Fortran source code in other Trilinos
                          packages. These flags are used for mpi builds and must
                          be specified in the configure script.
   -qxlf2003=polymorphic: allows for the use of polymorphism in the source code.
   -qxlf2003=autorealloc: allows the compiler to automatically reallocate the
                          left hand side with the shape of the right hand side
                          when using allocatable variables in an assignment.
   -qfree=f90:            informs the compiler that the source code is free form
                          and conforms to Fortran 90.

   These flags(-qfree=f90 -qxlf2003=polymorphic -qxlf2003=autorealloc) are
   hardcoded in Trilinos/packages/ForTrilinos/CMakeLists.txt

 - Required compiler flag for xlc++ include:
   -qrtti=all:            this flag should be included in the configure script.

 - The project is primarily user-driven; so new interfaces are developed at the
   request of Trilinos users.

-------------------------------------------------------------------------------
  
Kokkos

  Significant internal/external changes to both the Kokkos Node API and the
  Kokkos Linear Algebra library. Most of these changes are centered around 
  CrsGraph and CrsMatrix and their kernels. Some exciting developments
  regarding  sparse mat-vec on multi-core/GPUs did not make it in this release;
  look for more development in 10.6.1.

  - Lots of additional documentation, testing and examples in Kokkos.

  - Improved debugging in Kokkos Node API

  - Added isHostNode static bool to all Kokkos nodes (false for ThrustGPUNode)

  - Imported select Teuchos memory management classes/methods into the Kokkos
    namespace.

  - Minor bug fixes, warnings addressed.

  Changes breaking backwards compatibility:
  - Kokkos CRS classes (i.e., CrsGraph and CrsMatrix) are now templated on the 
    sparse kernel operator, allowing specialization of the class data 
    according to the implementation of the kernel.

  - Kokkos CRS classes now contain host-allocated memory, instead of
    node-allocated memory. This means that use of these buffers by the node
    will, in general, require a copy. 

-------------------------------------------------------------------------------
  
Meros
  
  - Meros has been removed from the release. Teko provides replacement
    Functionality.

-------------------------------------------------------------------------------

ML

  User-Level functionality changes
  
  - Modifications to ML to allow user to specify the use of CRS storage.
    Certain methods in Ifpack are much more efficient if the matrix is in
    Epetra_CRS_Matrix mode.  This new switch tells ML to store things as CSR
    instead of MSR (it's still the default).

  - Modifying MLMEX so the solve mode can (optionally) return iteration
    counts.  Only works in ML_Epetra mode, not MLAPI.

  - Adding ML support for Ifpack-SuperLU(ILUTP) smoother.

  - Adding a face-based least-squares finite element (LSFEM)
    preconditioner to ML.  See TrilinosCouplings for an example.

  - Adding MLMEX matlab interface to the cmake build system.

  Internal changes, output changes and bugfixes

  - Fixed a bug in ML_Project_Coordinates so that it works where
    dim != numPDEs. For using auxillary aggregation for problems like linear
    elasticity.

  - Fixing a memory leak in ML_Init_Aux.

  - Adding additional output to ML. This focuses on the IFPACK/SORa
    smoother as well as improved RefMaxwell output.

  - Modifications to RefMaxwell to allow direct use of Ifpack (rather
    than via MLP).

  - Removing ML's dependence on ZoltanTpl.

  - Changed the output of the IFPACK-ILU smoother so that it is more
    informative.

-------------------------------------------------------------------------------

Teko

  Teko is a library for implementation of blocked and segregated preconditioners
  in the context of iterative solvers for linear systems. This includes a high
  level interface for manipulating block operators and creating inverse
  operators using solver and preconditioning capabilities in Trilinos. In
  addition, utilities are provided that decompose large Epetra_CrsMatrix objects
  into physically meaningful sub blocks.  A brief over view of the capabilities
  built in Teko is

  - Generic preconditioners operations: Additive, multiplicative, Neumann
    series, block Gauss-Seidel, block Jacobi, and 2x2 block LU factorization

  - Manipulation of abstract linear operators: implicit/explicit operator
    addition and multiplication, constructing an approximate inverse operator
    using Trilinos preconditioner and solver technology

  - Deconstruction of Epetra_CrsMatrix into is physical components

  - Parameter list driven interface for constructing preconditioners

  NOTE: A word of caution.  The interfaces in Teko are still maturing and may
  change substantially in the future. 

-------------------------------------------------------------------------------

Tpetra

  Significant internal changes in Tpetra for this release, mostly centered
  around the CrsMatrix class. Lots of new features centering around
  multi-core/GPUs did not make it in this release; look for more development in
  10.6.1.

  - Lots of additional documentation, testing and examples in Tpetra.

  - Imported select Teuchos memory management classes/methods into the Tpetra
    namespace.

  - Updates to the Anasazi/Tpetra adaptors for efficiency, node-awareness and
    debugging.

  - Minor bug fixes, warnings addressed.

  Changes breaking backwards compatibility:
  - Tpetra CRS objects (i.e., CrsGraph and CrsMatrix) are required to be
    "fill-active" in order to be modified. Furthermore, they are required to be
    "fill-complete" in order to call multiply/solve. The transition between
    these states is mediated by the methods fillComplete() and resumeFill(). 
    This will only effect users that modify a matrix after calling
    fillComplete().

  Newly deprecated functionality:
  - CrsGraph/CrsMatrix persisting views of graph and matrix data are now
    deprecated. New, non-persisting versions of these are provided.


###############################################################################
#                                                                             #
# Trilinos Release 10.4 Release Notes                                         #
#                                                                             #
###############################################################################
 
Overview:
 
The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The Trilinos 10.4 general release contains 47 packages: Amesos, Anasazi,
AztecOO, Belos, CTrilinos*, Didasko, Epetra, EpetraExt, FEI, Galeri, GlobiPack*,
Ifpack, Intrepid, Isorropia, Kokkos, Komplex, LOCA, Meros, Mesquite, ML,
Moertel, MOOCHO, NOX, Optika, OptiPack*, Pamgen, Phalanx, Piro, Pliris,
PyTrilinos, RTOp, Rythmos, Sacado, Shards, STK, Stokhos, Stratimikos, Sundance,
Teuchos, ThreadPool, Thyra, Tifpack, Tpetra, TriKota, TrilinosCouplings,
Triutils, Zoltan.

(* denotes packages that are being released externally as a part of Trilinos
for the first time.)

Framework Release Notes:

- Reduction of user CMake cache variables with CMake GUI 2.8.2 and newer

  Release 2.8.2 of the CMake QT-based GUI now has separate check boxes for
  "Grouped" and "Advanced" CMake cache variables.  This, together with changes
  in the Trilinos CMake files to only set defaults for cache variables for
  Trilinos packages that are actually enabled, has made the manipulation of
  CMake variables much more manageable for Trilinos users.

- Export Makefile support added
  
  Similar to the find Trilinos capability for cmake-aware projects an export
  Makefile capability is being officially released. Each package will have a
  Makefile.export.<package> created for it that can be included in the Makefiles
  for a project to give it access to information about what was built, which
  compilers were used etc. Please see
  commonTools/importing/README.Export_Makefile for more information and
  instructions on how to use it.

- Find Trilinos files moved

  The installed files for finding Trilinos in a cmake-aware project have moved 
  to the include directory instead of being at the top level. It was felt that
  installing into the top level could be confusing when the install path was a
  system path. 

 
More information:
 
Trilinos website: http://trilinos.sandia.gov
 
===============================================================================
 
Package Release Notes:
 
-------------------------------------------------------------------------------

Anasazi

- Brought Anasazi/Tpetra adaptors back online (experimental)

-------------------------------------------------------------------------------

Belos

- Replaced non-const MultiVecTraits::CloneView(MV) with explicit
  MultiVecTraits::CloneViewNonConst(MV).

  This is a non-backwards-compatible change to Belos::MultiVecTraits, requiring
  changes through Belos solver, solver managers, and orthomanagers.  The result
  is that it is much harder to accidentally create a non-const view when a const
  view is sufficient. To do so requires CloneViewNonConst() be called
  explicitly, all such calls being manually invoked during this refactorization.

- Efficiency improvements for Belos/Tpetra adaptors (experimental)

-------------------------------------------------------------------------------

Kokkos

Sparse ops:
- Combined DefaultSparseSolve and DefaultSparseMultiply into DefaultSparseOps
- Added new traits class, DefaultKernels, to specify default sparse and default
  block sparse objects
- Added new classes supporting Tpetra::VbrMatrix

MultiVector ops:
- Some methods were missing "inline" specifier. This could (should?) improve
  performance for TPINode.

CUDANodeMemoryModel:
- Support for tracing/profiling data movement between host and GPU

-------------------------------------------------------------------------------

phdMesh

- phdMesh has been removed from the release. STK provides replacement
  functionality.

-------------------------------------------------------------------------------

PyTrilinos

- The logic for determining the prefix for the install directory for PyTrilinos
  has been improved.  Highest precedence is given to the configure variable
  PyTrilinos_INSTALL_PREFIX.  If this is not set by the user, then next highest
  precedence is given to CMAKE_INSTALL_PREFIX.  If this has not been set by the
  user, then the prefix of the python interpreter that PyTrilinos is being
  compiled against is used.

-------------------------------------------------------------------------------

Sundance

- To compile Sundance explicit instantiation is now required. To enable explicit
  instantiation you will need to set Trilinos_ENABLE_EXPLICIT_INSTANTIATION to
  ON when configuring.

-------------------------------------------------------------------------------

Teuchos

Known breaks in backward compatibility:

- Changed direct constructors for ArrayRCP to take (lowerOffset, size) instead
  of (lowerOffset, upperOffset) to be consistent with the nonmember constructors
  like arcp(...) and ArrayView.  This was done to make these constructors
  consistent with the non-member constructors.  As long clients were using the
  nonmember constructors this will not break backward compatibility.  However,
  if clients are using the direct constructors, upperOffset becomes size which
  means that the size will actually become one less with the upperOffset
  becoming one less.  This will therefore not result in memory access errors but
  will result in exceptions being thrown when accessing the real last element.
  Given the confusion that having different arguments caused (that I got caught
  with too) and the inherent safety in the change, I think this break with
  strict backward compatibility is well worth the (minor) problems it might
  cause to users.

- Removed define of TEUCHOS_PRIVIATE_DELETE_NOT_SUPPORTED for _AIX.  The macro
  TEUCHOS_PRIVIATE_DELETE_NOT_SUPPORTED was designed to be used only internally
  within Teuchos (and perhaps other parts of Trilinos) but at some point all use
  of this macro was removed (apparently in all of Trilinos).  If client code
  used this macro for their own purposes, then this change will break client
  code when _AIX is defined.  However, it seems unlikely that there will be such
  client code around.

-------------------------------------------------------------------------------

Tpetra

- Kokkos and Tpetra are in the middle of a medium refactor in order to better
  support GPU and multicore nodes. Therefore, there has been some potential
  regression in performance for GPU nodes; and some known issues regarding
  multi-core CPU performance (especially  on NUMA platforms) have not been
  addressed. The rest of this refactor is likely to happen  in the development
  branch, and will not be released until 10.6 (estimated for September 2010). 

  Users that require access to this code should contact a Trilinos developer
  regarding access to the development branch repository. 

Improvements to doxygen documentation.
- Added ifdefs to support profiling/tracing of host-to-device memory transfers 
  These are enable via cmake options
  -D Kokkos_CUDA_NODE_MEMORY_PROFILING:BOOL=ON
  -D Kokkos_CUDA_NODE_MEMORY_TRACE:BOOL=ON

VBR capability (experimental)
- Added variable-block row matrix (VbrMatrix) and underlying support classes
  (BlockMap, BlockMultiVector)
- Added power method example of VBR classes

CrsMatrix:
- Now implements DisbObject, allowing import/export capability with CrsMatrix
  objects (experimental)
- Combined LocalMatVec and LocalMatSolve objects into a single template
  parameter (non BC). This required changes to CrsMatrixMultplyOp and
  CrsMatrixSolveOp operators as well (non BC).
- Access default for this type via Kokkos::DefaultKernels
- Removed cached views of object data. this should have no effect on CPU-based
  nodes, but will result in slower performance for GPU-based nodes. This
  regression is a result of the release happening mid-refactor. It will not be
  addressed in the 10.4.x sequence.
- Bug fixes regarding complex cases involving user-specified column maps and
  graphs.

DistObject interface:
- Added createViews(), releaseViews() methods to allow host-based objects to
  temporarily cache views of host data during import/export procedure

Map: 
- Added new non-member constructors: createContigMap(),
  createWeightedContigMap(), createUniformContigMap()
- Fixed some bugs regarding use of unsigned Ordinal types
- Fixed MPI-stalling bug in getRemoteIndexList()

MultiVector:
- Added view methods offsetView() and offsetViewNonConst() to create a
  MultiVector view of a subset of rows
- Added non-member constructor Tpetra::createMultiVector(map,numVecs)

Vector:
- Added non-member constructor Tpetra::createVector(map)

Tpetra I/O:
- Added Galeri-type methods for generating pedagogical matrices (currently, only
  3D Laplacian)

External adaptors (experiemental)
- Efficiency improvements for Belos/Tpetra adaptors
- Brought Anasazi/Tpetra adaptors back online



###############################################################################
#                                                                             #
# Trilinos Release 10.2 Release Notes                                         #
#                                                                             #
###############################################################################
 
Overview:
 
The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.
 
Packages:
 
The Trilinos 10.2 general release contains 45 packages: Amesos, Anasazi,
AztecOO, Belos, Didasko, Epetra, EpetraExt, FEI, Galeri, Ifpack, Intrepid,
Isorropia, Kokkos, Komplex, LOCA, Meros, Mesquite*, ML, Moertel, MOOCHO, NOX, 
Optika*, Pamgen, Phalanx, PhdMesh, Piro*, Pliris, PyTrilinos, RTOp, Rythmos,
Sacado, Shards, STK*, Stokhos^, Stratimikos, Sundace, Teuchos, ThreadPool,
Thyra, Tifpack*, Tpetra, TriKota*, TrilinosCouplings, Triutils, and Zoltan.
 
(* denotes packages that are being released externally as a part of Trilinos
for the first time.)

(^ Stokhos was not included in the initial 10.0 release, but was released
externally starting in Trilinos 10.0.3.)
 
The limited release contains an additional 2 packages, CTrilinos and
ForTrilinos, that are scheduled for external release in the near future.

Framework Release Notes:
 
- Find Trilinos capability for CMake-aware client codes
 
CMake-aware client codes can now use the Find Trilinos capability to find
Trilinos and its libraries in a more natural way.  The Find Trilinos
capability has two variants, one for a build tree (the actual directory where
Trilinos was built) and one for an installation tree.  It works by enabling the
CMake function "FIND_PACKAGE(Trilinos PATHS <paths to search>)" to find a copy
of Trilinos.  Many useful variables are available that can be used in your
CMake files.  For example, the fully constructed link line for linking against
Trilinos libraries is available, as well as the path(s) to Trilinos header
files, and the set of compilers and compiler flags used to build Trilinos. This
capability can also be used to find individual Trilinos packages. For more
information on how to use this capability and what variables are available,
please see the documentation in Trilinos/cmake/README.Find_Trilinos or at
http://trilinos.sandia.gov/Finding_Trilinos.txt.

- Trilinos_ENABLE_ALL_OPTIONAL_PACKAGES is ON by default

The default for Trilinos_ENABLE_ALL_OPTIONAL_PACKAGES was changed from OFF to
ON.  Optional package features will now be available by default, however it
will take more time to compile and link Trilinos in most cases.  If optional
features are not of interest, the variable can be set to OFF manually.

 
More information:
 
Trilinos website: http://trilinos.sandia.gov
 
===============================================================================
 
Package Release Notes:
 
-------------------------------------------------------------------------------

Epetra

Epetra provides initial support for OpenMP.  The Epetra_CrsMatrix class
supports OpenMP parallel sparse matrix-vector multiply and sparse
matrix-multivector multiply (the Multiply() and Apply() methods).  The
Epetra_MultiVector and Epetra_Vector classes support OpenMP parallelism for all
computational functions.  The Epetra_CrsMatrix, Epetra_MultiVector,
Epetra_Vector and Epetra_CrsGraph classes supports parallel data placement
(when not constrained by user-provided data) to improve non-uniform memory
access.

-------------------------------------------------------------------------------

Mesquite*

MESQUITE is a linkable software library that applies a variety of node-movement
algorithms to improve the quality and/or adapt a given mesh. Mesquite is
designed to address the following commonly encountered mesh optimization
problems:

    * Untangle meshes,
    * Provide local size control,
    * Improve angles, orthogonality, and skew,
    * Increase minimum edge-lengths for increased time-steps,
    * Improve mesh smoothness,
    * Perform anisotropic smoothing,
    * Improve surface meshes, adapt to surface curvature,
    * Improve hybrid meshes (including pyramids & wedges),
    * Smooth meshes with hanging nodes,
    * Maintain quality of moving and/or deforming meshes,
    * Perform ALE rezoning,
    * Improve mesh quality on and near boundaries,
    * Improve transitions across internal boundaries,
    * Align meshes with vector fields, and
    * R-adapt meshes to solutions using error estimates.

Mesquite improves surface or volume meshes which are structured, unstructured,
hybrid, or non-comformal. A variety of element types are permitted. Mesquite is
designed to be as efficient as possible so that large meshes can be improved.

-------------------------------------------------------------------------------
 
Optika*
 
The Optika package provides trilinos users with easy access to GUI input
methods for their programs. Optika gives developers the tools they need to
quickly obtain information from their users, while still implementing a robust
GUI.  The general work flow of a program utilizing the Optika package goes
something like this:
 
   1. Determine what inputs are needed from the user
   2. Create a list specifying these inputs
   3. Execute the GUI with the getInput() function to obtain the inputs
      specified in step 2
   4. Proceed with the rest of the program with the given user inputs
 
An alternate work flow is also available.  In this work flow, the developer
specifies a custom function along with the inputs.  When the GUI is executed,
it stays active for the entire duration of the program.  Every time the user
clicks a button, the custom function is called with the current input values.
 
If you think Optika might be useful for your application, we encourage you to
take a look at some of the examples included with the Optika package.
 
-------------------------------------------------------------------------------

Piro*

Piro is a new package in Trilinos 10.2 that is striving to be the single
unifying layer above all nonlinear solver, time integration, optimization,
and UQ packages. Piro wraps the typical usage of NOX, LOCA,
and Rythmos solvers, for applications that present themselves
using the EpetraExt::ModelEvaluator abstraction. These solvers
all inherit from the same base class, which can in turn be fed
into the analysis packages. Piro wraps the black-box mode
usage of optimization and UQ analysis libraries, including Moocho
and Dakota, under a single call that takes a Thyra::ModelEvaluator
and a parameter list.

-------------------------------------------------------------------------------

PyTrilinos

PyTrilinos.NOX notes:

  Updated the wrappers so that the Jacobian can be specified using the
  NOX.Epetra.Interface.Jacobian base class.  To get this to work
  required that the directorin %typemaps for Epetra_Operator used by
  NOX.Epetra.Interface.Jacobian be updated to downcast the
  Epetra_Operator argument to our best guess at the derived class.
  Such a downcast had already been written for the EpetraExt
  ModelEvaluator, so code was moved around to make it more generally
  accessible.  This uncovered a memory management bug that took some
  time to track down, but the result now is much more stable memory
  management all-around.

  The new capability is demonstrated in serial in example script
  exNOX_2DSim.

-------------------------------------------------------------------------------

STK*

STK (Sierra Toolkit) contains capabilities intended to support massively
parallel multi-physics computations on dynamically changing unstructured
meshes. The primary capability in the STK package is the mesh database which
supports creation and manipulation of mesh entities (nodes, elements etc) and
computational field data defined on the mesh. STK also contains sub-libraries
that support geometric proximity searches, assembly into linear-systems, etc.

-------------------------------------------------------------------------------

Teuchos

(*) Default debug enable of RCP node tracing: Setting Teuchos_ENABLE_DEBUG=ON
now sets Teuchos_ENABLE_DEBUG_RCP_NODE_TRACING=ON by default.  This is a more
strict type of checking that will catch more errors.

(*) Known breaks in backward compatibility:

- The type Teuchos_Ordinal has been changed from int to ptrdiff_t by default.
On 64 bit machines, this will be 'long int' instead of 'int'.  This can be
changed back to int by configuring with -DTeuchos_ORDINAL_TYPE:STRING=int.

- The size_type typedef in Teuchos::Array has been changed from size_t to
Teuchos_Ordinal which is now ptrdiff_t, a signed integer which is *not* int on
a 64 bit platform.  See the argument for this in Bugzilla bug 4253.

- The size_type typedef in Teuchos::ArrayView and Teuchos::ArrayRCP has also
been changed to Teuchos_Ordinal to be consistent with Teuchos::Array.

- The size_type typedef in Teuchos::Range1D has been changed to
Teuchos_Ordinal.

- Removed Teuchos_exit.h with the TEUCHOS_EXIT(...) macros.  These were a bad
idea and where never used in Trilinos.  Hopefully no external Trilinos user
made use of these either.

- Non-member functions related to RCPNode tracing have been collected into a
new static class Teuchos::RCPNodeTracer.  Given that no user code should ever
be calling these functions in production code this should not affect most
users.

-------------------------------------------------------------------------------

Thyra

(*) Added deprecated warnings.  When using GCC, the g++ compiler will now emit
warning messages when client code uses deprecated types and functions.  The
developer of the client code should change over to use non-deprecated code
because the deprecated code will be removed when Trilinos 11.0 is put out.

(*) Deprecated the use of all raw C++ pointers.  All use of raw C++ pointers
is now deprecated in all functions and classes.  For the most part, if a raw
pointer was being used in function foo( ..., T*, ... ) the new function
prototype is foo( ..., const Ptr<T>&, ... ).  A good way to convert from a raw
C++ reference T& to an Ptr<T> object is to use Teuchos::outArg(...) or
Teuchos::inOutArg(...) depending on the nature of the argument.  To convert
from a RCP<T> to a Ptr<T> use the function RCP<T>::ptr().

(*) Refactored the Thyra::LinearOp[WithSolve]Base interfaces:

- LinearOpBase: Removed double templating.  Now requires overriding
opSupportedImpl(...) and applyImpl(...).  This is a break in strict backward
compatibility but making these functions pure virtual was needed to make sure
the interface is implemented correctly.  Interface should be 100% backward
compatible for external clients through deprecated functions.

- LinearOpWithSolve: Removed double templating.  Now requires overriding
solveImpl(...).  Interface should be 100% backward compatible for external
clients through deprecated functions.  Also, the new solve[Impl](...) 
function only takes a single SolveCriteria object and only returns a single
SolveStatus object to simplify usage.

- Removed SingleScalarXXX node classes.  There is not need for these anymore
now that double templating is gone.

- Removed SingleRhsXXX node subclasses.  These classes just make the
inheritance hierarchy deeper without providing a lot of value.

- ExampleTridiag[Serial,Spmd]LinearOp subdclasses refactored to directly
inherit from LinearOpDefaultBase and use the Detached[Spmd]VectorView classes
to get vector data.

(*) Explicit template instantiation: Thyra now fully supports explicit
template instantiation.  This results in code that builds much faster and can
avoid internal compiler error on some platforms.

-------------------------------------------------------------------------------
 
Tifpack*

Tifpack contains preconditioners that operate on the templated linear-algebra
objects provided by the Tpetra package. Tifpack preconditioners support using
the same integer and floating-point types that are provided by Tpetra,
including extended-precision types from the QD library. Tifpack is intended to
replace the capabilities in the existing Trilinos Ifpack package, but only a
few preconditioners are supported for this initial release. Preconditioners
provided at this time are Relaxation (Jacobi, Gauss-Seidel, Symmetric
Gauss-Seidel), Chebyshev, ILUT and RILUK.

-------------------------------------------------------------------------------

Tpetra/Kokkos

-  Experimental support for CPU multi-threading on *nix via ThreadPool
   (Pthreads) and cross-platform via Intel TBB.

-  Experimental support for NVIDIA GPUs via CUDA/Thrust.

-  Support for explicit instantiation of Tpetra classes for scalars float,
   double, complex<float> and complex<double>.

-  Numerous bug fixes and performance improvements.

-  Minor interface changes to improve accessibility and extend functionality.

-------------------------------------------------------------------------------

TriKota*

TriKota is a new package in Trilinos 10.2. TriKota is a convenience package
that builds the Dakota framework underneath Trilinos as if it were another
Trilinos package. Dakota contains a wide array of algorithms for optimization
and UQ. TriKota provides adaptors between the Trilinos (ModelEvaluator)
interface to the Dakota interface, and wraps the typical library-mode usage of
Dakota in a convenience class and some simple example problems. Information on
the capabilities of the Dakota framework can seen at:
http://www.cs.sandia.gov/dakota/index.html.

-------------------------------------------------------------------------------

Zoltan v3.3

-  Added a local ordering method based on Hilbert Space-Filling Curves
   for ordering data within a processor to improve cache performance.

-  Simplified Zoltan_Order interface.

-  Added an example that uses Zoltan's migration functions.

-  Added the capability to test a new mesh partitioning model in zdrive
   using hypergraph partitioning.

-  Applied several code and documentation bug fixes.

-------------------------------------------------------------------------------

###############################################################################
#                                                                             #
# Trilinos Release 10.0 Release Notes                                         #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling
technologies within an object-oriented software framework for the solution of
large-scale, complex multi-physics engineering and scientific problems.

Packages:

The version 10.0 general release contains 38 packages: Amesos, Anasazi,
AztecOO, Belos, Didasko, Epetra, EpetraExt, FEI, Galeri, Ifpack, Intrepid*,
Isorropia, Kokkos, Komplex, LOCA, Meros, ML, Moertel, MOOCHO, NOX, Pamgen,
Phalanx, PhdMesh, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, Shards*,
Stratimikos, Sundace, Teuchos, ThreadPool, Thyra, Tpetra*, TrilinosCouplings,
Triutils, and Zoltan.

(* denotes packages that are being released externally as a part of Trilinos
for the first time.)

The limited release contains an additional 8 packages that may be available in
special situations by request. These are: CTrilinos, ITAPS, ForTrilinos,
Globipack, Optika, Optipack, Stokhos, and TriKota.

CMake Build System:

Trilinos has switched to a CMake build system from an Autotools build system
for the 10.0 release.  Instructions for building with cmake are available
from the Trilinos homepage: http://trilinos.sandia.gov.  General information
about CMake, as well as installation binaries and CMake source code are 
available from the CMake homepage: http://www.cmake.org.

Windows Support:

Beginning with the 10.0 release, many Trilinos packages now support the
Windows platform.  Support for additional packages is planned for the near
future.  Windows binary installers will also be available for Trilinos 10.0.
A list of packages that do not support the Windows platform is included below
in the "Known issues" section.

More information:

Trilinos website: http://trilinos.sandia.gov

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

Amesos

Amesos includes the KLU and Paraklete solvers.  Paraklete works only in
32-bit mode at this time.

Third-party direct solvers accessible via the CMake build system include:

(*) MUMPS
(*) UMFPACK
(*) Scalapack
(*) SuperLU
(*) SuperLUDist (requires ParMETIS to be enabled as well)

-------------------------------------------------------------------------------

Didasko

Examples have been added for the Tpetra package, as well as for the Hypre
and Euclid interfaces that were added to Ifpack and EpetraExt.

-------------------------------------------------------------------------------

EpetraExt

EpetraExt now supports the use of the scalable solver package Hypre from
Lawrence Livermore National Laboratory as a preconditioner with Trilinos
solvers.  This support includes use of the native Hypre data structures,
without copying, allowing current Hypre users to seamlessly integrate Trilinos
and Hypre capabilities.

-------------------------------------------------------------------------------

Ifpack

New interfaces to third party parallel ILU/ILUT solvers in the form of
Hypre/Euclid and HIPS have been added to IFPACK.  The former provides parallel
classical ILU and the latter provides a parallel multilevel ILUT capability.
Unlike IFPACK's existing ILU/ILUT capability, these packages preserve off-core
entries in the matrix.  This makes them especially useful for multicore
architectures.

-------------------------------------------------------------------------------

Isorropia

- New support for geometric partitioning (RCB, RIB, HSFC) via
  Epetra_MultiVector.
- Improved support for parallel Jacobian matrix coloring.
- Isorropia now uses its own parameters, separate from Zoltan
  parameters. Please see the package release notes for details.

-------------------------------------------------------------------------------

MOOCHO

(*) MS Windows support with MS Visual C++: Several tests fail in strange ways
and therefore MOOCHO must be considered not to work for this platform for this
release.

-------------------------------------------------------------------------------

Stokhos (internal release only)

Stokhos is a Trilinos package for applying intrusive stochastic Galerkin
uncertainty quantification methods to nonlinear dynamical systems, primarily
stochastic partial differential equations.

Stokhos supports generating stochastic residual coefficients using automatic
differentiation with Sacado and forming and solving stochastic Galerkin linear
systems and nonlinear systems using Epetra and the EpetraExt::ModelEvaluator.

Stokhos can make use of the Fortran UQ Toolkit of Debusschere et al for
generating residual coefficients using Taylor series and time integration
methods, and can leverage Dakota for sparse-grid quadrature.

Stokhos is primarily developed and maintained by Eric Phipps with significant
contributions by Bert Debusschere, Omar Knio, Chris Miller, and Habib Najm.

-------------------------------------------------------------------------------

Stratimikos

(*) Support for newer Belos solvers has not been added yet.

-------------------------------------------------------------------------------

Teuchos

(*) Breaks in backward compatibility:

- The raw pointer T* argument in Teuchos::set_extra_data(...) has been
changed to Teuchos::Ptr<T>&.  This requires that you replace:

    Teuchos::set_extra_data(data, dataName, &rcpObj);

with:

    Teuchos::set_extra_data(data, dataName, Teuchos::outArg(rcpObj));

-------------------------------------------------------------------------------

Thyra

(*) MS Windows support with MS Visual C++:

- Thyra complex support and float support are disabled by default.
The complex-related code just did not work correctly and there was not
time to track down the problem.

- Several of the tests showed excessive diffs for this platform so their
tolerance was loosened.

(*) Partial refactoring of code to use safe memory management classes

-------------------------------------------------------------------------------

Zoltan

Features:

* New interface to Scotch and PT-Scotch parallel graph partitioning algorithms.

* Simplified interface to graph ordering and coloring algorithms.

* Automated symmetrization of graphs for graph partitioning, coloring and
  ordering. (See parameters GRAPH_SYMMETRIZE and GRAPH_SYM_WEIGHT in the Scotch
  and ParMETIS graph packages.)

* Improved function Zoltan_LB_Eval returns more information about a
  decomposition to users.

* Improved examples showing Zoltan usage in C and C++ are included in
  zoltan/example.

* Improved support for builds under autotools, including builds of Zoltan's F90
  interface.

* New support for CMake builds and testing through Trilinos; builds of Zoltan's
  F90 interface are included.

* Improved integration into Isorropia partitioners for Trilinos' Epetra
  classes.

Backward compatibility:

* Interfaces to Zoltan_Color, Zoltan_Order and Zoltan_LB_Eval have changed.

* The Zoltan native build environment, while still distributed, will no longer
  be supported. Users should use the autotools or CMake systems. Builds of the
  Zoltan F90 interface are supported in both autotools and CMake.

-------------------------------------------------------------------------------

Known issues in Release 10.0:

* Several packages do not yet support the Windows platform.  Packages that
  do not yet support the Windows platform will not be enabled with the 
  Trilinos_ENABLE_ALL_PACKAGES, Trilinos_ENABLE_ALL_OPTIONAL_PACKAGES,
  Trilinos_ENABLE_ALL_FORWARD_DEP_PACKAGES, OR
  Trilinos_ENABLE_SECONDARY_STABLE_CODE options.  Non-supported packages
  among external release packages currently include: Anasazi, FEI, MOOCHO,
  Pamgen, Phalanx, Phdmesh, PyTrilinos, Sundance, and Tpetra.

* Building with MPI on Windows is not thoroughly tested.  There are some
  issues that need to be resolved.  Improved Windows MPI support will 
  be added to an upcoming minor release.

* g95 0.91 on OSX is known to produce a configure failure.  Consider using
  gfortran, or disabling Fortran support with Trilinos_ENABLE_Fortran=OFF.
  Most, not all, Trilinos packages can be built with Fortran support
  disabled.

-------------------------------------------------------------------------------

###############################################################################
#                                                                             #
# Trilinos Release 9.0 Release Notes                                          #
#                                                                             #
###############################################################################

Overview:

The Trilinos Project is an effort to develop algorithms and enabling 
technologies within an object-oriented software framework for the solution of 
large-scale, complex multi-physics engineering and scientific problems. All 
packages are self-contained, with the Trilinos top layer providing a common 
look-and-feel and infrastructure.

Packages:

The version 9.0 general release contains 37 packages: Amesos, Anasazi, Aztecoo,
Belos, Didasko, Epetra, Epetraext, Fei*, Galeri, Ifpack, Isorropia, Kokkos,
Komplex, Loca, Meros, ML, Moertel, Moocho, New_Package, NOX, Pamgen*, Phalanx*,
PhdMesh*, Pliris, PyTrilinos, RTOp, Rythmos, Sacado, Stratimikos,
Sundance*, Teuchos, ThreadPool*, Thyra, Trilinoscouplings, Triutils,
WebTrilinos, and Zoltan*

(* denotes packages that are being released as a part of Trilinos for the
first time.)

The limited release contains an additional 4 packages that are available in
special situations by request. These are: Claps, Intrepid, RBGen, and Tpetra.

More information:

Trilinos website: http://trilinos.sandia.gov


===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

Amesos

(*) Amesos now includes Paraklete version 0.3.

(*) Amesos 2.4 in Trilinos 9.0 is compatible with Tim Davis' SuiteSparse
    version 3.0.0 (not the latest version).

(*) Known bug: Paraklete does not currently work on 64-bit machines.

-------------------------------------------------------------------------------

Anasazi

(*) The Anasazi package released in Trilinos 9.0 includes a new type of
    eigensolver.

(*) The IRTR solvers are implicit versions of the Riemannian Trust-Region
    eigensolvers (Absil, Baker, Gallivan 2007).

(*) Two implementations are provided, which balance computation/memory
    trade-offs via the ability to disable caching of operator applications.

-------------------------------------------------------------------------------

Epetra

Epetra support for PETSc matrices: The Epetra_PETScAIJMatrix class is a
lightweight wrapper class for encapsulating PETSc serial and parallel AIJ
matrices. Its intended audience is PETSc users who would like to build and
apply Trilinos preconditioners and solvers. This class derives from the
Epetra_RowMatrix class.

-------------------------------------------------------------------------------

Isorropia

Isorropia has expanded its scope from partitioning and load-balancing to
include other algorithms for combinatorial scientific computing. The primary
focus is still on partitioning and load-balancing of matrices and vectors.
Version 3.0 includes a significant code refactoring compared to earlier
versions to improve efficiency and robustness.

(*) Isorropia now depends on Zoltan, which is available as a package in
    Trilinos 9.0.  (Zoltan is automatically enabled by Isorropia.)

(*) The default partitioning method for sparse matrices is Zoltan's hypergraph
    partitioner, which is significantly better than the internal method.

(*) New features: Graph/matrix coloring and graph/matrix ordering (nested
    dissection).

(*) Redesign of the class structure to support new features. An
    Isorropia::Operator is the parent class of Partitioner, Colorer, and
    Orderer.

(*) Significant improvement in the efficiency (run time and memory usage) of
    redistributing Epetra matrices due to improved memory allocation.

(*) New redistribute_reverse() method in the Redistributor to support moving
    vectors back and forth between two distributions.

(*) When redistributing Epetra matrices, improved default choices for the maps.
    The call to FillComplete() is now optional, allowing the application to
    supply its own range and domain maps.

(*) Several minor changes in interface to enforce more consistent naming
    schemes, but version 3.0 is fully backwards compatible.

-------------------------------------------------------------------------------

Komplex

The Komplex package includes a new class that provide equivalent real
formulation capabilities to Epetra users called Komplex_LinearProblem.This is
the newest capability and should be used if at all possible.
Komplex_LinearProblem constructs an Epetra_LinearProblem from existing matrix
and coefficient data. A real matrix of twice the dimension of the original
complex-valued problem is explicitly constructed as an Epetra_CrsMatrix. Given
this matrix and the user-supplied RHS (and possibly an initial guess), the
Komplex_LinearProblem object is ready for use with any Trilinos solver and
preconditioner.

-------------------------------------------------------------------------------

ML

(*) New support for PETSc smoothers in the case when the fine grid matrix is
    really a PETSc data structure.  This is meant to be used in conjunction
    with the Epetra_PETScAIJMatrix class.

(*) New use of MPI subcommunicators for direct solves with KLU on the coarsest
    level.  This will mainly impact large scale simulations (>1K processors).

(*) New restart capability to ensure behavior can be reproduced exactly from
    solve to solve.

(*) New interfaces to Zoltan's hypergraph repartitioning algorithms.

-------------------------------------------------------------------------------

MOOCHO

Mostly minor changes which include:

(*) Added response-only DiagonalQuadraticResponseOnlyOpt exampled based on an
    EpetraExt::ModelEvaluator.  This is to show users how to run MOOCHO on an
    unconstrained problem in parallel.

(*) Cleaned out some junk

-------------------------------------------------------------------------------

Phalanx

Phalanx is a local field evaluation kernel specifically designed for general
partial differential equation solvers.  The main goal of Phalanx is to
decompose a complex problem into a number of simpler problems with managed
dependencies to support rapid development and extensibility of the PDE code.
Through the use of template metaprogramming concepts, Phalanx supports
arbitrary user defined data types and evaluation types.  This allows for
unprecedented flexibility for direct integration with user applications and
provides extensive support for embedded technology such as automatic
differentiation for sensitivity analysis and uncertainty quantification.

-------------------------------------------------------------------------------

RTOp

Major refactoring of all code.

(*) All interfaces in rtop/src/interfaces are now "memory safe" using Teuchos
    memory management classes

(*) Support code in rtop/src/support has been significantly changed to remove
    duplication and bloat, provide for memory safely, and make it infinitely
    easier to create simple RTOp subclasses.

(*) All of the concrete RTOp classes in rtop/src/ops_lib have been updated.

(*) All of the simpler RTOps now use a simple set of macros and provide good
    examples for users on how to create their own RTOp classes.  This includes
    very detailed unit tests for all of the code.

(*) Old MPI junk that was not needed anymore was removed.

(*) Removed SUNDIAL RTOp subclasses since these are not being used and there
    was no unit tests for them.

With few exceptions, all changes should be backward compatible for clients of
the RTOpPack::RTOpT abstract interface (search for "deprecated" comments).

-------------------------------------------------------------------------------

Stratimikos

Mostly minor changes which include:

(*) Changed the name of Thyra::DefaultRealLinearSolverBuilder to
    Stratimikos::DefaultLinearSolverBuilder.

(*) Added some better unit tests, especially for adjoint solves.

-------------------------------------------------------------------------------

Teuchos

The Teuchos package released in Trilinos 9.0 has some additional tools to
assist users and developers with memory management and unit testing:

(*) Memory Management Classes:  The suite of debug-checking memory management
    classes has been extended to include the Ptr, ArrayView, and Tuple classes.
    Together with the existing classes RCP, ArrayRCP, and Array, these form a
    complete memory management system to replace all raw pointers to single
    objects and contiguous arrays of value-type objects in all
    application-level code.  For a few details on how these should be used, see:

     http://www.cs.sandia.gov/~rabartl/ThyraCodingGuideLines.pdf

(*) xUnit-like Unit Testing Infrastructure:  Full featured support for native
    unit testing has been developed.  See examples in teuchos/test/UnitTest.

-------------------------------------------------------------------------------

Thyra

(*) Added new templated Thyra::DefaultSerialDenseLinearOp[WithSolve]Factory
    subclasses to allow use of LAPACK for solving linear systems using
    Thyra::MultiVector objects as input.  This was mostly just to allow for
    better, more independent unit tests.

(*) Some refactorings to replace raw C++ pointers with safe Teuchos memory
    management classes (but a lot of work still needs to be done here)

(*) Removed the SUNDIALS RTOp wrappers since they no longer exist in RTOp

(*) Changed from Thyra::ETransp to Thyra::EOpTransp to avoid doxygen conflicts
    with Teuchos::ETransp.  A backward-compatible typedef to Thyra::ETransp
    still exists to not break existing external code.

With few exceptions, all changes should be backward compatible
(search for "deprecated" comments).

-------------------------------------------------------------------------------

Zoltan

The Zoltan Toolkit provides critical data-management services to a wide range
of parallel applications.  Zoltan includes many utilities needed by
unstructured and/or adaptive parallel applications. These utilities include

  (*) a suite of dynamic load-balancing and parallel partitioning tools
      (including geometric, hypergraph-based and graph-based algorithms) that
      distribute data over sets of processors for balanced computation
      with low interprocessor communication costs,
  (*) data migration tools that simplify movement of data to new parts,
  (*) parallel graph/matrix ordering algorithms for fill-reducing matrix
      ordering, including interfaces to PT-Scotch (LaBRI/INRIA-Bordeaux) and
      ParMETIS (U. Minnesota),
  (*) parallel graph coloring including distance-1 and distance-2 coloring,
  (*) distributed data directories that efficiently locate off-processor data,
      and
  (*) an unstructured communication package that greatly simplifies
      interprocessor communication.

Zoltan's native interface is object-oriented and easy-to-use;
it enables Zoltan to be used by a wide range of different applications.
Zoltan is designed to be flexible and extensible, so different algorithms
can be used, compared and added easily.
Zoltan has been used in particle simulations, finite element methods with
adaptive mesh refinement, linear solvers and preconditioners, circuit
simulations, crash simulations and contact detection, and
biological cell simulations.

The Zoltan toolkit was first released in 2001; this release is Zoltan v3.1.
New features in Zoltan v3.1 include
  (*) Graph/Matrix ordering interface to PT-Scotch, a high-quality graph
      ordering and partitioning library from LaBRI/INRIA-Bordeaux;
  (*) New matrix ordering interface that returns ordering information such as
      permutations and separators to the application;
  (*) New hypergraph partitioning options for inexpensively refining
      partitions;
  (*) Robustness improvements to Zoltan's parallel hypergraph partitioner and
      repartitioner;
  (*) New Autotools build environment;
  (*) Serial, non-MPI builds enabled through the Autotools build environment;
      and
  (*) Tight integration with the Trilinos project, including Trilinos package
      Isorropia, a matrix-based interface to Zoltan.

Many applications use both Zoltan and Trilinos.  Zoltan's
inclusion in Trilinos simplifies the configuration and build process for
those applications.  It also enables tighter coupling between Trilinos
packages that use Zoltan, such as the Isorropia package of Epetra-based
interfaces to Zoltan's partitioning, ordering and coloring capabilities.

Zoltan can still be built as a stand-alone toolkit separate from Trilinos,
as backward compatibility with previous Zoltan releases has been maintained.

Please visit the Zoltan Home Page (http://www.cs.sandia.gov/Zoltan) for
more information on Zoltan.

-------------------------------------------------------------------------------

###############################################################################
#                                                                             #
# Trilinos Release 8.0 Release Notes                                          #
#                                                                             #
###############################################################################

Overview:

Trilinos is a collection of compatible software packages that support parallel 
linear algebra computations, solution of linear, non-linear and eigen systems 
of equations and related capabilities. The majority of packages are written in 
C++ using object-oriented techniques. All packages are self-contained, with the 
Trilinos top layer providing a common look-and-feel and infrastructure. 

Packages:

The version 8.0 general release contains 30 packages: Amesos, Anasazi, AztecOO,
Belos, Didasko, Epetra, EpetraExt, Galeri, IFPACK, Isorropia, Kokkos, Komplex,
LOCA, Meros, ML, Moertel, MOOCHO, New_Package, NOX, Pliris, PyTrilinos, RTOp,
Rythmos, Sacado, Stratimikos, Teuchos, Thyra, Triutils, TrilinosCouplings, and
WebTrilinos.

The limited release contains an additional 2 packages that are available in 
special situations by request. These are: Claps and Tpetra.

In addition to many new features across most packages, Trilinos Release 8.0
contains 3 packages that are being released for the first time:

- Belos (Next-generation iterative solvers)
- Sacado (Automatic differentiation)
- TrilinosCouplings (Select trilinos package interfaces)

Package-specific features for these new packages, as well as many of
the other packages are listed below.

More information:

Trilinos website: http://trilinos.sandia.gov

===============================================================================

New Make Targets

Trilinos now supports a large set of make targets.  Prior to Trilinos 8.0,
"make" built libraries, tests, and examples.  Starting with Trilinos 8.0,
"make" builds only libraries.  Tests can be compiled using "make tests", and
examples using "make examples".  To build libraries, tests, and examples, the
"make everything" make target can be used.  Below is a listing of new and
modified make targets that will be most useful to users:

make - Builds just the libraries
make install - Installs just the libraries
make examples - Makes just the examples (assumes libraries are built)
make install-examples - Install the examples (assumes libraries are installed)
make tests - Makes just the tests (assumes libraries are built)
make everything - Builds libraries, tests, and examples
make install-everything - Installs libraries and examples

===============================================================================

Shared Libraries

- There is now rudimentary, experimental support for shared libraries
  under Linux and Mac OS X.  Shared versions of Trilinos libraries are
  now required for the PyTrilinos package, so this is where the shared
  libraries are built.  However, it is not necessary to enable the
  PyTrilinos package to build the shared libraries.  Also, shared
  libraries are built for ALL enabled packages, not just those with
  python interfaces.  To enable shared libraries without enabling
  PyTrilinos, use the configuration option

    --enable-shared

  Note that the build system for building shared libraries employs
  python, so this must be installed.  However, the other PyTrilinos
  prerequisites -- swig and numpy -- are not required for building
  shared libraries.  The resulting shared libraries are stored in your
  build directory in the sub-directory

    packages/PyTrilinos/shared

  and are installed in the same directory in which the static
  libraries are installed.  Note that these shared libraries are
  considered EXPERIMENTAL.  Only those shared libraries that are
  linked to PyTrilinos extension modules get tested.  The other shared
  libraries might possibly have unresolved symbols.  Please report any
  problems.

- To get shared libraries to work, it may be necessary to manually add
  position-independent code options to the compiler flag variables.
  This is not necessary on Mac OS X or some flavors of Linux, because
  position-independent code is the default.  However, on those Linux
  versions for which this is not the default, and on 64-bit systems,
  you will need to add these compiler options.  For example, if the
  proper option for your compiler for position-independent code is
  "-fPIC", then your configuration invocation should include

    FFLAGS=-fPIC CFLAGS=-fPIC CXXFLAGS=-fPIC

  There is a standing feature request that this be done automatically,
  but it has not been implemented yet.

===============================================================================

Package Release Notes:

-------------------------------------------------------------------------------

Amesos

- KLU and BTF have been upgraded to version 1.0.

-------------------------------------------------------------------------------

Belos

The Trilinos 8.0 release will contain the first public release of the Belos
iterative linear solver package.  Belos provides next-generation iterative
linear solvers and a powerful linear solver developer framework.  This
framework includes

- Abstract interfaces to linear algebra allowing the user to leverage any
  existing investment in their description of matrices and vectors.  Linear
  algebra adapters are included for Epetra and Thyra.

- Abstract interfaces to orthogonalization; implementations of iterated
  classical Gram-Schmidt (ICGS), classical Gram-Schmidt with a DGKS correction
  step, and iterated modified Gram-Schmidt (IMGS) are included.

- Abstract interfaces to iteration kernels; implementations of conjugate
  gradient (CG), block CG, block GMRES, pseudo-block GMRES, block flexible
  GMRES, and GCRO-DR iterations are included.

- Powerful solver managers are provided for solving a linear system using CG
  or block CG, GMRES or block GMRES with restarting, pseudo-block GMRES for
  performing single-vector GMRES simultaneously on multiple right-hand sides,
  and a single-vector recycled Krylov method (GCRO-DR).

- Basic linear problem class is provided for the user to define a
  unpreconditioned or preconditioned (left, right, two-sided) linear system for
  Belos to solve.

- Many examples for solving unpreconditioned, preconditioned linear systems
  with one or multiple right-hand sides using all the Belos solver managers.

-------------------------------------------------------------------------------

Epetra

- Epetra contains a new class called Epetra_VbrRowMatrix that completely
  supports the use of an existing Epetra_VbrMatrix object via the
  Epetra_RowMatrix interface. This new class addresses the fact that it is
  impossible to fully support Epetra_RowMatrix directly with Epetra_VbrMatrix
  (having Epetra_VbrMatrix inherit from Epetra_RowMatrix), so this new class
  should be used.

-------------------------------------------------------------------------------

Moocho

- Miscellaneous improvements for Thyra support.

-------------------------------------------------------------------------------

Pliris

- A problem with a large number of multiple Right Hand Sides has been addressed
  and a fix implemented.

-------------------------------------------------------------------------------

PyTrilinos

- PyTrilinos is now a single, self-contained package again.  For the
  most part, this affects developers more than users, with one
  exception.  The PyTrilinos package is enabled with the configuration
  option

    --enable-pytrilinos

  rather than the previous option, --enable-python, which had the
  effect of enabling python support within each package that provided
  wrappers.  Individual PyTrilinos package wrappers can be enabled or
  disabled with

    --enable-pytrilinos-package
    --disable-pytrilinos-package

  where "package" refers to a specific Trilinos package.

-------------------------------------------------------------------------------

Sacado

Sacado is a set of automatic differentiation tools for C++ applications. It
provides templated classes for forward, reverse and Taylor mode automatic
differentiation.

Sacado contains several basic AD classes:

  * Forward mode AD with the number of derivative components chosen at
    run-time: Sacado::Fad::DFad (most flexible)
  * Forward mode AD with the number of derivative components chosen at
    compile-time: Sacado::Fad::SFad (most efficient)
  * Forward mode AD with the maximum number of derivative components chosen
    at compile-time but actual number used chosen at run-time:
    Sacado::Fad::SLFad (sits between Sacado::Fad::DFad and Sacado::Fad::SFad
    in flexibility and efficiency)
  * Reverse mode: Sacado::Rad::ADvar
  * High-order univariate Taylor polynomials: Sacado::Tay::Taylor

-------------------------------------------------------------------------------

Stratimikos

- New Belos wrappers (Belos released for first time in Trilinos 8.0)

-------------------------------------------------------------------------------

Teuchos

- Name change from Teuchos::RefCountPtr to Teuchos::RCP

  The name of the class Teuchos::RefCountPtr has been changed to Teuchos::RCP
  and the file Teuchos_RefCountPtr.hpp is not Teuchos_RCP.hpp.  You can update
  all of you C++ code automatically and safely using the script:

    Trilinos/packages/teuchos/refactoring/change-RefCountPtr-to-RCP-20070619.sh

  Please see the header of this script for instructions.

  If you choose not to refactor your code (e.g. by running the above script on
  it) then you can take your chances and just include the backward
  compatibility file Teuchos_RefCountPtr.hpp.  However, this is *not*
  recommended because this file uses a terrible macro that is dangerous to
  have.

- Improved parameter validation support 

-------------------------------------------------------------------------------

Thyra

- Improved support for implicit linear operators with object labels and other
  improvements

- Various miscellaneous improvements and additions

-------------------------------------------------------------------------------

TrilinosCouplings

TrilinosCouplings is a new package that was created as a place to put select
interfaces between Trilinos packages.  The code for the Trilinos 8.0 release
was all taken from existing packages.  Currently there is code for interfaces
between Ifpack and ML, and ML and NOX.

-------------------------------------------------------------------------------

The following packages did not report any significant feature updates for
Trilinos 8.0:

  Anasazi, Aztecoo, Didasko, EpetraExt, Galeri, Ifpack, Isorropia, Kokkos,
  Komplex, LOCA, Meros, ML, Moertel, New_Package, NOX, RTOp, Rythmos,
  TriUtils, WebTrilinos

===============================================================================

Known Issues

- Sacado does not build on the Sun platform with no known workaround.  See
  bugzilla bug 3586 for more information.

- The test for TrilinosCouplings is currently not functioning.  Changes need to
  be made to the configuration for the package to fix this issue.  We plan to
  address this in one of the first release updates.  On many machines this test
  will fail in mpi, in other cases, the test will simply output a message and
  exit.

- We are aware of a number of other minor, platform-specific test failures:

    Linux (mpi):
        Anasazi             BlockDavidson_test.exe (12 processors)
        PyTrilinos          exMLAPI_Simple.p
        PyTrilinos          exMLAPI_Smoother.py
        PyTrilinos          testML_Preconditioner.py
        TrilinosCouplings   ml_nox_1Delasticity_example.exe
    Linux (serial):
        Belos               gcrodr_hb.exe
        PyTrilinos          exAztecOO_RowMatrix.py
        PyTrilinos          exNOX_1Dfem.py
        Rythmos             basicExample_amesos.exe
    Mac (mpi):
        Meros               testEpetraThyra.exe
        ML                  ml_user_smoothing.exe
    Mac (serial):
        Meros               testEpetraThyra.exe


###############################################################################
#                                                                             #
# Trilinos Release 7.0 Release Notes                                          #
#                                                                             #
###############################################################################

Overview:

Trilinos is a collection of compatible software packages that support parallel 
linear algebra computations, solution of linear, non-linear and eigen systems 
of equations and related capabilities. The majority of packages are written in 
C++ using object-oriented techniques. All packages are self-contained, with the 
Trilinos top layer providing a common look-and-feel and infrastructure. 

Packages:

The version 7.0 general release contains 27 packages: Amesos, Anasazi, AztecOO, 
Didasko, Epetra, EpetraExt, Galeri, IFPACK, Isorropia, Kokkos, Komplex, LOCA,
Meros, Moertel, MOOCHO, ML, New_Package, NOX, Pliris, PyTrilinos, RTOp,
Rythmos, Stratimikos, Teuchos, Thyra, Triutils, and WebTrilinos.

The limited release contains an additional 5 packages that are available in 
special situations by request. These are: Belos, Capo, Claps, Jpetra, and
Tpetra.

In addition to many new features across most packages, Trilinos Release 7.0
contains nine packages that are being released for the first time:

- Galeri (distributed linear system generation)
- Isorropia (repartitioning and rebalancing)
- Meros (segregated preconditioning)
- Moertel (Mortar methods)
- MOOCHO (Multifunctional Object-Oriented arCHitecture for Optimization)
- RTOp (reduction/transformation operators)
- Rythmos (transient integrator for ordinary differential equations and
  differential-algebraic equations)
- Stratimikos (unified set of Thyra-based wrappers to linear solver and
  preconditioner capabilities)
- WebTrilinos (web-based interface to some Trilinos packages - must be set up
  on a user's server/machine)

Package-specific features for these new packages, as well as many of
the other packages are listed below.

More information:

Trilinos website: http://software.sandia.gov/trilinos 

===============================================================================

External Package Capability

The "external" Trilinos package makes it easy add additional packages that are
external to Trilinos to the Trilinos build process.  Users who develop
additional capabilities on top of and outside of Trilinos may find this tool
useful for simplifying their Trilinos interface.  Packages that utilize this
tool can easily be added to a user's existing set of Trilinos packages.

Instructions for using the external package capability can be found in the
Trilinos tarball in packages/external/README or on the web at
http://software.sandia.gov/trilinos/external.html.

===============================================================================

Amesos

- Cleaned the MUMPS interface. Improved memory management by using smart
  pointers. Dropped the not-so-well-tested single-precision MUMPS. Improved
  passing of CNTL and ICNTL through the parameter list.

- Increases the performances of the UMFPACK interface by a factor of at least
  2. This means that the time requires by the Amesos wrappers is reduced by
  2 -- the time required by UMFPACK still is unaffected.

- Added to (almost) all classes profiling to evaluate how much time is spent
  in the amesos wrappers (that is, without considering any of the time spent
  in the called solver). This time is printed on screen when PrintTiming() is
  called.

Amesos/Thyra adapters:

What’s New:

- Timing and output tracing:  The Teuchos::TimeMonitor class has been
  incorporated to time the various factorization and solve operations and
  produce profiler-like output.  In addition, the Teuchos::VerboseObject
  interface is now supported which allows some informational outputting to be
  sent to a configurable output stream.

Known issues:

- Incomplete parameter validation and inconsistent use of parameter lists:
  Currently, parameters not specified in the input parameter list are not
  appended with the default values and all parameters and sublists are not
  fully validated.  This is an issue that needs to be resolved in the core
  Amesos source code.

-------------------------------------------------------------------------------

Anasazi

In Trilinos Release 7.0, the Anasazi eigensolver framework has been
considerably refactored to provide simpler user interfaces as well as
powerful eigensolver developer interfaces.

- This release provides simpler user interfaces, called solver managers,
  for three eigensolvers:  block Davidson, block Krylov-Schur, and
  locally-optimal block preconditioned conjugate gradient (LOBPCG).

- Powerful lower-level interfaces are provided for each eigensolver,
  enabling the expert user to specialize their own solver manager.

- Status test mechanisms have been incorporated into the Anasazi framework
  to give the user and solver manager the flexibility to direct the behavior
  of the eigensolver.

- The Anasazi::OrthoManager provides the eigensolver with an abstract
  interface to orthogonalization and orthonormalization.  This enables the
  user to specialize their own orthogonalization/orthonormalization if those
  already provided in Anasazi (CGS w/ iterative refinement or SVQB) are not
  sufficient.
   
- Interfaces to linear algebra are provided through the templated traits
  classes:  Anasazi::MultiVecTraits and Anasazi::OperatorTraits.  These
  classes have template specializations for Epetra and Thyra.  Testing
  functionality is also provided for user-written template specializations
  via the Anasazi::TestMultiVecTraits() and Anasazi::TestOperatorTraits()
  functions.

- All Trilinos web documentation and Didasko tutorial have been updated to
  reflect the changes in the Anasazi framework.

-------------------------------------------------------------------------------

AztecOO 3.5

- Additional scaling capabilities.

- Improved I/O control.

- Numerous small "hardening" changes.

AztecOO/Thyra Adapters:

What’s New:

- Timing and output tracing:  The Teuchos::TimeMonitor class has been
  incorporated to time the various setup and solve operations and produce
  profiler-like output.  In addition, the Teuchos::VerboseObject interface is
  now supported which allows some informational outputting to be sent to a
  configurable output.

- Acceptance of external preconditioner factory object:  The AztecOO/Thyra
  adapters now except an external preconditioner factory object to create
  preconditioners.  This allows Ifpack, ML, and Meros preconditioners to all be
  used in a seamless way.  Any other compatible preconditioner can also be
  supported as well.

- General Thyra operator support: Any general Thyra linear operator can now be
  supported including implementations based on product vector spaces.  To be
  effective, an appropriate preconditioner factory must also be set to create a
  preconditioner.  This is used in Meros to allow AztecOO to be used with the
  segregated block preconditioners.

-------------------------------------------------------------------------------

Didasko

- No significant changes.

-------------------------------------------------------------------------------

Epetra 3.5

- New Epetra_BasicRowMatrix class: Facilitates easy development of
  user-defined adapters for the Epetra_RowMatrix interface.  Greatly reduces
  the number of methods that must be be implemented.

- New Epetra_JadMatrix class (which supercedes Epetra_JadOperator).  This
  classes accepts an existing Epetra_RowMatrix object and creates an
  Epetra_JadMatrix object.  The Epetra_JadMatrix object uses the so-called
  jagged diagonal data structure to store the sparsematrix coefficients in a
  format especially suitable for vector processors.  Once constructed, the
  JadMatrix object can be used with any Trilinos package that requires an
  Epetra_RowMatrix or Epetra_Operator object.  This implementation also
  contains special Cray compiler directives (_Pragma "ivdep") to force optimal
  vectorization.

- New Epetra_InvOperator class.  A simple class that interprets an existing
  Epetra_Operator as an inverse operator.

- New method for Epetra Map and BlockMap objects to cheaply test if a map
  has 1-to-1 (uniquely-owned) global IDs:  This method facilitates easy
  testing for whether or not a particular map can be used as an input
  argument to functions that require the map to have uniquely-owned global
  IDs.

- New function called Create_OneToOne_Map in Epetra_Util namespace that
  creates an Epetra_Map with unique global IDs from an existing Epetra_Map
  that may or may not have unique global IDs.

- New function called Create_OneToOne_BlockMap in Epetra_Util namespace that
  creates an Epetra_BlockMap with unique global IDs from an existing
  Epetra_BlockMap that may or may not have unique global IDs.

- New function called Create_Root_Map in Epetra_Util namespace that creates
  an Epetra_Map from an existing Epetra_Map such that all global IDs are
  collected to the specified root processor and all other processors own
  no global IDs.

- New method to compute the Frobenius norm of an Epetra_CrsMatrix or
  Epetra_VbrMatrix object.

- Debugging code in Epetra_CrsMatrix to support detailed printing of
  intermediate matrix-vector multiplication information.  This code is
  compiled if  EPETRA_CRS_MATRIX_TRACE_DUMP_MULTIPLY is defined at compile
  time.

Epetra/Thyra adapters:

What’s New:

- Refactored for new SPMD classes:  The “fake” Epetra/Thyra adapters have been
  updated for the new Thyra SPMD support software.  The names of the conversion
  functions in Thyra_EpetraThyraWrappers.hpp have also be simplified.

-------------------------------------------------------------------------------

EpetraExt 3.5

- New class EpetraExt_ProductOperator: Supports implicit composition of
  multiple Epetra_Operator objects to act as a single operator.

- New class EpetraExt_BlockCrsMatrix: Supports aggregation of multiple
  Epetra_CrsMatrix as sub-matrix objects to act as a single matrix.

- New class EpetraExt_MultiMpiComm: Supports two-level communication where
  each processor is part of the global communicator and a sum-domain
  communicator.

- EpetraExt_MatrixMatrix performance improvements:  Substantial improvements to
  sparse matrix time sparse matrix multiplication for most cases.

- InOut facilities: Substantial improvement to input and output functions that
  read and write matrix and vector objects to and from files.  Added simplified
  interfaces that allow distributed matrix construction without requiring the
  user to define Epetra_Maps.  Added support to write the implied matrix
  coefficients of an Epetra_Operator.  Added support for HDF5 and XML formatted
  files.

- ModelEvaluator: New capabilities to support generic solution interfaces for
  linear and non-linear systems via Thyra.

EpetraExt/Thyra adapters:

What’s New:

- Thyra::EpetraModelEvaluator:  This class wraps an EpetraExt::ModelEvaluator
  object (which deals only in Epetra-based objects) and provides an
  implementation of the Thyra::ModelEvaluator interface strictly in terms of
  abstract Thyra objects.  Any linear solver and preconditioner can be
  supported by configuring a EpetraExt::ModelEvaluator object with a compatible
  linear solver factory object.

-------------------------------------------------------------------------------

Galeri (new)

Understanding, validating, using and developing algorithms and software tools
for distributed linear algebra solvers, like Krylov accelerators and
preconditioners, requires input data. This data should have three critical
properties:

   1. reflect real-life applications to a sufficient extent so that we can use 
      them to predict performance;
   2. be sufficiently simple to be amenable to mathematical analysis;
   3. it is possible to write generators that easily provide instances of
      these problems. 

The goal of the Galeri package is exactly to produce these input data for
linear solvers.

As regards real-life applications, we have here selected PDE-type problems.
Although Galeri can generate some non-PDE linear systems, surely there is a
strong focus on PDE applications. Among them, the Laplace problem is probably
the most widely studied application, and a broad range of results are
available. For most solvers and preconditioners, often there is a sharp
convergence bound that can be used to validate a particular class, or to get a
sense of the performances of a new method. A Trilinos package that uses Galeri
is the MatrixPortal module of WebTrilinos.

Galeri's Matrix generation capabilities can help to make examples shorter and
easier to read, since they can produce challenging linear systems in a few code
lines. Therefore, the attention of the example's reader is not distracted by
complicated instructions aiming to build this or that linear system. Since most
linear algebra packages of Trilinos use Galeri, users will quickly become
familiar with it. Galeri is used in the examples of the Amesos, IFPACK, and ML
packages. For more details, please check the Galeri web page
(http://software.sandia.gov/trilinos/packages/galeri).

-------------------------------------------------------------------------------

Ifpack 3.1

- New class Ifpack_Chebyshev: Chebyshev polynomial preconditioner.

- New class Ifpack_DiagPreconditioner: Simplifies construction and use of
  diagonal preconditioners.

- New functionality to test if Teuchos ParameterList values are valid for
  Ifpack preconditioner.

- Changed the hash table class for ICT and ILUT. The latter is then much faster
  than the previous version. The new class has a better memory usage and it is
  simpler to modify and extend.

- Fixed a few memory leaks in the ILU factorization class.

- Added Chebyshev preconditioner with point diagonal scaling.

- Added support for UseTranspose(true) in Ifpack_AdditiveSchwarz, Ifpack_ILUT
  and Ifpack_Amesos.

Ifpack/Thyra adapters:

Thyra preconditioner factory adapters for Ifpack are new for this release.

Known issues:

- Incomplete parameter validation and inconsistent use of parameter lists:
  Currently, parameters not specified in the input parameter list are not
  appended with the default values and all parameters and sublists are not
  fully validated.  This is an issue that needs to be resolved in the core
  Ifpack source code.

-------------------------------------------------------------------------------

Isorropia 1.0 (new)

- initial release, version 1.0

- Isorropia is a Trilinos interface to Zoltan repartitioning/balancing
  capabilities

- requires Zoltan version 2

- several example programs illustrate usage

- doxygen documentation on Trilinos website

-------------------------------------------------------------------------------

Kokkos 1.1

- New experimental interface to OSKI optimized kernels.

-------------------------------------------------------------------------------

Komplex 1.1

- No significant changes.

-------------------------------------------------------------------------------

LOCA

- Many of the internals of LOCA have been rewritten to more fully support
  multi-parameter continuation, constraint tracking, higher-order predictors
  and advanced bifurcation algorithms. The old framework has been completely
  removed, and therefore all users must upgrade their interface to the new
  framework. For a brief description of the new framework, see the New LOCA
  Framework page. In addition, some of the parameter list entries that control
  LOCA have changed. See the LOCA Parameter Reference Page for a description of
  the new parameter list structure.

- A minimally augmented turning point formulation has been added to LOCA. This
  method appears to be significantly faster and more robust than the turning
  point methods based on the Moore-Spence formulation.

- A modified pitchfork bordering method has been added to LOCA, which is
  similar to the modified turning point method already available. This method
  avoids the singular matrix solves in the original pitchfork bordering method.

- Parallel and serial Hopf support has been added to LOCA.

-------------------------------------------------------------------------------

Meros 1.0 (new) 

Meros is a segregated preconditioning package. It provides scalable block
preconditioning for problems that couple simultaneous solution variables such
as Navier-Strokes problems.

The source documentation can be found on the Meros web page:
http://software.sandia.gov/Trilinos/packages/meros/

For more information, see Trilinos/packages/meros/README-MEROS

-------------------------------------------------------------------------------

ML

ML/Thyra Adapters:

Thyra preconditioner factory adapters for ML are new for this release.

Known issues:

- Incomplete parameter validation, inconsistent use of parameter lists, non-XML
  compatible parameters:  Currently, parameters not specified in the input
  parameter list are not appended with the default values and all parameters
  and sublists are not fully validated.   In addition, many of the ML
  parameters can not be read in from an XML file.  For example, the parameters
  that control AztecOO from ML can not be directly read in from an XML file.
  These are issues that need to be resolved in the core ML source code.

-------------------------------------------------------------------------------

Moertel (new)

- Supplies capabilities for nonconforming mesh tying and contact formulations
  in 2 and 3 dimensions using Mortar methods.

- Uses dual and standard Mortar methods to construct Lagrange multiplier
  constraints for nonconforming interfaces.

- Serves as a programming language for other types of mesh tying approaches.

-------------------------------------------------------------------------------

MOOCHO (new)

MOOCHO is collection of software for the solution of large-scale
simulation-constrained optimization problems using primarily reduced-space
successive quadratic programming algorithms.

Known issues:

- Incomplete support for all Thyra::ModelEvaluator options:  All of the bells
  and whistles for the different possible modes for simulation-constrained
  optimization through the Thyra::ModelEvaluator classes are not yet in place.
  Right now, the code handles the cases of exact direct sensitivities, finite
  difference direct sensitivities and adjoint sensitivities with some caveats.
  For example, even through the direct sensitivity method only requires the
  application of the operator DgDx (ModelEvaluator notation) onto vectors, the
  current implementation requires that a vector for transpose(DgDx ) be
  explicitly returned.  In the next release of Trilinos, all modes should be
  fully supported without imposing undue requirements on the application.

- Outdated linear algebra and model interfaces:  MOOCHO currently uses its own
  linear algebra layer called AbstractLinAlgPack that actually predates (and
  helped to inspire) Thyra.  In the next release, it is highly possible that
  MOOCHO will be refactored to use a linear algebra layer based directly on
  Thyra and perhaps the new Thyra handle layer which will help to help other
  Trilinos developers to be able to understand and develop algorithms in
  MOOCHO.  This refactoring is also likely to radically change the NLP
  interfaces to move to a single ModelEvaluator-like interface that will allow
  for faster prototyping of new optimization algorithms.

-------------------------------------------------------------------------------

New_Package

- No significant changes.

-------------------------------------------------------------------------------

NOX

- NOX is now using reference counted smart pointers (RCPs) for memory
  management. Passing an RCP wrapped object through a method call implies a
  persisting relationship. We are using the Teuchos::RefCountPtr object for
  the RCP.

- The NOX::Parameter::List has been removed. We are now using the
  Teuchos::ParameterList object. This has the same functionality with minor
  changes to the syntax of method calls.

- NOX now has a non-optional dependency on the Teuchos package (also part of
  Trilinos). While it can be built stand-alone, we recommend building NOX as
  part of Trilinos with the teuchos library enabled to simplify dependencies.

- NOX and LOCA now generate Makefiles that users can include in their own
  makefiles to get all dependencies correct. For example if NOX is built with
  Epetra support enabled, nox depends on epetra, aztecoo and ifpack headers and
  libraries. To keep the user from having to learn about those packages so they
  can link nox into their codes, just include the NOX file Makefile.export.nox
  file to get variables that have all sub package dependencies correct. In the
  installation directory, look at the files include/Makefiles.export.nox and
  include/Makefiles.export.nox.macros. The important flags in
  Makefile.export.nox are NOX_INCLUDES, NOX_LIBS, LOCA_INCLUDES, and LOCA_LIBS
  flags. The Makefile.export.nmox.macros file contains the compiler flags that
  were used to build the NOX and LOCA packages. It is very important to use
  consistent flags when linking your application against Trilinos.

- Multivector support is no longer a configure option, but is automatically
  built as part of the library.

- The epetra interfaces (NOX::Epetra::Interface namespace) have been changed.
  They now take an Epetra_Operator as an argument when evaluating the Jacobian
  and preconditioner objects. While this is redundant for our base epetra group
  (since it shares the same operator between groups), this allows users to
  override the eptra group and use separate operators for each group if
  desired.

- There are 2 options for creating an Ifpack preconditioners. The original code
  where the "Preconditioner" option in the "Linear Solver" sublist was set to
  "Ifpack" and the new ifpack code "New Ifpack". The original option explicitly
  constructs an ifpack ilu object that has since been deprecated and will most
  likely be removed in the next release (Trilinos 8.0). The option "New Ifpack"
  uses the new ifpack factory object. You can now create a parameter list that
  directly uses the ifpack factory arguments and can create any ifpack
  preconditioner (not limited to ILU). We recommend switching to the "New
  Ifpack" preconditionerr interface asap.

- In the epetra support, the preconditioner options "AztecOO", "New Ifpack",
  and "ML" allow users to recompute the preconditioner using the same graph so
  that preconditioner memory is not allocated and destroyed each linear solve.
  The new "Linear Solver" sublist key is "Preconditioner Reuse Policy" with the
  possible values "Rebuild", "Reuse", and "Recompute". If you choose "Rebuild",
  this is what nox has done in previous releases - destroy, reallocate and
  recompute the preconditioner for each linear solve. "Reuse" will use the same
  preconditioner for every linear solve. "Recompute" will recompute the
  preconditioner, but will try to efficiently reuse any objects that don't need
  to be destroyed. How efficient the "Recompute" option is depends on the type
  of preconditioner. For example if we are using ILU in Ifpack, the graph that
  is allocated does not need to be destroyed and recomputed even though the
  computation will recompute the factorization when the matrix changes. These
  changes support native Aztec, Ifpack and ML preconditioners. 

-------------------------------------------------------------------------------

Pliris 1.1

- Added a new method - Solve.  This allows a user to split the factor and solve
  for a dense matrix.  This is useful when the right hand side is changing in
  the numerical simulation.

- A test case has been added to test this functionality. 

-------------------------------------------------------------------------------

PyTrilinos 3.0

PyTrilinos 3.0 is a significant structural change from version 2.0,
although most of these changes will be invisible to the typical user.
"PyTrilinos" used to refer to both a python package (here using the
python definition of package, meaning "a module of modules") and to a
small Trilinos package (here using the Trilinos definition of package,
meaning a set of one or more related compiled libraries) of utility
classes that helped to enable the python modules.

The classes that used to comprise the PyTrilinos library have either
been eliminated or moved to other Trilinos packages.  The PyTrilinos
Trilinos package now serves to enable certain cleanup functions.  The
most important of these is to fix a problem seen with MPI builds,
where bad_cast exceptions can be raised because the python extension
modules are linked to static libraries.

If you are building Trilinos on Linux or Mac OS X and have enabled
both python and MPI, the PyTrilinos package will go back and create
dynamic versions of various Trilinos libraries (e.g., libepetra.so).
These get stored in your build directory under

    packages/PyTrilinos/src

PyTrilinos then goes back again and re-links the python extension
modules (e.g. _Epetra.so) to these new dynamic libraries.  This has
eliminated several (but not all) problems seen when running PyTrilinos
scripts in parallel.

Note that if you wish to run python test scripts *prior* to installing
Trilinos, you need to tell your shell how to find the dynamic
libraries.  You do this by setting an environment variable, either

    LD_LIBRARY_PATH, or
    DYLD_LIBRARY_PATH

for Linux and Mac OS X respectively, to include the directory that
contains the dynamic libraries.  When you invoke mpirun, you must
export this environment variable.  For example,

    mpirun -x LD_LIBRARY_PATH -np 4 testVector.py -t

When you run "make install", the dynamic libraries will get installed
as well.  Depending on where you specify installation, this may
eliminate the need to specify and export these environment variables.

                         --------------------                         

Several other changes have been made since PyTrilinos 2.0/Trilinos 6.0:

* As the first part of these release notes indicate, MPI is explicitly
  supported.  This support was considered "experimental" in PyTrilinos
  2.0.

* The build process has been significantly improved.  PyTrilinos now
  uses the export Makefiles that are supported by many Trilinos
  packages, and this has greatly helped in using accurate lists of
  include paths, library paths and libraries.  Furthermore, the
  PyTrilinos build system now parses Makefiles directly to obtain the
  values of user-configured variables, eliminating another source of
  build error.

* NumPy support.  PyTrilinos has been upgraded from compatibility with
  the now-obsolete Numeric module to its successor, NumPy.  As of this
  writing, NumPy is in beta testing for release 1.0.  PyTrilinos is
  compatible with NumPy 0.9.6 and 0.9.8, and has been tested against
  NumPy 1.0b, versions 2 and 4.

* Much focus has been placed on improving the Epetra module.
  Previously, many Epetra class methods were wrapped, but if they had
  pointers in the argument list representing C arrays, these methods
  could not actually be used in python.  A large percentage of these
  methods have been updated.  Any python sequence can be used in place
  of input array arguments, and NumPy arrays are returned for output
  arrays.

* More Epetra array-like classes now doubly-inherit from NumPy arrays.
  These classes are:

    + Epetra.IntSerialDenseMatrix
    + Epetra.IntSerialDenseVector
    + Epetra.IntVector
    + Epetra.MultiVector
    + Epetra.SerialDenseMatrix
    + Epetra.SerialDenseVector
    + Epetra.Vector

  When you instantiate one of these classes, the resulting object can
  also be treated as and will be recognized as a NumPy array.  This
  creates a high-degree of compatibility with other python packages,
  such as SciPy, matplotlib, etc.

* Exception handling added.  Not all cases are yet handled, but many
  of the common ones are, and an infrastructure is in place for
  PyTrilinos developers to convert C++ exceptions into python
  exceptions.

* The Teuchos module has been added and ParameterLists are explicitly
  handled now, but python dictionaries can be used in their place.
  Also, nested dictionaries are now recognized as sub-lists, greatly
  increasing the usefulness of this feature.

* The Galeri module has been added.

* For Trilinos release 7.0, the NOX module has been disabled.  We have
  been unable to keep up with the significant changes made in the NOX
  package, but we are working on it.  Hopefully, this module will be
  re-enabled in a minor future update, 7.0.x.

* Documentation has been expanded.  The documentation section of the
  PyTrilinos web site now covers prerequisites, build notes and has an
  individual page for each module covering differences between the C++
  and python interfaces.

-------------------------------------------------------------------------------

RTOp (new)

RTOp (reduction/transformation operators) provides the basic mechanism
for implementing vector operations in a flexible and efficient manner.
This software was basically refactored out of Thyra from the last
release of Trilinos 6.0 since MOOCHO, and in the future Tpetra, directly
depends on RTOp but not Thyra.  Contained in RTOp is:

a) a small number of interoperability interfaces

b) support software including code for the parallel SPMD mode based on
only Teuchos::Comm (and not MPI directly)

c) a library of pre-implemented RTOp subclasses for everything from
simple AXPYs and norms, to more specialized vector operations.

-------------------------------------------------------------------------------

Rythmos 1.0 (new)

Rythmos is a transient integrator for ordinary differential equations and
differential-algebraic equations with support for explicit, implicit, one-step
and multi-step algorithms.  The fundamental design of Rythmos is aimed at
supporting operator-split algorithms, multi-physics applications, block linear
algebra, and adjoint integration. 

New Features:

 - Everything is new.  This is the first release for Rythmos.

 - Implicit Backward Differentiation Formula Stepper:  This stepper provides a
   re-implementation of the implicit algorithms in the LLNL Sundials code CVODE.
   This is an implicit BDF integrator for ODEs which uses variable step-sizes
   and variable-orders first through fifth.

 - Explicit Runge-Kutta Stepper:  This stepper provides a four stage fourth
   order explicit RK steper with fixed step-sizes provided by the application.
   Full variable step-size support and application provided Butcher tableaus
   will be supported in the next release.

 - Forward Euler Stepper:  This stepper provides the explicit forward Euler
   algorithm with fixed step-sizes provided by the application.  Full variable
   step-size support will be in the next release.

 - Backward Euler Stepper:  This stepper provides the implicit backward Euler
   algorithm with fixed step-sizes provided by the application.  This
   class supports ODEs and DAEs.  Full variable step-size support will be
   in the next release.

Known Issues:

 - Currently Rythmos does not have an interface to NOX.  This will be provided
   through an EpetraExt::ModelEvaluator interface in NOX in the next release.
   Therefore the nonlinear solving capabilities in Rythmos are limited to a
   simple undampened Newton iteration in Thyra::TimeStepNewtonNonlinearSolver.

 - The InterpolationBuffer base class is just starting to be developed and has
   not been compiled or tested in any way yet.  It is provided as an example of
   what the interface could look like and where the integrator class will be
   derived from.

 - An integrator class does not yet exist.  It will depend on the
   InterpolationBuffer class and both of these will be completed in the next
   release.  Therefore users should use the Stepper class directly to step
   differential equations forward in time.  When this class is implemented it
   will enable solving operator-split and multi-physics problems.
 
 - The Explicit Taylor Polynomial Stepper is in active development and under
   current research.  It is provided only as an example interface.  This
   stepper may be completed in the next release.

-------------------------------------------------------------------------------

Stratimikos (new)

Stratimikos is a set of wrappers of common linear solver functionality through
Thyra.  In this initial release, Stratimikos provides the “Façade” class
Thyra::DefaultRealLinearSolverBuilder that provides a single parameter list
(i.e. Teuchos::ParameterList) driven interface to much of the linear solver and
preconditioner capability contained in Trilinos.  For example, the class
Thyra::DefaultRealLinearSolverBuilder is the recommended way to access the
linear solver adapters in Amesos/Thyra, AztecOO/Thyra, and Belos/Thyra (not in
Trilinos 7.0) as well as the preconditioner adapters in Ifpack/Thyra and
ML/Thyra.  With a single parameter list that can be read from an XML file, the
user can select for a wide variety of different linear solver and
preconditioner combinations.

Known issues:

- Incomplete parameter validation and inconsistent use of parameter lists:
  While many of the parameter lists and sublists accepted by the Stratimikos
  façade class Thyra::DefaultRealLinearSolverBuilder are fully validated and
  will write default parameter values when missing in the input parameter list
  such as for AztecOO/Thyra, other sublists for other solvers are not.  This is
  not specifically a Stratimikos issue but instead is an issue for the core
  code in Ifpack, ML, and Amesos.

-------------------------------------------------------------------------------

Teuchos

In Trilinos Release 7.0, the Teuchos tools package has some additional
functionality available to Trilinos developers and users:

- This release provides a simple XML parser that is compiled by default
  when eXpat is not available, enabling the perpetual use of Teuchos' XML
  utilities like XML-ParameterList reading and writing in any code.  Also,
  the Teuchos' XML utilities are now built by default.

- Complex scalar-type support is built by default for scalar-type templated
  utilities like the ScalarTraits, BLAS, LAPACK, and SerialDenseMatrix.

- A reference-counted class similar to RefCountPtr designed to manage an
  array of objects is available, called ArrayRefCountPtr.

-------------------------------------------------------------------------------

Thyra

What's New:

- Implicit Linear Operators:  Thyra now includes support software that
  implements implicit zero, identity, diagonal, added, multiplied,
  scaled/adjoint, and blocked linear operators that complement the existing
  product vector space and (multi)vector subclasses.  These implicit operators
  allow you to create arbitrarily complex, nested, linear operators that are
  useful in a variety of contexts (e.g. Schur complement solvers, block
  preconditioners, time/space discretizations etc.).  Look for these in the
  “ANA Operator/Vector Support” collection and click on “ANA Development
  Support” link.

- Removal of explicit MPI support/dependence:  The separate serial and MPI
  support software collections for vector spaces, vectors, multi-vectors and
  linear operators have been merged into a single set of SPMD support software
  that is only dependent on the small new Teuchos::Comm interface.  This got
  rid of a lot of duplicate code and will allow for other more specialized
  implementations of communication.

- Java-like handle classes supporting Matlab-like operator overloading:  Thyra
  now includes a set of Java-like handle classes for wrapping vector spaces,
  vectors and linear operators and allowing you to write expressions like
  y=x+alpha*z and y=beta*A*x + B*y that don’t result in any unnecessary
  temporary copies unless required..  The linear operator handle class also
  provides full support for the implicit linear operator subclasses described
  above.  Look for these in the “ANA Operator/Vector Support” collection and
  click on “ANA Development Support” link.

- Zero-based indexing:  All of Thyra has been changed from largely 1-based
  indexing to completely zero-based indexing.  This especially impacted the
  multi-vector column access and subview functions.  Therefore, any current
  users are cautioned to carefully review their codes to see what impact this
  will have.  Note that most single-vector ANAs will not be affected by this
  change at all since there is not such indexing used in these types of
  algorithms.

- Compile-time enabled runtime checks: Almost all runtime tests in
  Thyra-related software must be explicitly enabled by adding
  –enable-teuchos-debug to the configure line.  This replaces having to
  manually define a _DEBUG macro as was required in the last release of
  Trilinos.  We highly recommend that this flag be turned on by all users and
  developers while developing with Thyra-related software.  Once a program is
  working and you want to run timed studies, then you should remove
  –enable-teuchos-debug, and turn up the compiler optimization flags.

- Expanded linear solver and preconditioner factory interfaces:  The Thyra
  linear solver interfaces in Trilinos 6.0 have been refined to now include the
  concept of a preconditioner factory.  Adapters are found in Amesos, AztecOO,
  Ifpack and ML.

- Nonlinear model evaluator:  The Thyra::ModelEvaluator interface now supports
  functionality for simulation-constrained optimization (i.e. as used by
  MOOCHO).

Known issues:

- Long compilation times: Compilation times for the examples and tests can be
  very excessive on older machines or when using some compilers.  The reason
  for this is that Thyra is entirely templated code currently and uses implicit
  template instantiation.  Therefore, when every *.cpp test/example file is
  compiled, the compiler has to parse and analyze every header and create
  instantiations over and over again.  In the future, the option of performing
  explicit template instantiation will be available and this will greatly
  speed up the build process but will also inhibit some of the flexibility of
  supporting different Scalar types and might complicate the build process.
  In the mean time for this release, to speed up the builds for Trilinos,
  users might consider adding –disable-thyra-tests and –disable-thyra-examples
  to the configure line.

- Wrong behavior of explicit element access functions: The behavior of the
  Thyra::[Multi]VectorBase::acquireDetachedView(…) functions is not consistent
  with the nature of abstract numerical algorithms (ANA) in single program
  multiple data (SPMD) mode.  The current behavior facilitates the
  interoperability of abstract vectors in an SPMD configuration without
  requiring lots of dynamic casts but is the wrong behavior from the ANA
  perspective.  This will be corrected in the next version of the release and
  specialized interfaces will be developed for (multi)vector-(multi)vector
  interoperability and the behavior of the functions
  Thyra::[Multi]VectorBase::acquireDetachedView(…) will be the same in every
  process of an SPMD, or any other type, of runtime configuration.  Therefore,
  users are warned to isolate any code that depends on the current behavior of
  the Thyra::[Multi]VectorBase::acquireDetachedView(…) functions since this
  behavior will change on the next release.   Note that most user code will
  never use these functions so this future refactoring this should cause
  serious problems for users.

- Unnecessary temporary creation in handle layer code:  The performance of
  handle-based code can be less efficient that nonhandle-based code in some
  cases, such as the creation of extra temporary vectors.  This may be fixable
  in later releases through more careful consideration operator evaluation
  logic.  In the mean time, studying the current implementation and some
  experimentation may help.

- Does not compile on IBM xlC compiler:  Thyra and all Thyra-related software
  can not be compiled on the IBM AIX C++ compiler (i.e. xlC).  The problem is
  that this C++ compiler gets tripped up with calling one version of an
  overloaded virtual function and declares the call to be ambiguous (which
  about 6 other distinct compilers consider the call to be non-ambiguous).
  Specifically, it declares that a call to the acquireDetachedView(…) function
  to be ambiguous.  The next release of Thyra might remove the overloaded
  functions and replace them with distinct names.

- ConstHandle classes will be removed:  The handle layer (e.g.
  Thyra::[Const]Vector, Thyra::[Const]LinearOperator etc.) is likely to change
  after the initial release of Trilinos 7.0.  The change will involve getting
  rid of the ConstHandle classes and going to a runtime protection of const
  involving just a single Handle class (e.g. Thyra::Vector and
  Thyra::LinearOperator).  Any code that uses the two-class handle system
  [Const]Handle should have no little problem being updated after the
  refactoring.  In fact, typedefs could allow all user code to be recompiled
  without change in most cases (but an actual code change would be a better
  long term solution).

-------------------------------------------------------------------------------

TriUtils

- No significant changes.

-------------------------------------------------------------------------------

WebTrilinos (new)

WebTrilinos is a scientific portal, a web-based environment to use several
Trilinos packages through the web. If you are teaching sparse linear algebra,
you can use WebTrilinos to present code snippets and simple scripts, and let
the students execute them from their browsers. If you want to test linear
algebra solvers, you can use the MatrixPortal module, and you just have to
select problems and options, then plot the results in nice graphs.

From the user's perspective, the only component required to use WebTrilinos is
any browser and an internet connection. Then, (simple) C++ and Python programs
can be written on a web form, executed on a server, and the output is sent back
to the user's browser. Code snippets for most of Trilinos and PyTrilinos
packages are already available in convenient repositories. WebTrilinos also
contains a problem solving environment (PSE) for the analysis of linear algebra
solvers, like direct solvers, Krylov solvers, and preconditioners. This
environment is called MatrixPortal.

To be installed, WebTrilinos requires the following:

   1. a web server, like Apache;
   2. PHP installed on the web server;
   3. an installed version of Trilinos, with the following packages: Teuchos,
      Epetra, EpetraExt, AztecOO, IFPACK, Amesos, ML, Galeri, PyTrilinos (and,
      of course, WebTrilinos itself);
   4. the PyChart package;
   5. the convert *nix tool to convert image files. 

WebTrilinos comes with a set of easy-to-use tools that suggest the
configuration options. For more details, please check the WebTrilinos web page
(http://software.sandia.gov/trilinos/packages/webtrilinos).


###############################################################################
#                                                                             #
# Trilinos Release 6.0 Release Notes                                          #
#                                                                             #
###############################################################################

Overview:

Trilinos is a collection of compatible software packages that support parallel 
linear algebra computations, solution of linear, non-linear and eigen systems 
of equations and related capabilities. The majority of packages are written in 
C++ using object-oriented techniques. All packages are self-contained, with the 
Trilinos top layer providing a common look-and-feel and infrastructure. 

Packages:

The version 6.0 general release contains 18 packages: Amesos, Anasazi, AztecOO, 
Didasko, Epetra, EpetraExt, Ifpack, Kokkos, Komplex, LOCA, ML, New_Package, 
NOX, Pliris, PyTrilinos, Teuchos, Thyra, and Triutils.

The limited release contains an additional 9 packages that are available in 
special situations by request. These are: Belos, Capo, Claps, Jpetra, Meros, 
Rythmos, Tpetra, TSF, and TSFExtended.

In addition to many new features across most packages, Trilinos Release 6.0 
contains one new package, Thyra.  This package represents our first general 
release of an abstract interface to support generic programming.  Thyra 
contains interfaces for basic linear algebra objects, a first linear solver 
interface, and supporting software.  Furthermore, adapters for Amesos, AztecOO, 
Epetra, Ifpack, ML, NOX and Teuchos provide a broad set of functionality to 
users of Thyra.  Finally, since Thyra is fundamentally an interface, users can 
write code based on Thyra without committing to any particular concrete linear 
algebra package, but instead have access to a growing collection of supported 
concrete libraries.

A second major feature is the much improved design and implementation of 
PyTrilinos.  PyTrilinos capabilities are now primarily distributed across 
Trilinos packages (although critical common functionality is still in the 
PyTrilinos package), so that Epetra, EpetraExt, Triutils, AztecOO, Amesos, 
Ifpack, ML, LOCA, NOX and New_Package are accessible to Python applications.  
PyTrilinos also supports parallel MPI execution without additional Python 
modules, and parallel performance for large-grain computations matches native 
Trilinos performance.  Finally, Python users are able to define their own
matrix modules in Python, satisfying Trilinos abstract interface, that can be
used by Trilinos solvers.

Other package-specific features are listed below.

More information:

Trilinos website: http://software.sandia.gov/trilinos 

===============================================================================

Amesos

- Improved memory management and performances 
- Added Scalapack, TAUCS and PARDISO support.
- Python interface for the factory and most classes.
- Amesos_Klu:
  - Improved performance on small matrices 
  - Supports non-standard indexing (i.e. {1,2,5,8,9}
  - Supports domain and range maps which differ from the matrix row map
- Amesos_Superlu and Amesos_Superludist:
  - Compatible with all Amesos solvers
  - Memory leaks eliminated
- Thyra wrappers for linear solve interface.  These adapter subclasses allow 
  any amesos direct solver to be incorporated, in a seamless way, into abstract 
  numerical algorithms written using the Thyra operator/vector abstractions.
- Makefile.export support 
- Eliminated dependence on triutils 
- Improved robustness through enhanced nightly testing

Known bugs:

- Amesos_Dscpack has memory leaks, prints to standard out and may crash if 
  SymbolicFactorization() is called multiple times on the same Amesos object.
- Amesos packages other than Amesos_Klu do not accept non-standard maps (e.g. 
  one with indices {1,2,5,8,9, ... } )
- Amesos packages other than Amesos_Klu do not accept range and domain maps 
  which differ from the matrix map
- Superludist fails on some matrices
- Error handling on singular and near singular matrices is inconsistent

-------------------------------------------------------------------------------

Anasazi

In Trilinos Release 6.0, Anasazi has a new solver, enhanced functionality and 
much more documentation.

- This release of Anasazi provides abstract implementations of three 
  eigensolvers:  block Davidson,  block Krylov-Schur, and locally-optimal block 
  preconditioned conjugate gradient (LOBPCG).  LOBPCG is the newest abstract 
  eigensolver implementation in the Anasazi framework for computing solutions 
  to symmetric eigenvalue problems.

- All three eigensolvers in Anasazi use the Anasazi::SortManager to sort for 
  the eigenvalues of interest. This functionality was previously available for 
  only the block Krylov-Schur implementation.

- Anasazi solvers now collect timing information that will be outputted if the 
  Anasazi::OutputManager is given the Anasazi::TimingDetails flag.

- The Anasazi framework now provides testing functionality for user-written 
  interfaces to Anasazi::MultiVecTraits and Anasazi::OperatorTraits.  This 
  functionality gives users a way to perform a sanity check on their interface.

- Anasazi has an updated and expanded tutorial in Didasko.

-------------------------------------------------------------------------------

AztecOO

- Python interface.
- Thyra linear solver adapters : Allows an AztecOO solver to be incorporated, 
  in a seamless way, into abstract numerical algorithms written using the Thyra 
  operator/vector abstractions.

-------------------------------------------------------------------------------

Didasko

- New chapter on Anasazi.

-------------------------------------------------------------------------------

Epetra

- Python interface for several objects, in serial and MPI: Epetra_Map, 
  Epetra_CrsMatrix, Epetra_LinearProblem, Epetra_Vector, Epetra_MultiVector, 
  Epetra_SerialDenseVector Epetra_SerialDenseMatrix, and more.
- Thyra adapters for vector space, linear operator, vector and multivector 
  classes.

-------------------------------------------------------------------------------

EpetraExt

- Python interface for I/O

-------------------------------------------------------------------------------

IFPACK

- Python interface for the factory class

-------------------------------------------------------------------------------

Kokkos

- No notable changes.

-------------------------------------------------------------------------------

Komplex

- No notable changes.

-------------------------------------------------------------------------------

LOCA

New features:

- A constraint tracking feature has been added to LOCA where the user can 
  specify additional algebraic constraints that must be satisfied along with 
  the residual.  Examples include boundary conditions, phase conditions in 
  periodic orbits, etc.  The resulting Newton system can be efficiently solved 
  using the QR method discussed below.  This capability is only available using 
  the LOCA::NewStepper also discussed below.

- A QR method for solving augmented systems of equations in parallel has been 
  added, and is an extension of the Householder method already available to 
  systems with more than one augmented row/column.  This method allows bordered 
  systems of equations to be solved in roughly the same time as original system 
  and is well-conditioned even when the original system is nearly singular.  
  This capability is only available using the LOCA::NewStepper discussed below.

- Many of the internals of LOCA have been rewritten to more fully support 
  multi-parameter continuation, constraint tracking, higher-order predictors 
  and advanced bifurcation algorithms.  This process is mostly, but not fully 
  complete.  This functionality is available by choosing the LOCA::NewStepper 
  for continuation instead of the original LOCA::Stepper.  However pitchfork 
  and Hopf continuation are currently not available in the new framework. 
  Documentation for this new framework can be found on the New LOCA Framework 
  page.

- LOCA's interface to eigensolvers has changed slightly and now uses a strategy 
  interface approach instead of relying on the group to provide 
  computeEigenvalues() and saveEigenvalues() methods.  This provides a more 
  natural decoupling of the parallel linear algebra data structures (i.e., the 
  group) from the eigensolver method/package (eigensolver strategy object). The 
  use of strategy interfaces instead of group methods is a major theme in the 
  new LOCA framework, and is discussed more fully on the new framework page.

Other notes:

- Teuchos::RefCountPtr support has been added to improve software quality. For 
  the most part, ref-count pointers are only used in the new framework.

- Many regression tests have been added to improve software quality.

- Libtool support has been removed from LOCA due to portability issues.

- Python support is temporarily disabled in this release due to a major 
  refactor of the build system for python wrappers in Trilinos.

Portability notes:

- There currently is a portability issue with LOCA to the Solaris platform 
  using the Sun Forte 7 compilers.  LOCA builds on this platform but does not 
  run correctly.  It appears the problem is compiler related as the virtual 
  table for some LOCA objects is not setup correctly.  All of the LOCA examples 
  and any LOCA tests involving continuation runs fail with a segmentation 
  fault.  It is not known whether LOCA runs correctly when built with version 
  10 of the Sun compilers.  See bugzilla bug 1238 for more information on this 
  issue.

-------------------------------------------------------------------------------

ML

- Improved the organization of the MLAPI source files and examples.  Now the 
  compilation of the MLAPI sources is about 20% faster, and the compilation of 
  the MLAPI examples up to 3 times faster.  Some never-used examples and 
  classes have been deleted.
- Drop the support for command line parameters. A similar capability is 
  supported by the Python interface.
- Repartitioning is now fully available through the MultiLevelPreconditioner 
  interface.
- Completed the ML wrapper for Python, using SWIG. The ML module still requires 
  a manual configuration of shared libraries, as done (on Linux/GCC at the 
  moment) with script make_shared_linux.sh, located in the PyTrilinos 
  directory.  The basic functionalities of the MultiLevelPreconditioner class 
  are available, for both serial and parallel runs. The ML module is compatible 
  with the Epetra and AztecOO modules.
- Changed the wrapper names and contents for Epetra matrices.  Now the dynamic 
  cast to Epetra_CrsMatrix and/or Epetra_VbrMatrix is done only once in the 
  construction of the preconditioner.  This results in an improvement of the 
  performances up to 30% for smore test problems.

- Added a simple finite element code, that can be used to test ML and MLAPI 
  preconditioners. The code offers a pure Galerkin and a SUPG discretization 
  for second order PDEs, in 2D and 3D, using triangles, quads, tets, and 
  hexahedra. L2 and H1 norms of the computed solution and error can be 
  computed. Results can be visualized using MEDIT.
- In the MLAPI namespace, added class MultiLevelAdaptiveSA, which implements 
  the \alpha SA algorithm (computation of slow converging modes for problems 
  with non-smooth kernels).
- Added a class, Ifpack_ML, that wraps an MultiLevelPreconditioner as 
  Ifpack_Preconditioner, so that ML can be used as local solver in a domain 
  decomposition preconditioner.
- Extended capabilities to read matrices from file in various formats.
- Added support for adaptive smoothed aggregation within MLAPI.  A new class, 
  called MultiLevelAdaptiveSA, has been added.
- Added a prototype of class for non-symmetric smoothed  aggregation.
- Added capability to write visualization files in legacy VTK (Visualization 
  toolkit) format.  These are readable by paraview, which is freely available 
  from www.paraview.org.  Supports 1D/2D/3D point cloud visualization for 
  aggregates, as well as solution visualization.

-------------------------------------------------------------------------------

New_Package

- PyTrilinos support:  Illustrates how a package can provide Python support.  
  Used by several other packages to provide new capabilities for PyTrilinos.

-------------------------------------------------------------------------------

NOX

- Refactor of configure for nox to align with the rest of Trilinos.  We now use 
  the same m4's that other packages use.  Also changed the way the examples are 
  configured so they are consistent with the tests.  Added implicit compilation 
  of ml and anasazi support.
- Addition of the export makefile system to enable easy interfacing to external 
  applications.
-  NOX now has a required dependency on Teuchos, it must be built as part of 
  Trilinos.

-------------------------------------------------------------------------------

Pliris

- No notable changes.

-------------------------------------------------------------------------------

PyTrilinos

In addition to python support present in Trilinos Release 5.0 for

  Epetra
  EpetraExt
  NOX
  NOX.Epetra

python interfaces have been added for the following packages:

  Amesos
  AztecOO
  IFPACK
  LOCA
  ML
  New_Package
  Triutils

Additionally, MPI support has been added.  Specifically, the Epetra.MpiComm 
class has been wrapped.  A new class, Epetra.PyComm, has been added, which 
returns an Epetra.SerialComm for serial builds and an Epetra.MpiComm for MPI 
builds.  For an MPI build, MPI_Init() is automatically called when the Epetra 
module is imported and MPI_Finalize() is automatically registered with the 
"atexit" module. Thus python scripts can be written that are identical for 
serial and MPI runs.

Configuration, building and installing
--------------------------------------

Python interfaces are enabled at configuration time now using the

--with-python[=path]    or
--enable-python[=path]

options, which are equivalent.  During "make", python interfaces will be built 
for every package that both supports python and is enabled.

(In Release 5.0, the four supported packages all had to be enabled. The 
--enable-pytrilinos configuration option, which enabled PyTrilinos in Release 
5.0, now only enables a small utility library used by all of the python 
interfaces.  The --enable-pytrilinos option is not strictly needed by end 
users, as the PyTrilinos package is automatically enabled by either 
--with-python or --enable-python.)

Python 2.3 or higher is highly recommended.  Some packages can be built against 
python 2.2, but there are some packages that require python 2.3.

SWIG (Simple Wrapper Interface Generator) version 1.3.23 or higher is required 
to generate the wrapper code.  These wrappers are not pre-built because they 
can be affected by configuration options. Configure will find swig if it is in 
your standard path, or you can tell configure where to find it using the 
--with-swig=PATH option.

The Numeric python module is required.

Do not configure with C flags -ansi or -pedantic.  Python supports arbitrary 
precision integers and these options will cause the compiler to fail.

The "make install" command will install the python interfaces (in addition to 
the standard package libraries and header files, of course).  If configured 
with --prefix=PATH, the modules will be installed in PATH/lib.  Make sure your 
PYTHONPATH environment variable is set correctly.  If --prefix=PATH is not 
provided, the modules will be installed in the standard location determined by 
where the python executable is installed.  This is often not /usr/local/, 
which is the default installation location for other Trilinos packages.  
Depending on how python was installed, this usually requires root access.

Testing
-------

>From the top build directory, or from a package top build directory, you can 
invoke "make run-pyexamples" or "make run-pytests" to execute all the scripts 
in the example or test directories, respectively. This will give concise output 
regarding failure or success for each script.  Detailed results of the tests 
that have been run can be found in the

packages/PACKAGE_NAME/test/runtests-results/

directory of the build directory.

Examples
--------

An important change was made to the directory structure for Release 6.0.  The 
python wrapper generation code is now contained within each package, under a 
directory named "python".  Within this directory are "src", "test", "example" 
and possibly other sub-directories.  For example, the epetra directory 
structure now includes

packages/epetra/python/
packages/epetra/python/example/
packages/epetra/python/src/
packages/epetra/python/test/

In the python/example sub-directory of each supported package, there will be 
one or more example python scripts demonstrating how to use the given module 
interface.  The python/test sub-directories are for unit tests.  If you are 
familiar with the python unittest module, these test scripts can provide 
additional examples of how to use the given module interface.

The example and test scripts are copied from the source directory to the build 
directory when "make" is run.  If these scripts are run from the build 
directory, they are designed to import the local build (uninstalled) versions 
of the Trilinos python interface modules.  If run from a different location 
(say, the source directory, or if you have copied them to another location), 
the scripts will still work as long as the python interfaces have been 
installed in a location where python can find them.

Using PyTrilinos
----------------

At this time, PyTrilinos documentation is admittedly incomplete. However, some 
documentation is available at

http://software.sandia.gov/trilinos/packages/pytrilinos/documentation.html

where you can find current lists of what packages are supported and which 
classes and functions within those packages have been wrapped.

PyTrilinos modules should be imported from a python script using, for 
example, the

>>> from PyTrilinos import Epetra

syntax.  Not all classes of all supported packages have been wrapped. One way 
to see what is available is to use the dir() function on a module:

>>> dir(Epetra)

For the most part, the python versions of functions, constructors and class 
methods use the same return values and argument lists as their C++ counterparts.  
Therefore, the individual package documentation is a good starting place for 
what is available, and for proper usage. However, it often makes sense to 
change the python argument lists --
for example, we may allow the use of a python list in place of a pointer to a 
C array, and we may then eliminate the integer size argument from the argument 
list, since it can now be obtained implicitly; or an output argument may be 
moved to a function's return value, often changing the return value to a tuple.  
Fortunately, all wrapped methods and functions have a documentation string that 
indicates correct usage.  Documentation strings in python can be obtained with 
the help() function.  For example:

>>> help(Epetra.CrsMatrix.InsertGlobalValues)
Help on method InsertGlobalValues in module Epetra:

InsertGlobalValues(*args) unbound Epetra.CrsMatrix method
InsertGlobalValues(self, int GlobalRow, int NumEntries, double Values, int 
Indices) -> int
InsertGlobalValues(self, int Row, int Size, SerialDenseVector Values, 
IntSerialDenseVector Entries) -> int
InsertGlobalValues(self, int row, PyObject Values, PyObject Indices) -> int

The PyObject type that will often appear in these documentation strings refer 
to arbitrary python objects, but often are expected to be containers such as 
lists, tuples or Numeric arrays.  In these cases, some experimentation may be 
in order.

For Developers
--------------

By convention, the code to build individual python interfaces now resides 
within each package, in the sub-directory "python".  For a template of how to 
wrap a Trilinos package, see the new-package package, and in particular the 

packages/new_package/python/Instructions.txt

file.

The PyTrilinos package itself is now a small library of utility classes and 
functions, intended to ease repetitive tasks that come up frequently when 
wrapping Trilinos packages.  For more details, contact Bill Spotz, 
wfspotz@sandia.gov.

-------------------------------------------------------------------------------

Teuchos

- No notable changes.

-------------------------------------------------------------------------------

Thyra (new)

- Defines fundamental abstract interfaces for vectors, multi-vectors, vector 
  spaces, and linear operators that form the foundation for all abstract 
  numerical algorithms.

- These interfaces will eventually be use to provide uniform interoperability 
  between a number of Trilinos (e.g. Belos, Anasazi, NOX, Rythmos, MOOCHO) and 
  non-Trilinos packages and to encapsulate application/physics codes.

- Also included are a small number of extended interoperability interfaces 
  such as:
  - Interface for linear operators that support a solve operation
  - Other miscellaneous interoperability interfaces
- Also included is adapter support code and very general concrete 
  implementations for:
  - Support for specialized scalar products for vector spaces
  - Support serial vector, multi-vector, vector space, and linear operator 
    implementations
  - Support MPI-based parallel vector, multi-vector, vector space, and linear 
    operator implementations
- Also included is utility code for helping to write abstract numerical 
  algorithms:
  - Unit tests for linear operators
  - Composite objects: product vectors, implicit operators (diagonal, 
    scaled/transposed, multiplicative etc.)
  - Explicit access to vector and multi-vector coefficients

-------------------------------------------------------------------------------

Triutils

- Python interface for the matrix gallery

-------------------------------------------------------------------------------

CLAPS (limited release only)

- The CLAPS package now contains two domain decomposition 
  preconditioners/solvers. The first, named CLOP, is based on a classic 
  overlapping Schwarz approach with an algebraically constructed coarse 
  space. The second, named CLIP, is an iterative substructuring (Schur 
  complement) approach that can be viewed as a primal counterpart of FETI-DP.


###############################################################################
#                                                                             #
# Trilinos Release 5.0 Release Notes                                          #
#                                                                             #
###############################################################################

Overview:

Trilinos is a collection of compatible software packages that support parallel 
linear algebra computations, solution of linear, non-linear and eigen systems 
of equations and related capabilities. The majority of packages are written in 
C++ using object-oriented techniques. All packages are self-contained, with the 
Trilinos top layer providing a common look-and-feel and infrastructure. 

Packages:

The version 5.0 general release contains 17 packages: Amesos, Anasazi, AztecOO, 
Didasko, Epetra, EpetraExt, Ifpack, Kokkos, Komplex, LOCA, ML, New_Package, 
NOX, Pliris, PyTrilinos, Teuchos, and Triutils.

The limited release contains an additional 9 packages that are available in 
special situations by request. These are: Belos, Claps, Jpetra, Meros, Tpetra, 
TSF, TSFCore, TSFCoreUtils and TSFExtended.

Some of the significant new features:

- Four new packages: Anasazi (Eigensolvers), Didasko (Tutorial), Pliris
  (Distributed dense solvers), PyTrilinos (Python interface to Trilinos
  libraries).
- Trilinos tutorial delivered as part of a new package called Didasko.
- Kernel performance in Epetra substantially improved, especially for
  multiple rights.
- Initial kernel support for vector architectures in Epetra.
- Significant improvements and enhancements in most existing packages.

More information:

Trilinos website: http://software.sandia.gov/trilinos 

===============================================================================

Amesos (version 2.0)

- Improved handling of Epetra_RowMatrix operators 
- Memory leaks have been reduced 
- Simplified configuration using
    --with-ldflags=-L/home/kstanley/Trilinos3PL/lib
    --with-libs=-lsuperludist
    --with-incdirs=-I/home/kstanley/Trilinos3PL/include
- Known bugs: 
  - Amesos_Dscpack has memory leaks, prints to standard out and may crash if 
    SymbolicFactorization() is called multiple times on the same Amesos 
    object. 
  - Amesos packages do not accept non-contiguous maps (e.g. one with indices 
    {1,2,5,8,9, ... } ) 
  - Superludist fails on some matrices 
  - Error handling on singular and near singular matrices is inconsistent 

-------------------------------------------------------------------------------

Anasazi (new)

- Anasazi framework includes abstract description of eigenproblem, eigensolver,
  sorting, and linear algebra. 
- Templated implementations of two block eigensolvers ( block Krylov-Schur and 
  block Davidson ) are included in this release. 
- Anasazi eigensolvers can use Epetra through linear algebra adapters. 
- A basic implementation of the abstract eigenproblem class is given for 
  solving standard and generalized eigenvalue problems. 
- A basic implementation of the abstract sorting class is given for the block 
  Krylov-Schur method. The block Davidson computes only the smallest 
  eigenvalues at this time. 
- Many examples for solving standard and generalized eigenvalues problems using 
  Anasazi are provided in this release. 

-------------------------------------------------------------------------------

AztecOO

- Robust support for multiple simultaneous instances of AztecOO objects.
  Prior releases had a very fragile memory management approach that require
  user intervention.
- Support (optional dependence on Teuchos) for ParameterList-driven use 
  of AztecOO via Teuchos ParameterList objects.

-------------------------------------------------------------------------------

Didasko (new)

- Didasko now contains the tutorial PDF file and examples. All the tutorial 
  material is located in the Trilinos/packages/didasko subdirectory. 
- The doxygen documentation has been improved. 
- All examples are configured with autotools. Users can enable the compilations 
  of the examples by adding --enable-didasko to their configure line. 

------------------------------------------------------------------------------- 
Epetra

- Memory efficiency improvement for MultiVector, CrsGraph and CrsMatrix 
  classes. 
- MultiVector uses much less O(NumVector) storage in important situations. 
- CrsGraph and CrsMatrix support a static profile mode that allows one-time 
  allocation of memory. 
- CrsGraph and CrsMatrix support a more robust OptimizeStorage capability that 
  improves memory use and performance. 
- Performance improvement for CrsMatrix and VbrMatrix kernels. 
- CrsMatrix matrix multiplication and triangular solves are 20% to 100% faster 
  that Version 4.0 
- VbrMatrix matrix multiplication is also improved for some important classes 
  of problems. 
- Initial vector architecture support for sparse matrix-vector multiplication. 
- A new class called JadOperator supports matrix-vector multiplication using 
  the so-called Jagged Diagonal data format. This format is especially 
  effective for vector machines such as the Cray X1 and NEC SX series machines.

-------------------------------------------------------------------------------
 
EpetraExt

- Scalable parallel distance-1 and distance-2 graph coloring. 
- Sparse matrix Add for Epetra CRS matrices. 
- Global index map "reindexing" tool for Epetra objects. 

-------------------------------------------------------------------------------

Ifpack

- IFPACK 3.0 defines a general interface for preconditioners, through class 
  Ifpack_Preconditioner. 
- Class Ifpack_AdditiveSchwarz can be used to define general overlapping 
  one-level domain decomposition preconditioners. 
- IFPACK now offers point and block relaxation schemes, of Jacobi, 
  Gauss-Seidel, and symmetric Gauss-Seidel type. For block schemes, the 
  package supports both dense and sparse blocks. 
- Two new factorizations, ILUT and ICT, have been introduced. 
- A new user's guide is available. The doxygen documentation has been improved. 

-------------------------------------------------------------------------------

Kokkos (version 1.1)

- No notable new features. 

-------------------------------------------------------------------------------

Komplex (version 2.0)

- No notable new features. 

-------------------------------------------------------------------------------

LOCA

- The LOCA library can now be built as a shared library using libtool. Known 
  issues with this are: 
  - Extra link libraries passed using the --with-libs configure flag should 
    use the "-Lpath -lname" format instead of "path/libname.a" 
  - Building LOCA as a static library on DEC architectures using template 
    repositories does not work. On these architectures, only build LOCA as a 
    shared library using the --enable-shared and --disable-static configure 
    flags, or turn off template repositories using the "-tweak" C++ compiler 
    flag. Note that if the later method is chosen, a large number of warnings 
    will be issued each time an executable is linked against LOCA. 
  - When building shared libraries on SGI systems in 64 bit, one must supply 
    the "-64" C++ compiler flag to not only the compiler and linker through 
    CXXFLAGS and LDFLAGS, but also to libtool using LIBTOOL_CCLINKER_FLAGS 
    or --with-libtool-cclinker-flags. Also one must turn off template 
    repositories and the template prelinker using the flags "-ptused 
    -no_prelink -no_auto_include". 
  - When building shared libraries on Solaris systems, one should add 
    "-xlic_lib=sunperf" to CFLAGS, "-library=sunperf" to CXXFLAGS and 
    LIBTOOL_CCLINKER_FLAGS, and make sure neither of these flags appear in 
    LDFLAGS. 
  - A basic, but functional python interface to NOX and LOCA now exists. A 
    test exhibiting this functionality can be found in the 
    Trilinos/packages/nox/test/lapack/LOCA_python directory. 

-------------------------------------------------------------------------------

ML (version 3.1)

- ML now supports Zoltan as a coarsening scheme (RCB only). Zoltan
  can be used to create the aggregates and to redistribute
  the next-level operator among the specified number of
  processors (which can be less than the available number of processes,
  for Maxwell solver only).
- a variable-block partitioning scheme (based on METIS) is now available. 
- ML now supports IFPACK smoothers, like variable block Jacobi, 
  Gauss-Seidel and symmetric Gauss-Seidel preconditioners, and 
  generic additive Schwarz preconditioner.
- Updated ML user's guide and Doxygen documentation.
- Improved MultiLevelPreconditioner class (now derived from
  Epetra_Operator and no longer from Epetra_RowMatrix). Updated
  filtering/GGB algorithm, based on the Anasazi package.
- Solving Maxwell equations via MultiLevelPreconditioner is now supported.
- Improved organization of the examples, more detailed comments and 
  additional README files. 
- Wrapping an ML_Operator struct as Epetra_RowMatrix is now supported.
- Improved test coverage.

-------------------------------------------------------------------------------

New_Package (version 1.1)

- New tests are working examples of how to add tests to the Trilinos 
  Test-Harness. 

-------------------------------------------------------------------------------

NOX

- A new Tensor based solver that is independent of the underlying linear 
  solver is now implemented (in the prerelease section). Previously the 
  Tensor method was hardwired to use an iterative solver. 
- Inexact Trust Region Techniques are fully supported (also in the prerelease 
  section). 
- Improved support for Epetra objects - The NOX::EpetraNew::Group should be 
  used in place of the NOX::Epetra::Group. In the future we will be phasing 
  out the NOX::Epetra::Group and replace it with NOX::EpetraNew::Group. 
- A multi-physics technique for code coupling has been demonstrated in the 
  test/epetra/Multiphysics directory. This will be expanded to a generic 
  capability in the next year. 

-------------------------------------------------------------------------------

Pliris (new)

- An Object Oriented interface to a Dense Parallel LU Solver is now in place.
- The matrix is described in terms of Epetra Vectors and Multivectors.
- Multiple right hand sides can be addressed.
- Configure with --enable-pliris
- Test code allows performance studies - performance is dependent on highly 
  optimized Level 3 BLAS.

-------------------------------------------------------------------------------

PyTrilinos (new)

- Requires SWIG version 1.3.23 or higher (http://www.swig.org). 
- Requires python Numeric (http://www.pfdubois.com/numpy). 
- Configure with --enable-pytrilinos. 
- Currently provides access to Epetra, EpetraExt and NOX. From python, use 
  "from PyTrilinos import name", where "name" is the desired module. 
- Online documentation provides list of which classes have been wrapped. 
- Wrapped classes support almost all of the class methods. See documentation 
  of wrapped packages for details. 

-------------------------------------------------------------------------------

Teuchos

- Additional BLAS/LAPACK wrappers 
- Teuchos::ScalarTraits template specializations for the GNU MP and Arprec 
  arbitrary precision libraries 
- Code enabling the conversion from NOX::Parameter::List to 
  Teuchos::ParameterList, and vice versa. 

-------------------------------------------------------------------------------

Triutils

- No notable new features.

