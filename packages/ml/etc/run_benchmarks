#!/bin/sh
#
# This script is used for running a series of benchmark tests.
# It is normally used in conjugation with the benchmarks located
# in mlbench. 
# 
# What to do:
#   1) If you don't have mlbench, try cvs checkout mlbench
#
#   2) Do a 'make clean' in the ml/Obj directory.
#      This will ensure that any executables requiring
#      compilation with a -DBENCHMARK will get automatically made by
#      run_benchmarks.
#
#      Note: the script automatically removes the executable and associated
#      object file and remakes them.  Thus, you only need to do a make clean
#      if some other ML src file uses the BENCHMARK macro.
#
#   3) If you are running in parallel and need something other than mpirun, 
#      edit the 'PARALLEL_CMD' variable below.
#
PARALLEL_CMD=`echo /usr/local/mpich/bin/mpirun -machinefile ./machines -np `
#
#      You may also need to edit the script etc/mpibench.pbs, which assumes
#      that mpirun is being used.
#
#   4) Run run_benchmarks. If you run it without arguments, it will
#      tell you what the defaults are. If these are not correct, add
#      arguments to run_benchmarks.
#
#       Usage: run_benchmarks [bench_root_directory executable_directory 
#                              scratch_root_directory parallel={TRUE,FALSE}
#                              batch={TRUE,FALSE}]
#       where
#
#           bench_root_directory      Directory path to mlbench test problems.
# 
#           executable_directory Path to directory where ml should be 
#                                compiled.
#
#           scratch_root_directory    Directory where output will be left.
#
#           parallel             Either TRUE or FALSE to indicate whether
#                                parallel benchmarks should be run.
#
#           batch                Either TRUE or FALSE to indicate whether
#                                batch system should be used.
#
SCRIPT_DIRECTORY=${PWD}
BENCH_ROOT_DIRECTORY=${HOME}/mlbench
EXECUTABLE_DIRECTORY=${PWD}/../Obj
SCRATCH_ROOT_DIRECTORY=/tmp/mlbench_results
PARALLEL=TRUE
# set to true if your system uses the pbs batch queue system
BATCH=FALSE
#
# To create new benchmark problems:
# 
#    1) Create a new subdirectory under mlbench for the new problem and
#       cd into this directory. run_benchmarks automatically descends each 
#       subdirectory (under mlbench) and runs the appropriate executable 
#       within the subdirectory. 
#
#       Alternatively, create a new subdirectory under mlbench, cd into this
#       directory, and create subdirectories.  Now proceed to step 2 for each
#       of the subdirectories.  For example, I did the following for the
#       maxwell benchmark:
#
#               cd ${BENCH_ROOT_DIRECTORY}
#               mkdir maxwell
#               cd maxwell
#               mkdir 2dcube; mkdir 3dcube; mkdir aslot
#
#               
#
#    2) Create a file called 'exe.name' containing the name of the executable
#       that is to be run within this subdirectory (e.g. ml_example2d, 
#       ml_read_maxwell, ml_readfile, etc.). If this executable does not
#       exist in EXECUTABLE_DIRECTORY, run_benchmarks will create it by
#       invoking make.
#
#   2a) (optional) Create a files called 'exe.makeflags' that contains any
#       necessary defines (-Dxxxxxx) that make needs.
#
#    3) Put any data files that you need to run this example.
#
#    4) Create files 'ml_inputfile*' where '*' can not be empty. 
#       run_benchmarks will run one benchmark for each of these input files
#       (copying the data in ml_inputfile* to ml_inputfile). The input files 
#       can contain data that is used by your program. ML contains utilities 
#       for reading certain types of input files (see ML_Reader_ReadInput in 
#       the file ml_read_utils.c) for more details or look at some of the 
#       sample inputfiles in mlbench. 
#       NOTE: If certain data needs to be read and is VERY specific to your 
#       problem and NOT IN ml_read_utils.c, you can do the following:
#          a) use ML_Reader_ReadInput() to read the standard input.
#          b) reopen the inputfile with your application and read the 
#             application specific stuff using utilities like 
#             ML_Reader_LookFor(). See ml_example2d.c for a sample of this.
#       THE ONLY DATA that the script 'run_benchmarks' will read in the 
#       inputfile is a line of the form:
#            Number of processors = x
#       where 'x' is the number of processors to execute the job on.
#       If this line is not present in the input file, run_benchmarks will
#       assume that it is a serial job.
#    5) Create files 'output*' where '*' takes on the same values as 
#       the ml_inputfile* files created in step 4). Each output file
#       should contain the proper output for each run. The easiest way
#       to do this is to 'run_benchmark' on the directory without the
#       output files and then copy the output files created by the script
#       (in ${SCRATCH_DIRECTORY}) into the appropriate location in mlbench.
#
# OUTPUT:
#    run_benchmarks will create one output file for each run in 
#    ${SCRATCH_DIRECTORY}. This output will have all lines with 'ime'
#    grepped out. This is to avoid timing data.  All lines with
#    "[Rr]eading" will also be grepped out.  A dif file will also
#    be created by doing a 'diff -w' with the output file in the directory
#    structure. It will also create summary information which is essentially
#    a 'wc' on the dif file and grepping the dif file for the printed 
#    components of the solution vector and the total number of iterations.
#    This output is also printed on the screen.
#
# DEPENDENCIES:
#   run_benchmarks depends on the following scripts:
#       run_one             script for running one benchmark
#       qbench              script for submitting a job to pbs batch scheduler
#       mpibench.pbs        script that is submitted to pbs batch scheduler
#
#
TEMP=`echo ${PWD} | sed "s,.*/ml/etc,tuvwxyz,"`
if test `expr ${TEMP}` != 'tuvwxyz'
then
   echo "Must execute run_benchmarks from 'ml/etc' directory!!!"
   exit
fi

#echo "Usage: run_benchmarks [bench_root_directory executable_directory scratch_root_directory parallel={TRUE,FALSE}batch={TRUE,FALSE}]

#echo $* $#
#
# Take command line arguments and replace defaults
#
if test $# -ge 6
then
  echo "Usage: run_benchmarks [bench_root_directory executable_directory scratch_root_directory parallel={TRUE,FALSE} batch={TRUE,FALSE}]"
  exit
fi
if test $# -eq 0
then
  echo "Taking defaults for everything:"
  echo "      BENCHMARK DIRECTORY  = " $BENCH_ROOT_DIRECTORY
  echo "      EXECUTABLE DIRECTORY = " $EXECUTABLE_DIRECTORY
  echo "      SCRATCH DIRECTORY    = " $SCRATCH_ROOT_DIRECTORY
  echo "      PARALLEL             = " $PARALLEL
  echo "      BATCH                = " $BATCH
  echo 
  echo "If defaults not wanted, overwrite using ..."
  echo "    Usage: run_benchmarks [bench_root_directory executable_directory
  scratch_root_directory parallel={TRUE,FALSE} batch={TRUE,FALSE}]"
  echo
fi
if test $# -ge 1
then
  BENCH_ROOT_DIRECTORY=$1
fi
if test $# -ge 2
then
  EXECUTABLE_DIRECTORY=$2
fi
if test $# -ge 3
then
  SCRATCH_ROOT_DIRECTORY=$3
fi
if test $# -ge 4
then
  PARALLEL=$4
fi
if test $# -ge 5
then
  BATCH=$5
fi

export SCRIPT_DIRECTORY
export BENCH_ROOT_DIRECTORY
export EXECUTABLE_DIRECTORY
export SCRATCH_ROOT_DIRECTORY
export PARALLEL
export BATCH
export PARALLEL_CMD
export BENCH_SUBDIR
export SCRATCH_SUBDIR

#
#  Check for the benchmark directory containing the 
#  valid input/output data.
#

if test -d ${BENCH_ROOT_DIRECTORY}
then
  touch ${BENCH_ROOT_DIRECTORY}
else
  echo "The directory ${BENCH_ROOT_DIRECTORY} does not exist?"
  exit
fi

#
#  Check for the executable directory
#
temp=`echo ${EXECUTABLE} | sed "s/ .*//"`
if test -d ${EXECUTABLE_DIRECTORY}
then
  touch ${EXECUTABLE_DIRECTORY}
else
  echo "The directory ${EXECUTABLE_DIRECTORY} does not exist?"
  exit
fi


#
#  Check for the work space directory where current run output 
#  will be stored.
#

if test -d ${SCRATCH_ROOT_DIRECTORY}
then
  touch ${SCRATCH_ROOT_DIRECTORY}
else
  echo "Creating the directory ${SCRATCH_ROOT_DIRECTORY}"
  mkdir ${SCRATCH_ROOT_DIRECTORY}
fi


#
# Run program within each subdirectory and compare output
# with that contained in the corresponding ${BENCH_ROOT_DIRECTORY}.
#
rm -f ${SCRATCH_ROOT_DIRECTORY}/summary
echo " *********** Summary ***************" >> ${SCRATCH_ROOT_DIRECTORY}/summary
echo >> ${SCRATCH_ROOT_DIRECTORY}/summary
echo >> ${SCRATCH_ROOT_DIRECTORY}/summary
echo
tail -3 ${SCRATCH_ROOT_DIRECTORY}/summary


cd ${BENCH_ROOT_DIRECTORY}
for i in *
do 
   if test `expr ${i}` != 'CVS' -a \
           `expr ${i}` != '*' -a \
           `expr ${i}` != 'README'
   then
      cd ${i}
#      echo -n $i "  "
      if test -d ${SCRATCH_ROOT_DIRECTORY}/${i}
      then
         touch ${SCRATCH_ROOT_DIRECTORY}/${i}
      else
         mkdir ${SCRATCH_ROOT_DIRECTORY}/${i}
      fi

      for j in *
      do
         if test -d ${j} -a \
            `expr ${j}`  != 'CVS'
         then
            cd ${j}
            SCRATCH_SUBDIR=`echo ${SCRATCH_ROOT_DIRECTORY}/${i}/${j}`
            BENCH_SUBDIR=`echo ${BENCH_ROOT_DIRECTORY}/${i}/${j}`
            if test -d ${SCRATCH_SUBDIR}
            then
               touch ${SCRATCH_SUBDIR}
            else
               mkdir ${SCRATCH_SUBDIR}
            fi
            ${SCRIPT_DIRECTORY}/run_one
            cd ..
         fi
      done

      SCRATCH_SUBDIR=`echo ${SCRATCH_ROOT_DIRECTORY}/${i}`
      BENCH_SUBDIR=`echo ${BENCH_ROOT_DIRECTORY}/${i}`

      ${SCRIPT_DIRECTORY}/run_one
      cd ..

   fi
done
